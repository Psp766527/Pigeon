INFO  2025-05-29 12:14:35.993 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:14:36.019 [main] c.d.i.d.p.PigeonApplicationTests - Starting PigeonApplicationTests using Java 17.0.15 with PID 21336 (started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:14:36.021 [main] c.d.i.d.p.PigeonApplicationTests - The following 1 profile is active: "dev"
INFO  2025-05-29 12:14:38.651 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 12:14:39.038 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 366 ms. Found 1 MongoDB repository interface.
INFO  2025-05-29 12:14:40.166 [main] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/OpenLogic/17.0.15+6-adhoc..jdk17u"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='pigeon', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5e99e2cb, com.mongodb.Jep395RecordCodecProvider@76ac68b0, com.mongodb.KotlinCodecProvider@f559c74]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-29 12:14:40.214 [cluster-ClusterId{value='683802580ff475ca08ccac86', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=31145700, minRoundTripTimeNanos=0}
WARN  2025-05-29 12:14:40.319 [main] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 12:14:40.463 [main] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 12:14:41.426 [main] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 12:14:44.504 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 12:14:44.642 [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 12:14:45.051 [main] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 12:14:45.056 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 12:14:45.057 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 12:14:45.057 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748501085052
INFO  2025-05-29 12:14:45.066 [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 12:14:45.108 [main] c.d.i.d.p.PigeonApplicationTests - Started PigeonApplicationTests in 10.808 seconds (process running for 14.659)
INFO  2025-05-29 12:14:46.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 12:14:46.703 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 12:14:46.713 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:14:46.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-fb4f0267-613e-41d0-bd7f-81af3bd0edac
INFO  2025-05-29 12:14:46.825 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:14:47.006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=97, memberId='consumer-dev-group-1-fb4f0267-613e-41d0-bd7f-81af3bd0edac', protocol='range'}
INFO  2025-05-29 12:14:47.021 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 97: {consumer-dev-group-1-fb4f0267-613e-41d0-bd7f-81af3bd0edac=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 12:14:47.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=97, memberId='consumer-dev-group-1-fb4f0267-613e-41d0-bd7f-81af3bd0edac', protocol='range'}
INFO  2025-05-29 12:14:47.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 12:14:47.183 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 12:14:47.210 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=35, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 12:14:47.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 12:14:47.832 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 12:14:47.834 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 12:14:47.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-fb4f0267-613e-41d0-bd7f-81af3bd0edac sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 12:14:47.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:14:47.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:14:47.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 12:14:47.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:14:47.840 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:14:48.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 12:14:48.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 12:14:48.378 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 12:14:48.378 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 12:14:48.390 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 12:14:48.391 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 12:43:32.923 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:43:33.047 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 17140 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:43:33.049 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 12:43:33.191 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 12:43:33.191 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 12:43:33.258 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
ERROR 2025-05-29 12:43:34.289 [restartedMain] o.s.boot.SpringApplication - Application run failed
org.springframework.boot.docker.compose.core.ProcessExitException: 'docker version --format {{.Client.Version}}' failed with exit code 1.

Stdout:
28.0.4


Stderr:
error during connect: Get "http://%2F%2F.%2Fpipe%2FdockerDesktopLinuxEngine/v1.48/version": open //./pipe/dockerDesktopLinuxEngine: The system cannot find the file specified.

	at org.springframework.boot.docker.compose.core.ProcessRunner.run(ProcessRunner.java:97)
	at org.springframework.boot.docker.compose.core.ProcessRunner.run(ProcessRunner.java:75)
	at org.springframework.boot.docker.compose.core.DockerCli$DockerCommands.getDockerCommand(DockerCli.java:146)
	at org.springframework.boot.docker.compose.core.DockerCli$DockerCommands.<init>(DockerCli.java:140)
	at org.springframework.boot.docker.compose.core.DockerCli.lambda$new$0(DockerCli.java:66)
	at java.base/java.util.HashMap.computeIfAbsent(HashMap.java:1220)
	at org.springframework.boot.docker.compose.core.DockerCli.<init>(DockerCli.java:65)
	at org.springframework.boot.docker.compose.core.DockerCompose.get(DockerCompose.java:145)
	at org.springframework.boot.docker.compose.lifecycle.DockerComposeLifecycleManager.getDockerCompose(DockerComposeLifecycleManager.java:166)
	at org.springframework.boot.docker.compose.lifecycle.DockerComposeLifecycleManager.start(DockerComposeLifecycleManager.java:114)
	at org.springframework.boot.docker.compose.lifecycle.DockerComposeListener.onApplicationEvent(DockerComposeListener.java:53)
	at org.springframework.boot.docker.compose.lifecycle.DockerComposeListener.onApplicationEvent(DockerComposeListener.java:35)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:185)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:178)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:156)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:138)
	at org.springframework.boot.context.event.EventPublishingRunListener.multicastInitialEvent(EventPublishingRunListener.java:136)
	at org.springframework.boot.context.event.EventPublishingRunListener.contextLoaded(EventPublishingRunListener.java:98)
	at org.springframework.boot.SpringApplicationRunListeners.lambda$contextLoaded$4(SpringApplicationRunListeners.java:72)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:118)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:112)
	at org.springframework.boot.SpringApplicationRunListeners.contextLoaded(SpringApplicationRunListeners.java:72)
	at org.springframework.boot.SpringApplication.prepareContext(SpringApplication.java:416)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:317)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1362)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1351)
	at com.daimlertrucksasia.it.dsc.pigeon.PigeonApplication.main(PigeonApplication.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
INFO  2025-05-29 12:45:01.573 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:45:01.892 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 13276 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:45:01.930 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 12:45:02.275 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 12:45:02.275 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
WARN  2025-05-29 12:45:06.168 [restartedMain] o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.support.BeanDefinitionOverrideException: Invalid bean definition with name 'graphQL' defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class]: Cannot register bean definition [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=graphQLConfig; factoryMethodName=graphQL; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class]] for bean 'graphQL' since there is already [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=io.leangen.graphql.spqr.spring.autoconfigure.BaseAutoConfiguration; factoryMethodName=graphQL; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [io/leangen/graphql/spqr/spring/autoconfigure/BaseAutoConfiguration.class]] bound.
INFO  2025-05-29 12:45:06.188 [restartedMain] o.s.b.a.l.ConditionEvaluationReportLogger - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
ERROR 2025-05-29 12:45:06.253 [restartedMain] o.s.b.d.LoggingFailureAnalysisReporter - 

***************************
APPLICATION FAILED TO START
***************************

Description:

The bean 'graphQL', defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class], could not be registered. A bean with that name has already been defined in class path resource [io/leangen/graphql/spqr/spring/autoconfigure/BaseAutoConfiguration.class] and overriding is disabled.

Action:

Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true

INFO  2025-05-29 12:47:32.712 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:47:32.841 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 33540 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:47:32.842 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 12:47:32.943 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 12:47:32.943 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
WARN  2025-05-29 12:47:34.120 [restartedMain] o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.support.BeanDefinitionOverrideException: Invalid bean definition with name 'graphQL' defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class]: Cannot register bean definition [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=graphQLConfig; factoryMethodName=graphQL; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class]] for bean 'graphQL' since there is already [Root bean: class=null; scope=; abstract=false; lazyInit=null; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; fallback=false; factoryBeanName=io.leangen.graphql.spqr.spring.autoconfigure.BaseAutoConfiguration; factoryMethodName=graphQL; initMethodNames=null; destroyMethodNames=[(inferred)]; defined in class path resource [io/leangen/graphql/spqr/spring/autoconfigure/BaseAutoConfiguration.class]] bound.
INFO  2025-05-29 12:47:34.138 [restartedMain] o.s.b.a.l.ConditionEvaluationReportLogger - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
ERROR 2025-05-29 12:47:34.193 [restartedMain] o.s.b.d.LoggingFailureAnalysisReporter - 

***************************
APPLICATION FAILED TO START
***************************

Description:

The bean 'graphQL', defined in class path resource [com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/GraphQLConfig.class], could not be registered. A bean with that name has already been defined in class path resource [io/leangen/graphql/spqr/spring/autoconfigure/BaseAutoConfiguration.class] and overriding is disabled.

Action:

Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true

INFO  2025-05-29 12:50:38.311 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:50:38.474 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 27460 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:50:38.475 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 12:50:38.612 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 12:50:38.612 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 12:50:40.682 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 12:50:41.051 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 354 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 12:50:41.705 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 12:50:41.713 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 12:50:42.379 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='pigeon', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@3d5ef5c, com.mongodb.Jep395RecordCodecProvider@4cb15cb2, com.mongodb.KotlinCodecProvider@1f5561d3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-29 12:50:42.420 [cluster-ClusterId{value='68380aca1130b291d7fb9237', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=61088700, minRoundTripTimeNanos=0}
WARN  2025-05-29 12:50:42.752 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 12:50:43.008 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 12:50:44.380 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 12:50:44.411 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 12:50:44.414 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 12:50:44.415 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 12:50:44.596 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 12:50:44.599 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5946 ms
INFO  2025-05-29 12:50:44.851 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 12:50:46.109 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 12:50:48.036 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 12:50:48.073 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 12:50:48.153 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 12:50:48.249 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 12:50:48.475 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 12:50:48.477 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 12:50:48.478 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 12:50:48.478 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748503248475
INFO  2025-05-29 12:50:48.483 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 12:50:48.509 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.87 seconds (process running for 12.668)
INFO  2025-05-29 12:50:49.087 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 12:50:49.088 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 12:50:49.091 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:50:49.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-e1292a8b-5149-408b-8ee4-b0c97013a685
INFO  2025-05-29 12:50:49.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:50:49.111 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=99, memberId='consumer-dev-group-1-e1292a8b-5149-408b-8ee4-b0c97013a685', protocol='range'}
INFO  2025-05-29 12:50:49.120 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 99: {consumer-dev-group-1-e1292a8b-5149-408b-8ee4-b0c97013a685=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 12:50:49.128 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=99, memberId='consumer-dev-group-1-e1292a8b-5149-408b-8ee4-b0c97013a685', protocol='range'}
INFO  2025-05-29 12:50:49.128 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 12:50:49.131 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 12:50:49.141 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=35, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 12:50:49.143 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 12:51:21.808 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
INFO  2025-05-29 12:51:21.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 86 due to node 0 being disconnected (elapsed time since creation: 443ms, elapsed time since send: 443ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 12:51:21.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node -1 disconnected.
INFO  2025-05-29 12:51:21.825 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=62) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:21.883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 2147483647 disconnected.
INFO  2025-05-29 12:51:21.884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-29 12:51:24.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:24.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:24.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:26.337 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:26.338 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:28.808 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:28.809 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:28.809 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:31.639 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:31.640 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:34.564 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:34.565 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:34.565 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:37.633 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:37.634 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:40.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:40.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:40.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:43.627 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:43.627 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:46.677 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:46.678 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:49.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:49.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 12:51:49.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1396949624, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 12:51:52.645 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 12:51:52.646 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
WARN  2025-05-29 12:51:55.359 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] The metadata response from the cluster reported a recoverable issue with correlation id 100 : {pigeon-dev-events=INVALID_REPLICATION_FACTOR}
INFO  2025-05-29 12:51:56.372 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 12:52:42.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: fdsaj
ERROR 2025-05-29 12:52:42.159 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: fdsaj
org.springframework.data.mongodb.UncategorizedMongoDbException: Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='root', source='pigeon', password=<hidden>, mechanismProperties=<hidden>}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:33)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.kafka.listener.adapter.KotlinAwareInvocableHandlerMethod.doInvoke(KotlinAwareInvocableHandlerMethod.java:45)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:78)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:475)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invoke(MessagingMessageListenerAdapter.java:421)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:85)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:50)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2887)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2865)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2777)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2614)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2503)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1528)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1466)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1335)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoSecurityException: Exception authenticating MongoCredential{mechanism=SCRAM-SHA-1, userName='root', source='pigeon', password=<hidden>, mechanismProperties=<hidden>}
	at com.mongodb.internal.connection.SaslAuthenticator.wrapException(SaslAuthenticator.java:300)
	at com.mongodb.internal.connection.SaslAuthenticator.getNextSaslResponse(SaslAuthenticator.java:143)
	at com.mongodb.internal.connection.SaslAuthenticator.lambda$authenticate$0(SaslAuthenticator.java:71)
	at com.mongodb.internal.connection.SaslAuthenticator.doAsSubject(SaslAuthenticator.java:307)
	at com.mongodb.internal.connection.SaslAuthenticator.authenticate(SaslAuthenticator.java:67)
	at com.mongodb.internal.connection.DefaultAuthenticator.authenticate(DefaultAuthenticator.java:53)
	at com.mongodb.internal.connection.InternalStreamConnectionInitializer.finishHandshake(InternalStreamConnectionInitializer.java:89)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:238)
	at com.mongodb.internal.connection.UsageTrackingInternalConnection.open(UsageTrackingInternalConnection.java:53)
	at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection.open(DefaultConnectionPool.java:631)
	at com.mongodb.internal.connection.DefaultConnectionPool$OpenConcurrencyLimiter.openWithConcurrencyLimit(DefaultConnectionPool.java:978)
	at com.mongodb.internal.connection.DefaultConnectionPool$OpenConcurrencyLimiter.openOrGetAvailable(DefaultConnectionPool.java:908)
	at com.mongodb.internal.connection.DefaultConnectionPool.get(DefaultConnectionPool.java:198)
	at com.mongodb.internal.connection.DefaultServer.getConnection(DefaultServer.java:94)
	at com.mongodb.internal.binding.ClusterBinding$ClusterBindingConnectionSource.getConnection(ClusterBinding.java:138)
	at com.mongodb.client.internal.ClientSessionBinding$SessionBindingConnectionSource.getConnection(ClientSessionBinding.java:161)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 56 common frames omitted
Caused by: com.mongodb.MongoCommandException: Command failed with error 18 (AuthenticationFailed): 'Authentication failed.' on server localhost:27017. The full response is {"ok": 0.0, "errmsg": "Authentication failed.", "code": 18, "codeName": "AuthenticationFailed"}
	at com.mongodb.internal.connection.ProtocolHelper.getCommandFailureException(ProtocolHelper.java:210)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:520)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceiveInternal(InternalStreamConnection.java:448)
	at com.mongodb.internal.connection.InternalStreamConnection.lambda$sendAndReceive$0(InternalStreamConnection.java:375)
	at com.mongodb.internal.connection.InternalStreamConnection.sendAndReceive(InternalStreamConnection.java:378)
	at com.mongodb.internal.connection.CommandHelper.sendAndReceive(CommandHelper.java:100)
	at com.mongodb.internal.connection.CommandHelper.executeCommand(CommandHelper.java:49)
	at com.mongodb.internal.connection.SaslAuthenticator.sendSaslStart(SaslAuthenticator.java:236)
	at com.mongodb.internal.connection.SaslAuthenticator.getNextSaslResponse(SaslAuthenticator.java:141)
	... 83 common frames omitted
INFO  2025-05-29 12:52:52.162 [cluster-ClusterId{value='68380aca1130b291d7fb9237', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1389600, minRoundTripTimeNanos=0}
INFO  2025-05-29 12:53:28.735 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 12:53:28.736 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 12:53:28.739 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-e1292a8b-5149-408b-8ee4-b0c97013a685 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 12:53:28.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:53:28.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:53:28.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 12:53:28.744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:53:28.744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 12:53:29.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 12:53:29.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 12:53:29.236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 12:53:29.236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 12:53:29.255 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 12:53:29.256 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 12:53:29.268 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 12:53:30.373 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 12:53:38.396 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 12:53:38.562 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 22360 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 12:53:38.567 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 12:53:38.710 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 12:53:38.710 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 12:53:40.365 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 12:53:40.761 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 375 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 12:53:41.693 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 12:53:41.703 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 12:53:42.673 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@630d4252, com.mongodb.Jep395RecordCodecProvider@346e2a6c, com.mongodb.KotlinCodecProvider@169b0ac3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-29 12:53:42.700 [cluster-ClusterId{value='68380b7ec798c42d3a51f3c8', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=68374000, minRoundTripTimeNanos=0}
WARN  2025-05-29 12:53:43.020 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 12:53:43.294 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 12:53:45.088 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 12:53:45.128 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 12:53:45.134 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 12:53:45.137 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 12:53:45.358 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 12:53:45.362 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6615 ms
INFO  2025-05-29 12:53:45.578 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 12:53:46.641 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 12:53:48.609 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 12:53:48.652 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 12:53:48.717 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 12:53:48.790 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 12:53:49.044 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 12:53:49.048 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 12:53:49.048 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 12:53:49.048 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748503429045
INFO  2025-05-29 12:53:49.055 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 12:53:49.088 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.894 seconds (process running for 13.871)
INFO  2025-05-29 12:53:49.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 12:53:49.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 12:53:49.738 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:53:49.775 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-c34a9be8-03b2-4d71-8534-4f9cc738965c
INFO  2025-05-29 12:53:49.776 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 12:53:49.792 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=101, memberId='consumer-dev-group-1-c34a9be8-03b2-4d71-8534-4f9cc738965c', protocol='range'}
INFO  2025-05-29 12:53:49.801 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 101: {consumer-dev-group-1-c34a9be8-03b2-4d71-8534-4f9cc738965c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 12:53:49.820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=101, memberId='consumer-dev-group-1-c34a9be8-03b2-4d71-8534-4f9cc738965c', protocol='range'}
INFO  2025-05-29 12:53:49.821 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 12:53:49.826 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 12:53:49.853 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=36, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 12:53:49.855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 12:54:00.553 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: hkj
INFO  2025-05-29 12:54:00.747 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Result : No message found under msgTemplateID [hkj] for locale en
INFO  2025-05-29 12:54:00.748 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.p.PigeonKafkaProducerService - Sending message to topic: , key: , message: 
INFO  2025-05-29 12:54:00.792 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = pigeon-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

INFO  2025-05-29 12:54:00.800 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 12:54:00.831 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer - [Producer clientId=pigeon-producer-1] Instantiated an idempotent producer.
INFO  2025-05-29 12:54:00.867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.producer.ProducerConfig - These configurations '[linger, batch, key-serializer, value-serializer, buffer, retry]' were supplied but are not used yet.
INFO  2025-05-29 12:54:00.868 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 12:54:00.868 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 12:54:00.868 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748503440868
WARN  2025-05-29 12:54:00.899 [kafka-producer-network-thread | pigeon-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=pigeon-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {=INVALID_TOPIC_EXCEPTION}
ERROR 2025-05-29 12:54:00.900 [kafka-producer-network-thread | pigeon-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=pigeon-producer-1] Metadata response reported invalid topics []
INFO  2025-05-29 12:54:00.900 [kafka-producer-network-thread | pigeon-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=pigeon-producer-1] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 12:54:00.901 [kafka-producer-network-thread | pigeon-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=pigeon-producer-1] ProducerId set to 5001 with epoch 0
ERROR 2025-05-29 12:54:00.902 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: Invalid topics: []
ERROR 2025-05-29 12:54:02.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:54:04.926 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:54:06.940 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:54:06.940 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.p.PigeonKafkaProducerService - All retry attempts failed for message to topic: 
INFO  2025-05-29 12:55:31.963 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: hkj
INFO  2025-05-29 12:55:31.970 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Result : No message found under msgTemplateID [hkj] for locale en
INFO  2025-05-29 12:55:31.971 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.p.PigeonKafkaProducerService - Sending message to topic: , key: , message: 
ERROR 2025-05-29 12:55:31.971 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:55:33.981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:55:35.997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:55:38.043 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key='' and payload='' to topic :
org.apache.kafka.common.errors.InvalidTopicException: 
ERROR 2025-05-29 12:55:38.044 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.p.PigeonKafkaProducerService - All retry attempts failed for message to topic: 
INFO  2025-05-29 12:58:14.223 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 12:58:14.223 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 12:58:14.225 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
WARN  2025-05-29 12:58:49.856 [http-nio-8084-exec-3] notprivacysafe.graphql.GraphQL - Query did not validate : 'mutation CreateMsgTemplate {
    createMsgTemplate(newMsg: { locale: "en", message: "You cannot link DSCJC with FORCJC that {0} are not of same branch.", messageTemplateID: 1,serviceProviderID:"JobCard",serviceConsumerID:"JobCard" }) {
        locale
        message
        msgTemplateID
        serviceProviderID
    }
}'
WARN  2025-05-29 12:58:59.141 [http-nio-8084-exec-4] notprivacysafe.graphql.GraphQL - Query did not validate : 'mutation CreateMsgTemplate {
    createMsgTemplate(newMsg: { locale: "en", message: "You cannot link DSCJC with FORCJC that {0} are not of same branch.", messageTemplateID: null,serviceProviderID:"JobCard",serviceConsumerID:"JobCard" }) {
        locale
        message
        msgTemplateID
        serviceProviderID
    }
}'
WARN  2025-05-29 12:59:00.917 [kafka-producer-network-thread | pigeon-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=pigeon-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 8 : {=INVALID_TOPIC_EXCEPTION}
INFO  2025-05-29 13:00:18.931 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:00:18.932 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:00:18.933 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-c34a9be8-03b2-4d71-8534-4f9cc738965c sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:00:18.939 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:00:18.939 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:00:18.939 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:00:18.943 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:00:18.944 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:00:19.092 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:00:19.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:00:19.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:00:19.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:00:19.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:00:19.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:00:19.110 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:00:19.562 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:00:19.566 [SpringApplicationShutdownHook] o.a.k.clients.producer.KafkaProducer - [Producer clientId=pigeon-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
INFO  2025-05-29 13:00:19.579 [SpringApplicationShutdownHook] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:00:19.579 [SpringApplicationShutdownHook] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:00:19.579 [SpringApplicationShutdownHook] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:00:19.579 [SpringApplicationShutdownHook] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:00:19.580 [SpringApplicationShutdownHook] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for pigeon-producer-1 unregistered
INFO  2025-05-29 13:00:36.127 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:00:36.214 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 33252 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:00:36.216 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:00:36.640 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:00:36.640 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:00:39.859 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:00:40.156 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 285 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:00:40.913 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:00:40.922 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:00:41.548 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@64706137, com.mongodb.Jep395RecordCodecProvider@3c484bf7, com.mongodb.KotlinCodecProvider@66cc81e4]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-29 13:00:41.637 [cluster-ClusterId{value='68380d21fe112360e2b6b140', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=67968600, minRoundTripTimeNanos=0}
WARN  2025-05-29 13:00:41.838 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:00:42.065 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:00:43.161 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:00:43.192 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:00:43.196 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:00:43.197 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:00:43.478 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:00:43.481 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6612 ms
INFO  2025-05-29 13:00:43.725 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:00:45.061 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:00:46.430 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:00:46.467 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:00:46.539 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:00:46.606 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:00:46.816 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:00:46.818 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:00:46.819 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:00:46.819 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748503846816
INFO  2025-05-29 13:00:46.823 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:00:46.850 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.884 seconds (process running for 12.962)
INFO  2025-05-29 13:00:47.572 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:00:47.573 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:00:47.576 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:00:47.595 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-9c9a1765-0232-4db7-963a-445273cd517b
INFO  2025-05-29 13:00:47.595 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:00:47.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=103, memberId='consumer-dev-group-1-9c9a1765-0232-4db7-963a-445273cd517b', protocol='range'}
INFO  2025-05-29 13:00:47.608 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 103: {consumer-dev-group-1-9c9a1765-0232-4db7-963a-445273cd517b=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:00:47.616 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=103, memberId='consumer-dev-group-1-9c9a1765-0232-4db7-963a-445273cd517b', protocol='range'}
INFO  2025-05-29 13:00:47.617 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:00:47.621 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:00:47.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:00:47.637 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:01:11.581 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:01:11.582 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:01:11.585 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 3 ms
INFO  2025-05-29 13:07:57.309 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:07:57.310 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:07:57.311 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-9c9a1765-0232-4db7-963a-445273cd517b sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:07:57.312 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:07:57.312 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:07:57.312 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:07:57.314 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:07:57.315 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:07:57.692 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:07:57.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:07:57.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:07:57.693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:07:57.700 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:07:57.701 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:07:57.703 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:07:57.902 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:08:11.423 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:08:11.520 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 7900 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:08:11.522 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:08:11.615 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:08:11.616 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:08:13.109 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:08:13.333 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 214 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:08:13.972 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:08:13.980 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:08:14.440 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@23267c9f, com.mongodb.Jep395RecordCodecProvider@5a3ffd70, com.mongodb.KotlinCodecProvider@1cc22994]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:08:14.581 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:08:14.750 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:08:15.427 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:08:15.449 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:08:15.452 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:08:15.453 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:08:15.591 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:08:15.593 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 3940 ms
INFO  2025-05-29 13:08:15.769 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:08:16.445 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:08:17.535 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:08:17.602 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:08:17.671 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:08:17.739 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:08:17.954 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:08:17.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:08:17.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:08:17.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748504297954
INFO  2025-05-29 13:08:17.957 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:08:17.962 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:08:18.003 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 7.566 seconds (process running for 8.489)
INFO  2025-05-29 13:08:19.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:08:19.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:08:19.102 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:08:19.130 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-5e2d741b-50b1-46b3-ac61-5dddf67a162d
INFO  2025-05-29 13:08:19.181 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:08:19.190 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=105, memberId='consumer-dev-group-1-5e2d741b-50b1-46b3-ac61-5dddf67a162d', protocol='range'}
INFO  2025-05-29 13:08:19.202 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 105: {consumer-dev-group-1-5e2d741b-50b1-46b3-ac61-5dddf67a162d=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:08:19.217 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=105, memberId='consumer-dev-group-1-5e2d741b-50b1-46b3-ac61-5dddf67a162d', protocol='range'}
INFO  2025-05-29 13:08:19.218 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:08:19.223 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:08:19.244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:08:19.247 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:08:38.656 [http-nio-8084-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:08:38.657 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:08:38.660 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Completed initialization in 3 ms
INFO  2025-05-29 13:08:39.714 [http-nio-8084-exec-4] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 4. Remaining time: 29984 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:08:39.715 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:08:44.536 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:08:45.043 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:08:58.155 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:08:59.099 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:09:11.292 [cluster-ClusterId{value='68380ee6569e4b7e06324b41', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:09:32.019 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:09:32.022 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:09:32.023 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-5e2d741b-50b1-46b3-ac61-5dddf67a162d sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:09:32.024 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:09:32.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:09:32.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:09:32.030 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:09:32.030 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:09:32.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:09:32.175 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:09:32.175 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:09:32.175 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:09:32.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:09:32.194 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:09:32.197 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:09:34.019 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:10:01.972 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 33652 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:10:01.978 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:10:02.363 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:10:02.364 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:10:02.393 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:10:05.093 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:10:05.542 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 431 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:10:06.335 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:10:06.345 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:10:07.157 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@47182d7a, com.mongodb.Jep395RecordCodecProvider@55c258ed, com.mongodb.KotlinCodecProvider@651ab46f]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:10:07.467 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:10:07.816 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:10:09.384 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:10:09.548 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:10:09.553 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:10:09.553 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:10:10.023 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:10:10.161 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:10:10.165 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 7659 ms
INFO  2025-05-29 13:10:10.971 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:10:15.083 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:10:17.608 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:10:18.080 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:10:18.286 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:10:18.452 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:10:19.036 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:10:19.042 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:10:19.042 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:10:19.043 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748504419037
INFO  2025-05-29 13:10:19.056 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:10:19.097 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 20.245 seconds (process running for 25.081)
INFO  2025-05-29 13:10:20.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:10:20.237 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:10:20.243 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:10:20.278 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-4968509b-9ad1-48fc-b0e8-c49c4f1f1a5e
INFO  2025-05-29 13:10:20.279 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:10:20.285 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=107, memberId='consumer-dev-group-1-4968509b-9ad1-48fc-b0e8-c49c4f1f1a5e', protocol='range'}
INFO  2025-05-29 13:10:20.300 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 107: {consumer-dev-group-1-4968509b-9ad1-48fc-b0e8-c49c4f1f1a5e=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:10:20.310 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=107, memberId='consumer-dev-group-1-4968509b-9ad1-48fc-b0e8-c49c4f1f1a5e', protocol='range'}
INFO  2025-05-29 13:10:20.311 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:10:20.318 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:10:20.345 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:10:20.348 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:10:27.947 [http-nio-8084-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:10:27.948 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:10:27.950 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 13:10:55.841 [http-nio-8084-exec-4] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 5. Remaining time: 29957 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:10:58.796 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:11:11.217 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:11:11.890 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:11:24.837 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:11:25.338 [cluster-ClusterId{value='68380f56dd302e6d3d1f3578', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:14:01.057 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 13:14:01.057 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:14:01.059 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 13:14:01.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:14:01.066 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 13:14:01.066 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:14:01.167 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:14:01.168 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:14:01.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:14:01.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:14:01.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:14:01.172 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:14:01.172 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:14:01.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:14:01.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:14:01.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:14:01.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:14:01.179 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:14:01.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:14:01.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:14:01.188 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:14:01.474 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:14:58.408 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:14:58.694 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 36636 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:14:58.697 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:14:58.933 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:14:58.934 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:15:03.986 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:15:04.477 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 474 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:15:05.386 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:15:05.396 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:15:06.022 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@186c8f81, com.mongodb.Jep395RecordCodecProvider@733ba6b6, com.mongodb.KotlinCodecProvider@f8ab2eb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:15:06.284 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:15:06.485 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:15:07.368 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:15:07.398 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:15:07.401 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:15:07.402 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:15:07.520 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:15:07.523 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 8450 ms
INFO  2025-05-29 13:15:07.719 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:15:08.786 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:15:08.794 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:15:10.403 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:15:10.521 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:15:10.679 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:15:10.801 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:15:11.710 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:15:11.714 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:15:11.714 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:15:11.715 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748504711711
INFO  2025-05-29 13:15:11.722 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:15:11.764 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 16.351 seconds (process running for 17.692)
INFO  2025-05-29 13:15:12.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:15:12.841 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:15:12.846 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:15:12.884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-5a060216-d274-481d-8982-102a6da1237d
INFO  2025-05-29 13:15:12.885 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:15:12.894 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=109, memberId='consumer-dev-group-1-5a060216-d274-481d-8982-102a6da1237d', protocol='range'}
INFO  2025-05-29 13:15:12.908 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 109: {consumer-dev-group-1-5a060216-d274-481d-8982-102a6da1237d=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:15:12.922 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=109, memberId='consumer-dev-group-1-5a060216-d274-481d-8982-102a6da1237d', protocol='range'}
INFO  2025-05-29 13:15:12.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:15:12.930 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:15:12.948 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:15:12.951 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:15:51.594 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:15:51.595 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:15:51.599 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 4 ms
INFO  2025-05-29 13:15:56.227 [http-nio-8084-exec-2] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 6. Remaining time: 29967 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:15:56.228 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:15:59.961 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:00.473 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:12.890 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:13.390 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:25.652 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:26.152 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:16:43.566 [cluster-ClusterId{value='683810812c4691b418c36adb', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:19:36.404 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (0 additions, 1 deletion, 0 modifications)
INFO  2025-05-29 13:19:36.441 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:19:36.442 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:19:36.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-5a060216-d274-481d-8982-102a6da1237d sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:19:36.444 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:19:36.444 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:19:36.445 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:19:36.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:19:36.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:19:36.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:19:36.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:19:36.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:19:36.840 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:19:36.855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:19:36.857 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:19:36.864 [Thread-4] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:19:36.877 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:19:37.404 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:19:37.406 [Thread-4] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:19:37.907 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 36636 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:19:37.909 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:19:38.709 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:19:38.752 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 40 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:19:38.943 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:19:38.945 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:19:38.984 [cluster-ClusterId{value='683811922c4691b418c36add', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:19:38.985 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@186c8f81, com.mongodb.Jep395RecordCodecProvider@733ba6b6, com.mongodb.KotlinCodecProvider@f8ab2eb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:19:38.994 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:19:39.025 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:19:39.139 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:19:39.140 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:19:39.141 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:19:39.141 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:19:39.180 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:19:39.181 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1253 ms
INFO  2025-05-29 13:19:39.193 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:19:39.306 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:19:39.568 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:19:39.576 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:19:39.579 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:19:39.580 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:19:39.594 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:19:39.594 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:19:39.594 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:19:39.594 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748504979594
INFO  2025-05-29 13:19:39.595 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:19:39.604 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 2.036 seconds (process running for 285.532)
INFO  2025-05-29 13:19:39.609 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-29 13:19:39.611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:19:39.612 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:19:39.614 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:19:39.622 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-694788fc-b304-4d4f-8c28-9d1d16022537
INFO  2025-05-29 13:19:39.624 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:19:39.630 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=111, memberId='consumer-dev-group-2-694788fc-b304-4d4f-8c28-9d1d16022537', protocol='range'}
INFO  2025-05-29 13:19:39.631 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 111: {consumer-dev-group-2-694788fc-b304-4d4f-8c28-9d1d16022537=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:19:39.637 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=111, memberId='consumer-dev-group-2-694788fc-b304-4d4f-8c28-9d1d16022537', protocol='range'}
INFO  2025-05-29 13:19:39.638 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:19:39.638 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:19:39.642 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:19:39.643 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:19:51.715 [cluster-ClusterId{value='683811922c4691b418c36add', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:02.794 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (1 addition, 0 deletions, 0 modifications)
INFO  2025-05-29 13:21:02.814 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:21:02.815 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:21:02.815 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-694788fc-b304-4d4f-8c28-9d1d16022537 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:21:02.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:21:02.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:21:02.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:21:02.820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:21:02.821 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:21:02.884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:21:02.885 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:21:02.885 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:21:02.886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:21:02.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-05-29 13:21:02.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:21:02.899 [Thread-7] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:21:02.919 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:21:03.467 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:21:03.468 [Thread-7] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:21:03.684 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 36636 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:21:03.685 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:21:04.271 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:21:04.321 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 49 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:21:04.536 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:21:04.538 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:21:04.596 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@186c8f81, com.mongodb.Jep395RecordCodecProvider@733ba6b6, com.mongodb.KotlinCodecProvider@f8ab2eb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:21:04.603 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:21:04.629 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:21:04.686 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:04.819 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:21:04.823 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:21:04.823 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:21:04.824 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:21:04.885 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:21:04.886 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1193 ms
INFO  2025-05-29 13:21:04.900 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:21:06.055 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:21:06.418 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:21:06.427 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:21:06.430 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:21:06.431 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:21:06.445 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:21:06.446 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:21:06.446 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:21:06.446 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748505066446
INFO  2025-05-29 13:21:06.447 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:21:06.681 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 3.089 seconds (process running for 372.61)
INFO  2025-05-29 13:21:06.683 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-29 13:21:06.705 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:21:06.716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:21:06.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:21:06.941 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-1447f572-bc53-45e4-b04f-26dfcef14fc8
INFO  2025-05-29 13:21:06.942 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:21:06.960 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=113, memberId='consumer-dev-group-3-1447f572-bc53-45e4-b04f-26dfcef14fc8', protocol='range'}
INFO  2025-05-29 13:21:06.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Finished assignment for group at generation 113: {consumer-dev-group-3-1447f572-bc53-45e4-b04f-26dfcef14fc8=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:21:06.965 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=113, memberId='consumer-dev-group-3-1447f572-bc53-45e4-b04f-26dfcef14fc8', protocol='range'}
INFO  2025-05-29 13:21:06.965 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:21:06.966 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:21:06.975 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:21:06.976 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:21:09.680 [http-nio-8084-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:21:09.681 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:21:09.682 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-05-29 13:21:12.272 [http-nio-8084-exec-4] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 76. Remaining time: 29999 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}].
INFO  2025-05-29 13:21:14.990 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:15.491 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:27.878 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:28.397 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:40.663 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:41.197 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:21:59.341 [cluster-ClusterId{value='683811e82c4691b418c36ade', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:23:39.803 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (0 additions, 1 deletion, 0 modifications)
INFO  2025-05-29 13:23:39.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:23:39.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:23:39.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-1447f572-bc53-45e4-b04f-26dfcef14fc8 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:23:39.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:23:39.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:23:39.812 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:23:39.813 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:23:39.813 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:23:40.258 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:23:40.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:23:40.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:23:40.259 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:23:40.265 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-05-29 13:23:40.266 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:23:40.267 [Thread-11] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:23:40.275 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:23:40.959 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:23:40.960 [Thread-11] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:23:41.181 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 36636 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:23:41.181 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:23:41.935 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:23:41.994 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 57 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:23:42.209 [restartedMain] o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'graphQLConfig' defined in file [C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes\com\daimlertrucksasia\it\dsc\pigeon\exceptions\e\GraphQLConfig.class]: Post-processing of merged bean definition failed
INFO  2025-05-29 13:23:42.218 [restartedMain] o.s.b.a.l.ConditionEvaluationReportLogger - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
ERROR 2025-05-29 13:23:42.714 [restartedMain] o.s.boot.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'graphQLConfig' defined in file [C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes\com\daimlertrucksasia\it\dsc\pigeon\exceptions\e\GraphQLConfig.class]: Post-processing of merged bean definition failed
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:584)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:413)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1375)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1205)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:569)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:277)
	at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:808)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:611)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:753)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1362)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1351)
	at com.daimlertrucksasia.it.dsc.pigeon.PigeonApplication.main(PigeonApplication.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig] from ClassLoader [org.springframework.boot.devtools.restart.classloader.RestartClassLoader@f80dd1d]
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:756)
	at org.springframework.util.ReflectionUtils.doWithLocalFields(ReflectionUtils.java:689)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.buildResourceMetadata(CommonAnnotationBeanPostProcessor.java:432)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:413)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessMergedBeanDefinition(CommonAnnotationBeanPostProcessor.java:313)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyMergedBeanDefinitionPostProcessors(AbstractAutowireCapableBeanFactory.java:1123)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:581)
	... 29 common frames omitted
Caused by: java.lang.NoClassDefFoundError: com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/CustomGraphQLExceptionHandler
	at java.base/java.lang.Class.getDeclaredFields0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredFields(Class.java:3297)
	at java.base/java.lang.Class.getDeclaredFields(Class.java:2371)
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:751)
	... 35 common frames omitted
Caused by: java.lang.ClassNotFoundException: com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:121)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 39 common frames omitted
INFO  2025-05-29 13:23:54.114 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 36636 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:23:54.126 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:23:55.244 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:23:55.344 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 77 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:23:56.063 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:23:56.065 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:23:56.143 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@186c8f81, com.mongodb.Jep395RecordCodecProvider@733ba6b6, com.mongodb.KotlinCodecProvider@f8ab2eb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:23:56.155 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:23:56.186 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:23:56.523 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:23:56.525 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:23:56.526 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:23:56.526 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:23:56.659 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:23:56.659 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2512 ms
INFO  2025-05-29 13:23:56.670 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:23:56.976 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:23:57.436 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:23:57.447 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:23:57.449 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:23:57.450 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:23:57.478 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:23:57.479 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:23:57.480 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:23:57.480 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748505237478
INFO  2025-05-29 13:23:57.481 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:23:57.502 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 3.586 seconds (process running for 543.43)
INFO  2025-05-29 13:23:57.504 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-29 13:23:57.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:23:57.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:23:57.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:23:57.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-6b1210f0-dda0-4cc9-9bb0-88edf2afbdcd
INFO  2025-05-29 13:23:57.515 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:23:57.520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=115, memberId='consumer-dev-group-4-6b1210f0-dda0-4cc9-9bb0-88edf2afbdcd', protocol='range'}
INFO  2025-05-29 13:23:57.521 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Finished assignment for group at generation 115: {consumer-dev-group-4-6b1210f0-dda0-4cc9-9bb0-88edf2afbdcd=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:23:57.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=115, memberId='consumer-dev-group-4-6b1210f0-dda0-4cc9-9bb0-88edf2afbdcd', protocol='range'}
INFO  2025-05-29 13:23:57.525 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:23:57.525 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:23:57.531 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:23:57.531 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:23:58.928 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:24:16.837 [http-nio-8084-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:24:16.841 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:24:16.844 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-05-29 13:24:20.568 [http-nio-8084-exec-4] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 134. Remaining time: 29993 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:24:20.633 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:24:24.484 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:24:24.985 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:24:38.288 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:24:38.798 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:25:03.468 [cluster-ClusterId{value='683812942c4691b418c36ae0', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
WARN  2025-05-29 13:25:59.790 [http-nio-8084-exec-4] n.g.e.SimpleDataFetcherExceptionHandler - Exception while fetching data (/createMsgTemplate) : class graphql.GraphqlErrorBuilder$GraphqlErrorImpl cannot be cast to class com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse (graphql.GraphqlErrorBuilder$GraphqlErrorImpl is in unnamed module of loader 'app'; com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse is in unnamed module of loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader @1c5d3f7f)
java.lang.ClassCastException: class graphql.GraphqlErrorBuilder$GraphqlErrorImpl cannot be cast to class com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse (graphql.GraphqlErrorBuilder$GraphqlErrorImpl is in unnamed module of loader 'app'; com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse is in unnamed module of loader org.springframework.boot.devtools.restart.classloader.RestartClassLoader @1c5d3f7f)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.handleException(CustomGraphQLExceptionHandler.java:49)
	at graphql.execution.ExecutionStrategy.asyncHandleException(ExecutionStrategy.java:406)
	at graphql.execution.ExecutionStrategy.handleFetchingException(ExecutionStrategy.java:394)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$5(ExecutionStrategy.java:312)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:309)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-05-29 13:25:59.810 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 13:25:59.810 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:25:59.811 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 13:25:59.943 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:25:59.958 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Attempt to heartbeat with Generation{generationId=115, memberId='consumer-dev-group-4-6b1210f0-dda0-4cc9-9bb0-88edf2afbdcd', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 13:25:59.959 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 13:25:59.959 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 13:25:59.959 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 13:25:59.960 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:25:59.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 13:25:59.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:25:59.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:25:59.964 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-1cea7e50-f0c3-4f85-8057-8062eee28435
INFO  2025-05-29 13:25:59.964 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:25:59.970 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=117, memberId='consumer-dev-group-4-1cea7e50-f0c3-4f85-8057-8062eee28435', protocol='range'}
INFO  2025-05-29 13:25:59.970 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Finished assignment for group at generation 117: {consumer-dev-group-4-1cea7e50-f0c3-4f85-8057-8062eee28435=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:25:59.974 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=117, memberId='consumer-dev-group-4-1cea7e50-f0c3-4f85-8057-8062eee28435', protocol='range'}
INFO  2025-05-29 13:25:59.974 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:25:59.974 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:25:59.978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:25:59.978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:26:00.332 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:26:00.332 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:26:00.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Member consumer-dev-group-4-1cea7e50-f0c3-4f85-8057-8062eee28435 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:26:00.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:26:00.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:26:00.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:26:00.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:26:00.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:26:00.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:26:00.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:26:00.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:26:00.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:26:00.546 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-05-29 13:26:00.546 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:26:00.548 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:26:01.399 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:35:43.875 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:35:43.953 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 8096 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:35:43.954 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:35:44.157 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:35:44.158 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:35:47.408 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:35:47.798 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 370 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:35:48.914 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:35:48.924 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:35:49.688 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@39a81d, com.mongodb.Jep395RecordCodecProvider@469613e5, com.mongodb.KotlinCodecProvider@377d72fb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:35:50.052 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:35:50.338 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:35:52.036 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:35:52.066 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:35:52.071 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:35:52.071 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:35:52.334 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:35:52.337 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 8075 ms
INFO  2025-05-29 13:35:52.565 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:35:52.573 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:35:53.855 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:35:55.100 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:35:55.139 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:35:55.243 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:35:55.351 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:35:55.628 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:35:55.630 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:35:55.630 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:35:55.630 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748505955628
INFO  2025-05-29 13:35:55.636 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:35:55.665 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 13.043 seconds (process running for 14.1)
INFO  2025-05-29 13:35:56.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:35:56.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:35:56.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:35:56.536 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-c7e141f3-230c-4009-a1d7-b433eda433c8
INFO  2025-05-29 13:35:56.537 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:35:56.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=119, memberId='consumer-dev-group-1-c7e141f3-230c-4009-a1d7-b433eda433c8', protocol='range'}
INFO  2025-05-29 13:35:56.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 119: {consumer-dev-group-1-c7e141f3-230c-4009-a1d7-b433eda433c8=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:35:56.558 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=119, memberId='consumer-dev-group-1-c7e141f3-230c-4009-a1d7-b433eda433c8', protocol='range'}
INFO  2025-05-29 13:35:56.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:35:56.564 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:35:56.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:35:56.579 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:36:02.863 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:36:02.863 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:36:02.866 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 3 ms
INFO  2025-05-29 13:36:04.003 [http-nio-8084-exec-2] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 4. Remaining time: 29981 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:36:06.264 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:36:18.727 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:36:19.228 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:36:31.678 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:36:32.198 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 13:36:34.089 [http-nio-8084-exec-2] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] threw exception
java.lang.NullPointerException: null
	at graphql.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:903)
	at graphql.com.google.common.collect.ImmutableList$Builder.add(ImmutableList.java:815)
	at graphql.collect.ImmutableKit.map(ImmutableKit.java:56)
	at graphql.ExecutionResultImpl.errorsToSpec(ExecutionResultImpl.java:93)
	at graphql.ExecutionResultImpl.toSpecification(ExecutionResultImpl.java:81)
	at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:106)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:121)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:67)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:144)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.request(MonoCompletionStage.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.request(FluxMap.java:164)
	at reactor.core.publisher.StrictSubscriber.onSubscribe(StrictSubscriber.java:77)
	at reactor.core.publisher.FluxMap$MapSubscriber.onSubscribe(FluxMap.java:92)
	at reactor.core.publisher.MonoCompletionStage.subscribe(MonoCompletionStage.java:56)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
ERROR 2025-05-29 13:36:34.091 [http-nio-8084-exec-2] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at graphql.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:903)
	at graphql.com.google.common.collect.ImmutableList$Builder.add(ImmutableList.java:815)
	at graphql.collect.ImmutableKit.map(ImmutableKit.java:56)
	at graphql.ExecutionResultImpl.errorsToSpec(ExecutionResultImpl.java:93)
	at graphql.ExecutionResultImpl.toSpecification(ExecutionResultImpl.java:81)
	at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:106)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:121)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:67)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:144)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.request(MonoCompletionStage.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.request(FluxMap.java:164)
	at reactor.core.publisher.StrictSubscriber.onSubscribe(StrictSubscriber.java:77)
	at reactor.core.publisher.FluxMap$MapSubscriber.onSubscribe(FluxMap.java:92)
	at reactor.core.publisher.MonoCompletionStage.subscribe(MonoCompletionStage.java:56)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-05-29 13:36:46.920 [cluster-ClusterId{value='6838155da10b7934c49e03d3', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:38:43.471 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:38:43.472 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:38:43.472 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-c7e141f3-230c-4009-a1d7-b433eda433c8 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:38:43.473 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:38:43.473 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:38:43.473 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:38:43.475 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:38:43.475 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:38:43.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:38:43.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:38:43.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:38:43.520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:38:43.526 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:38:43.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:38:43.529 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:38:43.810 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:38:55.542 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:38:55.598 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 22156 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:38:55.600 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:38:55.726 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:38:55.727 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:38:57.264 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:38:57.530 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 252 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:38:57.947 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:38:57.954 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:38:58.375 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@1f5561d3, com.mongodb.Jep395RecordCodecProvider@2ef17e7b, com.mongodb.KotlinCodecProvider@272dbf6]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:38:58.497 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:38:58.680 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:38:59.439 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:38:59.464 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:38:59.468 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:38:59.469 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:38:59.611 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:38:59.615 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 3855 ms
INFO  2025-05-29 13:38:59.812 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:39:00.624 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:39:01.159 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:01.965 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:39:02.023 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:39:02.096 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:39:02.180 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:39:02.514 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:39:02.520 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:39:02.521 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:39:02.521 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748506142515
INFO  2025-05-29 13:39:02.529 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:39:02.577 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 8.379 seconds (process running for 9.714)
INFO  2025-05-29 13:39:03.430 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:39:03.432 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:39:03.437 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:39:03.465 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-ad076dd8-907e-40fc-a20e-15e51ed3db42
INFO  2025-05-29 13:39:03.466 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:39:03.471 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=121, memberId='consumer-dev-group-1-ad076dd8-907e-40fc-a20e-15e51ed3db42', protocol='range'}
INFO  2025-05-29 13:39:03.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 121: {consumer-dev-group-1-ad076dd8-907e-40fc-a20e-15e51ed3db42=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:39:03.491 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=121, memberId='consumer-dev-group-1-ad076dd8-907e-40fc-a20e-15e51ed3db42', protocol='range'}
INFO  2025-05-29 13:39:03.492 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:39:03.496 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:39:03.513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:39:03.515 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:39:08.683 [http-nio-8084-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:39:08.685 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:39:08.687 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 13:39:09.550 [http-nio-8084-exec-3] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 3. Remaining time: 29987 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:39:09.551 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:14.492 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:14.719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:39:14.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:39:14.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-ad076dd8-907e-40fc-a20e-15e51ed3db42 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:39:14.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:39:14.723 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:39:14.723 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:39:14.725 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:39:14.726 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:39:14.978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:39:14.979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:39:14.980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:39:14.980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:39:14.994 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:39:14.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:39:15.000 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:39:15.014 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:27.246 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:27.758 [cluster-ClusterId{value='6838161aef506ec6a01a3438', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:39:39.673 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:39:53.304 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:39:53.603 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 17460 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:39:53.606 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:39:53.797 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:39:53.797 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:39:55.960 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:39:56.277 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 304 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:39:57.019 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:39:57.029 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:39:57.684 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@274d476f, com.mongodb.Jep395RecordCodecProvider@51bcaf7c, com.mongodb.KotlinCodecProvider@2f39ce37]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:39:57.980 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:39:58.323 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:39:59.664 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:39:59.728 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:39:59.732 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:39:59.733 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:39:59.864 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:39:59.866 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6000 ms
INFO  2025-05-29 13:40:00.139 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
INFO  2025-05-29 13:40:00.532 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
WARN  2025-05-29 13:40:01.181 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:40:02.301 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:40:02.343 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:40:02.446 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:40:02.549 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:40:02.868 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:40:02.871 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:40:02.871 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:40:02.871 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748506202868
INFO  2025-05-29 13:40:02.877 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:40:02.913 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.992 seconds (process running for 14.018)
INFO  2025-05-29 13:40:03.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:40:03.554 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:40:03.557 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:40:03.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-10d18923-cd6c-4aac-8b20-e689a1c4460a
INFO  2025-05-29 13:40:03.578 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:40:03.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=123, memberId='consumer-dev-group-1-10d18923-cd6c-4aac-8b20-e689a1c4460a', protocol='range'}
INFO  2025-05-29 13:40:03.592 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 123: {consumer-dev-group-1-10d18923-cd6c-4aac-8b20-e689a1c4460a=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:40:03.601 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=123, memberId='consumer-dev-group-1-10d18923-cd6c-4aac-8b20-e689a1c4460a', protocol='range'}
INFO  2025-05-29 13:40:03.602 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:40:03.606 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:40:03.621 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:40:03.623 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:40:11.631 [http-nio-8084-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:40:11.631 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:40:11.634 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 13:40:14.924 [http-nio-8084-exec-3] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 4. Remaining time: 29987 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:40:15.310 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:40:27.672 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:40:28.173 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:40:40.529 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:40:41.030 [cluster-ClusterId{value='683816558e21a5a5d736d804', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:43:14.770 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 13:43:14.771 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:43:14.773 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 13:43:14.790 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:43:14.791 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 13:43:14.791 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
ERROR 2025-05-29 13:43:14.856 [http-nio-8084-exec-3] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] threw exception
java.lang.NullPointerException: null
	at graphql.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:903)
	at graphql.com.google.common.collect.ImmutableList$Builder.add(ImmutableList.java:815)
	at graphql.collect.ImmutableKit.map(ImmutableKit.java:56)
	at graphql.ExecutionResultImpl.errorsToSpec(ExecutionResultImpl.java:93)
	at graphql.ExecutionResultImpl.toSpecification(ExecutionResultImpl.java:81)
	at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:106)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:121)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:67)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:144)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.request(MonoCompletionStage.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.request(FluxMap.java:164)
	at reactor.core.publisher.StrictSubscriber.onSubscribe(StrictSubscriber.java:77)
	at reactor.core.publisher.FluxMap$MapSubscriber.onSubscribe(FluxMap.java:92)
	at reactor.core.publisher.MonoCompletionStage.subscribe(MonoCompletionStage.java:56)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
ERROR 2025-05-29 13:43:14.862 [http-nio-8084-exec-3] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: java.lang.NullPointerException] with root cause
java.lang.NullPointerException: null
	at graphql.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:903)
	at graphql.com.google.common.collect.ImmutableList$Builder.add(ImmutableList.java:815)
	at graphql.collect.ImmutableKit.map(ImmutableKit.java:56)
	at graphql.ExecutionResultImpl.errorsToSpec(ExecutionResultImpl.java:93)
	at graphql.ExecutionResultImpl.toSpecification(ExecutionResultImpl.java:81)
	at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:106)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:121)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.apply(MonoCompletionStage.java:67)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:144)
	at reactor.core.publisher.MonoCompletionStage$MonoCompletionStageSubscription.request(MonoCompletionStage.java:145)
	at reactor.core.publisher.FluxMap$MapSubscriber.request(FluxMap.java:164)
	at reactor.core.publisher.StrictSubscriber.onSubscribe(StrictSubscriber.java:77)
	at reactor.core.publisher.FluxMap$MapSubscriber.onSubscribe(FluxMap.java:92)
	at reactor.core.publisher.MonoCompletionStage.subscribe(MonoCompletionStage.java:56)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-05-29 13:43:14.878 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:43:14.885 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=123, memberId='consumer-dev-group-1-10d18923-cd6c-4aac-8b20-e689a1c4460a', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 13:43:14.886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 13:43:14.886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 13:43:14.886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 13:43:14.913 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:43:14.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 13:43:14.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:43:14.924 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:43:14.934 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-c19f6c3a-e0f5-43f3-96a1-30c88247c57a
INFO  2025-05-29 13:43:14.935 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:43:14.943 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=125, memberId='consumer-dev-group-1-c19f6c3a-e0f5-43f3-96a1-30c88247c57a', protocol='range'}
INFO  2025-05-29 13:43:14.944 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 125: {consumer-dev-group-1-c19f6c3a-e0f5-43f3-96a1-30c88247c57a=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:43:14.952 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=125, memberId='consumer-dev-group-1-c19f6c3a-e0f5-43f3-96a1-30c88247c57a', protocol='range'}
INFO  2025-05-29 13:43:14.953 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:43:14.953 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:43:14.957 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:43:14.958 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:43:16.756 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
INFO  2025-05-29 13:43:16.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:43:16.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:43:16.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-c19f6c3a-e0f5-43f3-96a1-30c88247c57a sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:43:16.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:43:16.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:43:16.766 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:43:16.768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:43:16.768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:43:16.922 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:43:16.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:43:16.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:43:16.923 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:43:16.932 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 13:43:16.933 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:43:16.936 [Thread-4] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:43:16.938 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:43:17.263 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:43:17.264 [Thread-4] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:43:17.606 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 17460 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:43:17.607 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:43:18.950 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:43:18.991 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 40 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:43:19.176 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:43:19.179 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:43:19.239 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@274d476f, com.mongodb.Jep395RecordCodecProvider@51bcaf7c, com.mongodb.KotlinCodecProvider@2f39ce37]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:43:19.247 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:43:19.298 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:43:19.462 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:43:19.464 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:43:19.464 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:43:19.465 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:43:19.522 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:43:19.523 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1907 ms
INFO  2025-05-29 13:43:19.537 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:43:19.659 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:43:19.931 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:43:19.939 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:43:19.942 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:43:19.942 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:43:19.956 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:43:19.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:43:19.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:43:19.957 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748506399957
INFO  2025-05-29 13:43:19.957 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:43:19.976 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 2.551 seconds (process running for 211.08)
INFO  2025-05-29 13:43:19.979 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-29 13:43:19.984 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:43:19.985 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:43:19.986 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:43:20.132 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-b82e39ac-2100-4379-a1c4-e61a3d5e11dc
INFO  2025-05-29 13:43:20.133 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:43:20.138 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=127, memberId='consumer-dev-group-2-b82e39ac-2100-4379-a1c4-e61a3d5e11dc', protocol='range'}
INFO  2025-05-29 13:43:20.139 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 127: {consumer-dev-group-2-b82e39ac-2100-4379-a1c4-e61a3d5e11dc=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:43:20.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=127, memberId='consumer-dev-group-2-b82e39ac-2100-4379-a1c4-e61a3d5e11dc', protocol='range'}
INFO  2025-05-29 13:43:20.146 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:43:20.146 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:43:20.150 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:43:20.151 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:43:22.101 [cluster-ClusterId{value='6838171f8e21a5a5d736d806', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:45:38.942 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 3 class path changes (0 additions, 3 deletions, 0 modifications)
INFO  2025-05-29 13:45:38.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:45:38.947 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:45:38.948 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-b82e39ac-2100-4379-a1c4-e61a3d5e11dc sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:45:38.948 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:45:38.948 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:45:38.948 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:45:38.949 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:45:38.949 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:45:39.271 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:45:39.272 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:45:39.272 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:45:39.272 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:45:39.280 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-05-29 13:45:39.280 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:45:39.281 [Thread-7] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:45:39.311 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:45:39.709 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:45:39.710 [Thread-7] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:45:39.891 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 17460 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:45:39.892 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:45:40.392 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:45:40.429 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 34 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:45:40.554 [restartedMain] o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'graphQLConfig' defined in file [C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes\com\daimlertrucksasia\it\dsc\pigeon\exceptions\e\GraphQLConfig.class]: Post-processing of merged bean definition failed
INFO  2025-05-29 13:45:40.561 [restartedMain] o.s.b.a.l.ConditionEvaluationReportLogger - 

Error starting ApplicationContext. To display the condition evaluation report re-run your application with 'debug' enabled.
ERROR 2025-05-29 13:45:40.618 [restartedMain] o.s.boot.SpringApplication - Application run failed
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'graphQLConfig' defined in file [C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes\com\daimlertrucksasia\it\dsc\pigeon\exceptions\e\GraphQLConfig.class]: Post-processing of merged bean definition failed
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:584)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:413)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1375)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1205)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:569)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:529)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:339)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:373)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:207)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:277)
	at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:808)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:611)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:146)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:753)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:439)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:318)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1362)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1351)
	at com.daimlertrucksasia.it.dsc.pigeon.PigeonApplication.main(PigeonApplication.java:10)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:50)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig] from ClassLoader [org.springframework.boot.devtools.restart.classloader.RestartClassLoader@7b5fdd4c]
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:756)
	at org.springframework.util.ReflectionUtils.doWithLocalFields(ReflectionUtils.java:689)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.buildResourceMetadata(CommonAnnotationBeanPostProcessor.java:432)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.findResourceMetadata(CommonAnnotationBeanPostProcessor.java:413)
	at org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessMergedBeanDefinition(CommonAnnotationBeanPostProcessor.java:313)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyMergedBeanDefinitionPostProcessors(AbstractAutowireCapableBeanFactory.java:1123)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:581)
	... 29 common frames omitted
Caused by: java.lang.NoClassDefFoundError: com/daimlertrucksasia/it/dsc/pigeon/exceptions/e/CustomGraphQLExceptionHandler
	at java.base/java.lang.Class.getDeclaredFields0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredFields(Class.java:3297)
	at java.base/java.lang.Class.getDeclaredFields(Class.java:2371)
	at org.springframework.util.ReflectionUtils.getDeclaredFields(ReflectionUtils.java:751)
	... 35 common frames omitted
Caused by: java.lang.ClassNotFoundException: com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Class.java:467)
	at org.springframework.boot.devtools.restart.classloader.RestartClassLoader.loadClass(RestartClassLoader.java:121)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 39 common frames omitted
INFO  2025-05-29 13:45:43.965 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 17460 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:45:43.966 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:45:44.876 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:45:44.910 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 32 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:45:45.505 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:45:45.507 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:45:45.780 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@274d476f, com.mongodb.Jep395RecordCodecProvider@51bcaf7c, com.mongodb.KotlinCodecProvider@2f39ce37]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:45:45.787 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:45:45.889 [cluster-ClusterId{value='683817b18e21a5a5d736d807', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
WARN  2025-05-29 13:45:45.908 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:45:46.057 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:45:46.058 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:45:46.059 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:45:46.059 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:45:46.251 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:45:46.251 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2276 ms
INFO  2025-05-29 13:45:46.267 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:45:46.557 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:45:46.951 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:45:46.963 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:45:46.975 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:45:46.976 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:45:47.000 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:45:47.000 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:45:47.000 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:45:47.000 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748506547000
INFO  2025-05-29 13:45:47.003 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:45:47.016 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:45:47.017 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:45:47.019 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:45:47.026 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-e8ba1485-444b-4690-9a05-1eadde77348f
INFO  2025-05-29 13:45:47.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:45:47.029 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 3.389 seconds (process running for 358.132)
INFO  2025-05-29 13:45:47.031 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-29 13:45:47.037 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=129, memberId='consumer-dev-group-3-e8ba1485-444b-4690-9a05-1eadde77348f', protocol='range'}
INFO  2025-05-29 13:45:47.038 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Finished assignment for group at generation 129: {consumer-dev-group-3-e8ba1485-444b-4690-9a05-1eadde77348f=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:45:47.046 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=129, memberId='consumer-dev-group-3-e8ba1485-444b-4690-9a05-1eadde77348f', protocol='range'}
INFO  2025-05-29 13:45:47.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:45:47.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:45:47.050 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:45:47.051 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:45:59.239 [cluster-ClusterId{value='683817b18e21a5a5d736d807', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-e8ba1485-444b-4690-9a05-1eadde77348f sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:46:09.040 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 13:46:09.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:46:09.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 13:46:09.539 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 13:46:09.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 13:46:09.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 13:46:09.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 13:46:09.545 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-05-29 13:46:09.545 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 13:46:09.546 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 13:46:09.891 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 13:46:18.655 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 13:46:18.957 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 33768 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 13:46:18.959 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 13:46:19.096 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 13:46:19.097 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 13:46:21.341 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 13:46:21.773 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 418 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 13:46:22.888 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 13:46:22.898 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 13:46:23.918 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@371ff74c, com.mongodb.Jep395RecordCodecProvider@517fa617, com.mongodb.KotlinCodecProvider@2061bfd9]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 13:46:24.568 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 13:46:24.970 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 13:46:26.641 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:46:26.948 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 13:46:27.232 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:46:27.237 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 13:46:27.238 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 13:46:27.481 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 13:46:27.486 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 8331 ms
INFO  2025-05-29 13:46:27.737 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 13:46:31.596 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 13:46:33.061 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 13:46:33.138 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 13:46:33.247 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 13:46:33.373 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 13:46:33.649 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 13:46:33.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 13:46:33.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 13:46:33.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748506593649
INFO  2025-05-29 13:46:33.656 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 13:46:33.682 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 17.633 seconds (process running for 20.225)
INFO  2025-05-29 13:46:34.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 13:46:34.449 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 13:46:34.454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:46:34.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-71336169-3ec0-4894-89b1-3c90d5f863f8
INFO  2025-05-29 13:46:34.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 13:46:34.487 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=131, memberId='consumer-dev-group-1-71336169-3ec0-4894-89b1-3c90d5f863f8', protocol='range'}
INFO  2025-05-29 13:46:34.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 131: {consumer-dev-group-1-71336169-3ec0-4894-89b1-3c90d5f863f8=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 13:46:34.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=131, memberId='consumer-dev-group-1-71336169-3ec0-4894-89b1-3c90d5f863f8', protocol='range'}
INFO  2025-05-29 13:46:34.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 13:46:34.514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 13:46:34.530 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 13:46:34.532 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 13:46:54.954 [http-nio-8084-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 13:46:54.954 [http-nio-8084-exec-1] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 13:46:54.959 [http-nio-8084-exec-1] o.s.web.servlet.DispatcherServlet - Completed initialization in 5 ms
INFO  2025-05-29 13:47:01.175 [http-nio-8084-exec-1] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 5. Remaining time: 29983 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:47:01.176 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:04.921 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:05.428 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:17.707 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:18.212 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:30.747 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:36.773 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:47:49.575 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:49:30.312 [http-nio-8084-exec-5] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 58. Remaining time: 29999 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 13:49:33.535 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:49:46.103 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:49:46.608 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:49:59.854 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:50:03.644 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 13:50:41.662 [cluster-ClusterId{value='683817d715fe82694b86f004', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 14:20:33.403 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
INFO  2025-05-29 14:20:33.404 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 1981 due to node 0 being disconnected (elapsed time since creation: 1132261ms, elapsed time since send: 1132261ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 14:20:33.410 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-29 14:20:33.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1902724875, epoch=1673) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 14:20:33.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 14:20:33.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=131, memberId='consumer-dev-group-1-71336169-3ec0-4894-89b1-3c90d5f863f8', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 14:20:33.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 14:20:33.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 14:20:33.542 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 14:20:33.542 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 14:20:33.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 14:20:33.545 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 14:20:33.546 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 14:20:33.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-16fd8448-95bf-4f92-9336-e3865660d7a4
INFO  2025-05-29 14:20:33.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 14:20:33.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=133, memberId='consumer-dev-group-1-16fd8448-95bf-4f92-9336-e3865660d7a4', protocol='range'}
INFO  2025-05-29 14:20:33.553 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 133: {consumer-dev-group-1-16fd8448-95bf-4f92-9336-e3865660d7a4=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 14:20:33.555 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=133, memberId='consumer-dev-group-1-16fd8448-95bf-4f92-9336-e3865660d7a4', protocol='range'}
INFO  2025-05-29 14:20:33.556 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 14:20:33.556 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 14:20:33.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 14:20:33.560 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 14:28:53.504 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 14:28:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 14:28:53.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-16fd8448-95bf-4f92-9336-e3865660d7a4 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 14:28:53.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 14:28:53.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 14:28:53.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 14:28:53.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 14:28:53.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 14:28:53.991 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 14:28:53.992 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 14:28:53.992 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 14:28:53.992 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 14:28:54.000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 14:28:54.003 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 14:28:54.006 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 14:28:54.422 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 16:07:21.667 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 16:07:21.835 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 22540 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 16:07:21.837 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 16:07:22.298 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 16:07:22.298 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 16:07:25.042 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 16:07:25.374 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 317 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 16:07:25.986 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:07:25.993 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 16:07:26.538 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@15f8419, com.mongodb.Jep395RecordCodecProvider@5d69c463, com.mongodb.KotlinCodecProvider@43520c14]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 16:07:26.714 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:07:26.932 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 16:07:27.708 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 16:07:27.737 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:07:27.740 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 16:07:27.740 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 16:07:27.852 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 16:07:27.853 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5422 ms
INFO  2025-05-29 16:07:27.963 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 16:07:28.583 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 16:07:30.109 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:07:31.110 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:07:31.210 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 16:07:31.331 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 16:07:31.431 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 16:07:31.717 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 16:07:31.720 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 16:07:31.721 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 16:07:31.721 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748515051718
INFO  2025-05-29 16:07:31.729 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 16:07:31.770 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.651 seconds (process running for 13.355)
INFO  2025-05-29 16:07:33.603 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 16:07:33.606 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 16:07:33.613 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:07:33.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-ff465e5c-649a-45c9-9c3e-4a50a36d14a4
INFO  2025-05-29 16:07:33.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:07:33.735 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=135, memberId='consumer-dev-group-1-ff465e5c-649a-45c9-9c3e-4a50a36d14a4', protocol='range'}
INFO  2025-05-29 16:07:33.757 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 135: {consumer-dev-group-1-ff465e5c-649a-45c9-9c3e-4a50a36d14a4=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 16:07:33.958 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=135, memberId='consumer-dev-group-1-ff465e5c-649a-45c9-9c3e-4a50a36d14a4', protocol='range'}
INFO  2025-05-29 16:07:33.960 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 16:07:33.965 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 16:07:34.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 16:07:34.028 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 16:08:33.435 [http-nio-8084-exec-5] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 16:08:33.435 [http-nio-8084-exec-5] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 16:08:33.437 [http-nio-8084-exec-5] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-05-29 16:08:34.027 [http-nio-8084-exec-5] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 8. Remaining time: 29987 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 16:08:34.148 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:08:46.727 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:08:47.228 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:08:59.735 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:09:00.245 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 16:09:04.039 [http-nio-8084-exec-5] io.leangen.graphql.util.ClassFinder - GraphQL error: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:609)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1558)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1356)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1282)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:98)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:277)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:515)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:284)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:734)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:174)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:158)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.LocalizationController.createLocalizedMsg(LocalizationController.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at io.leangen.graphql.metadata.execution.FixedMethodInvoker.execute(FixedMethodInvoker.java:22)
	at io.leangen.graphql.metadata.Resolver.resolve(Resolver.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$3(OperationExecutor.java:105)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$2(OperationExecutor.java:101)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.generator.mapping.core.DataFetcherResultAdapter$ErrorAppender.aroundInvoke(DataFetcherResultAdapter.java:78)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:111)
	at io.leangen.graphql.execution.OperationExecutor.get(OperationExecutor.java:60)
	at graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation.lambda$instrumentDataFetcher$0(DataLoaderDispatcherInstrumentation.java:90)
	at graphql.execution.ExecutionStrategy.invokeDataFetcher(ExecutionStrategy.java:329)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:305)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getWriteConnectionSource(ClusterBinding.java:100)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getWriteConnectionSource(ClientSessionBinding.java:98)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:191)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$decorateWriteWithRetries$0(MixedBulkWriteOperation.java:148)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:210)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:80)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:446)
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1116)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:498)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:481)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:475)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$17(MongoTemplate.java:1564)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:607)
	... 125 common frames omitted
INFO  2025-05-29 16:09:17.024 [cluster-ClusterId{value='683838e6823f18fcaec91574', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:30:45.894 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 16:30:45.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 16:30:45.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-ff465e5c-649a-45c9-9c3e-4a50a36d14a4 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 16:30:45.897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:30:45.898 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:30:45.898 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 16:30:45.900 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:30:45.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:30:46.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 16:30:46.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 16:30:46.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 16:30:46.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 16:30:46.156 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 16:30:46.157 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 16:30:46.166 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 16:30:46.689 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 16:32:14.704 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 16:32:14.821 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 29916 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 16:32:14.823 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 16:32:14.924 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 16:32:14.925 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 16:32:17.243 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 16:32:17.505 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 251 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 16:32:18.141 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:32:18.148 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 16:32:18.656 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@15f8419, com.mongodb.Jep395RecordCodecProvider@5d69c463, com.mongodb.KotlinCodecProvider@43520c14]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 16:32:18.806 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:32:18.962 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 16:32:19.745 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 16:32:19.768 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:32:19.776 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 16:32:19.777 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 16:32:19.904 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 16:32:19.908 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4947 ms
INFO  2025-05-29 16:32:20.081 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 16:32:20.805 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 16:32:21.996 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:32:22.025 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:32:22.051 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 16:32:22.129 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 16:32:22.241 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 16:32:22.494 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 16:32:22.498 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 16:32:22.498 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 16:32:22.498 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748516542494
INFO  2025-05-29 16:32:22.502 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 16:32:22.533 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 9.171 seconds (process running for 11.186)
INFO  2025-05-29 16:32:23.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 16:32:23.338 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 16:32:23.344 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:32:23.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-2a748ee5-6580-445c-8b75-2c9b19b54389
INFO  2025-05-29 16:32:23.378 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:32:23.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=137, memberId='consumer-dev-group-1-2a748ee5-6580-445c-8b75-2c9b19b54389', protocol='range'}
INFO  2025-05-29 16:32:23.393 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 137: {consumer-dev-group-1-2a748ee5-6580-445c-8b75-2c9b19b54389=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 16:32:23.405 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=137, memberId='consumer-dev-group-1-2a748ee5-6580-445c-8b75-2c9b19b54389', protocol='range'}
INFO  2025-05-29 16:32:23.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 16:32:23.413 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 16:32:23.433 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 16:32:23.437 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 16:33:41.190 [http-nio-8084-exec-7] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 16:33:41.191 [http-nio-8084-exec-7] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 16:33:41.193 [http-nio-8084-exec-7] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 16:33:41.554 [http-nio-8084-exec-7] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 9. Remaining time: 29990 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 16:33:41.555 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:33:51.571 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:33:52.071 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:34:04.352 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:34:04.854 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 16:34:11.563 [http-nio-8084-exec-7] io.leangen.graphql.util.ClassFinder - GraphQL error: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:609)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1558)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1356)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1282)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:98)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:277)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:515)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:284)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:734)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:174)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:158)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.LocalizationController.createLocalizedMsg(LocalizationController.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at io.leangen.graphql.metadata.execution.FixedMethodInvoker.execute(FixedMethodInvoker.java:22)
	at io.leangen.graphql.metadata.Resolver.resolve(Resolver.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$3(OperationExecutor.java:105)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$2(OperationExecutor.java:101)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.generator.mapping.core.DataFetcherResultAdapter$ErrorAppender.aroundInvoke(DataFetcherResultAdapter.java:78)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:111)
	at io.leangen.graphql.execution.OperationExecutor.get(OperationExecutor.java:60)
	at graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation.lambda$instrumentDataFetcher$0(DataLoaderDispatcherInstrumentation.java:90)
	at graphql.execution.ExecutionStrategy.invokeDataFetcher(ExecutionStrategy.java:329)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:305)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getWriteConnectionSource(ClusterBinding.java:100)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getWriteConnectionSource(ClientSessionBinding.java:98)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:191)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$decorateWriteWithRetries$0(MixedBulkWriteOperation.java:148)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:210)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:80)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:446)
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1116)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:498)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:481)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:475)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$17(MongoTemplate.java:1564)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:607)
	... 125 common frames omitted
ERROR 2025-05-29 16:34:11.577 [http-nio-8084-exec-7] notprivacysafe.graphql.GraphQL - Execution '02ede026-2074-4b83-a623-620bc7b51a9b' threw exception when executing : query : 'mutation CreateMsgTemplate {
    createMsgTemplate(newMsg: { locale: "en", message: "You cannot link DSCJC with FORCJC that {0} are not of same branch.", messageTemplateID: "job.card.link.error.JobCard",serviceProviderID:"JobCard",serviceConsumerID:"JobCard" }) {
        locale
        message
        msgTemplateID
        serviceProviderID
    }
}'. variables '{}'
java.util.concurrent.CompletionException: java.lang.ClassCastException: class graphql.execution.ResultPath cannot be cast to class java.util.List (graphql.execution.ResultPath is in unnamed module of loader 'app'; java.util.List is in module java.base of loader 'bootstrap')
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:315)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:687)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:2168)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:319)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassCastException: class graphql.execution.ResultPath cannot be cast to class java.util.List (graphql.execution.ResultPath is in unnamed module of loader 'app'; java.util.List is in module java.base of loader 'bootstrap')
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse.getPath(GraphQLErrorResponse.java:47)
	at graphql.execution.ExecutionContext.lambda$addErrors$3(ExecutionContext.java:235)
	at graphql.util.LockKit$ReentrantLock.runLocked(LockKit.java:38)
	at graphql.execution.ExecutionContext.addErrors(ExecutionContext.java:229)
	at graphql.execution.ExecutionStrategy.unboxPossibleDataFetcherResult(ExecutionStrategy.java:352)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$6(ExecutionStrategy.java:319)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:684)
	... 72 common frames omitted
ERROR 2025-05-29 16:34:11.614 [http-nio-8084-exec-7] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] threw exception
java.lang.ClassCastException: class graphql.execution.ResultPath cannot be cast to class java.util.List (graphql.execution.ResultPath is in unnamed module of loader 'app'; java.util.List is in module java.base of loader 'bootstrap')
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse.getPath(GraphQLErrorResponse.java:47)
	at graphql.execution.ExecutionContext.lambda$addErrors$3(ExecutionContext.java:235)
	at graphql.util.LockKit$ReentrantLock.runLocked(LockKit.java:38)
	at graphql.execution.ExecutionContext.addErrors(ExecutionContext.java:229)
	at graphql.execution.ExecutionStrategy.unboxPossibleDataFetcherResult(ExecutionStrategy.java:352)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$6(ExecutionStrategy.java:319)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:684)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:2168)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:319)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
ERROR 2025-05-29 16:34:11.615 [http-nio-8084-exec-7] o.a.c.c.C.[.[.[.[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed: java.lang.ClassCastException: class graphql.execution.ResultPath cannot be cast to class java.util.List (graphql.execution.ResultPath is in unnamed module of loader 'app'; java.util.List is in module java.base of loader 'bootstrap')] with root cause
java.lang.ClassCastException: class graphql.execution.ResultPath cannot be cast to class java.util.List (graphql.execution.ResultPath is in unnamed module of loader 'app'; java.util.List is in module java.base of loader 'bootstrap')
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLErrorResponse.getPath(GraphQLErrorResponse.java:47)
	at graphql.execution.ExecutionContext.lambda$addErrors$3(ExecutionContext.java:235)
	at graphql.util.LockKit$ReentrantLock.runLocked(LockKit.java:38)
	at graphql.execution.ExecutionContext.addErrors(ExecutionContext.java:229)
	at graphql.execution.ExecutionStrategy.unboxPossibleDataFetcherResult(ExecutionStrategy.java:352)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$6(ExecutionStrategy.java:319)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:684)
	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:662)
	at java.base/java.util.concurrent.CompletableFuture.thenApply(CompletableFuture.java:2168)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:319)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-05-29 16:34:23.750 [cluster-ClusterId{value='68383eba8e404604edff46bd', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:38:47.760 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 16:38:47.762 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 16:38:47.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-2a748ee5-6580-445c-8b75-2c9b19b54389 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 16:38:47.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:38:47.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:38:47.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 16:38:47.769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:38:47.770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:38:47.916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 16:38:47.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 16:38:47.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 16:38:47.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 16:38:47.929 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 16:38:47.932 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 16:38:47.936 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 16:38:48.472 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 16:39:10.917 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 16:39:11.008 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 21260 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 16:39:11.011 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 16:39:11.219 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 16:39:11.220 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 16:39:16.113 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 16:39:16.694 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 563 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 16:39:17.882 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:39:17.908 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 16:39:19.214 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@1cb2371, com.mongodb.Jep395RecordCodecProvider@4f603cec, com.mongodb.KotlinCodecProvider@450b4629]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 16:39:19.386 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:39:19.583 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 16:39:20.403 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 16:39:20.425 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:39:20.429 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 16:39:20.431 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 16:39:20.542 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 16:39:20.544 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 9248 ms
INFO  2025-05-29 16:39:20.682 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 16:39:21.585 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 16:39:22.146 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:39:23.754 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:39:24.027 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 16:39:24.125 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 16:39:24.384 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 16:39:24.675 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 16:39:24.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 16:39:24.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 16:39:24.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748516964675
INFO  2025-05-29 16:39:24.684 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 16:39:24.720 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 16.01 seconds (process running for 17.123)
INFO  2025-05-29 16:39:25.569 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 16:39:25.576 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 16:39:25.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:39:25.629 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-61d7f939-36fc-453c-9c8d-6067e8bb4a97
INFO  2025-05-29 16:39:25.630 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:39:25.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=139, memberId='consumer-dev-group-1-61d7f939-36fc-453c-9c8d-6067e8bb4a97', protocol='range'}
INFO  2025-05-29 16:39:25.650 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 139: {consumer-dev-group-1-61d7f939-36fc-453c-9c8d-6067e8bb4a97=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 16:39:25.662 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=139, memberId='consumer-dev-group-1-61d7f939-36fc-453c-9c8d-6067e8bb4a97', protocol='range'}
INFO  2025-05-29 16:39:25.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 16:39:25.670 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 16:39:25.691 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 16:39:25.694 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 16:39:41.397 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 16:39:41.398 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 16:39:41.400 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 16:39:42.050 [http-nio-8084-exec-2] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 4. Remaining time: 29986 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 16:39:42.051 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:39:47.907 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:39:48.409 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:40:01.110 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:40:01.612 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 16:40:12.051 [http-nio-8084-exec-2] io.leangen.graphql.util.ClassFinder - GraphQL error: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:609)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1558)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1356)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1282)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:98)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:277)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:515)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:284)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:734)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:174)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:158)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy72.save(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.LocalizationController.createLocalizedMsg(LocalizationController.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at io.leangen.graphql.metadata.execution.FixedMethodInvoker.execute(FixedMethodInvoker.java:22)
	at io.leangen.graphql.metadata.Resolver.resolve(Resolver.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$3(OperationExecutor.java:105)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$2(OperationExecutor.java:101)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.generator.mapping.core.DataFetcherResultAdapter$ErrorAppender.aroundInvoke(DataFetcherResultAdapter.java:78)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:111)
	at io.leangen.graphql.execution.OperationExecutor.get(OperationExecutor.java:60)
	at graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation.lambda$instrumentDataFetcher$0(DataLoaderDispatcherInstrumentation.java:90)
	at graphql.execution.ExecutionStrategy.invokeDataFetcher(ExecutionStrategy.java:329)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:305)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getWriteConnectionSource(ClusterBinding.java:100)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getWriteConnectionSource(ClientSessionBinding.java:98)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:191)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$decorateWriteWithRetries$0(MixedBulkWriteOperation.java:148)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:210)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:80)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:446)
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1116)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:498)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:481)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:475)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$17(MongoTemplate.java:1564)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:607)
	... 125 common frames omitted
INFO  2025-05-29 16:40:13.841 [cluster-ClusterId{value='6838405f5d6f7349ad5bc76e', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:40:44.234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 16:40:44.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 16:40:44.236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-61d7f939-36fc-453c-9c8d-6067e8bb4a97 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 16:40:44.237 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:40:44.238 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:40:44.238 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 16:40:44.240 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:40:44.240 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:40:44.353 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 16:40:44.353 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 16:40:44.354 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 16:40:44.354 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 16:40:44.367 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 16:40:44.368 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 16:40:44.371 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 16:40:44.872 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 16:40:55.714 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 16:40:55.848 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 32744 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 16:40:55.850 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 16:40:56.002 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 16:40:56.011 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 16:40:57.624 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 16:40:58.051 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 415 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 16:40:58.534 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:40:58.542 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 16:40:59.040 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@146b681c, com.mongodb.Jep395RecordCodecProvider@12a833e4, com.mongodb.KotlinCodecProvider@6f1bd1cb]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 16:40:59.187 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:40:59.362 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-29 16:41:00.408 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 16:41:00.433 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:41:00.437 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 16:41:00.437 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 16:41:00.552 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 16:41:00.556 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4491 ms
INFO  2025-05-29 16:41:00.683 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 16:41:01.510 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 16:41:01.746 [cluster-ClusterId{value='683840c26bc0e2dc96b61429', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:41:03.173 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:41:03.258 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 16:41:03.393 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 16:41:03.505 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 16:41:03.784 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 16:41:03.788 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 16:41:03.788 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 16:41:03.789 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748517063784
INFO  2025-05-29 16:41:03.793 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 16:41:03.826 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 9.509 seconds (process running for 10.697)
INFO  2025-05-29 16:41:04.616 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 16:41:04.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 16:41:04.624 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:41:04.652 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-26496e77-b1ed-42fa-a548-c968a1fa5578
INFO  2025-05-29 16:41:04.654 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:41:04.658 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=141, memberId='consumer-dev-group-1-26496e77-b1ed-42fa-a548-c968a1fa5578', protocol='range'}
INFO  2025-05-29 16:41:04.665 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 141: {consumer-dev-group-1-26496e77-b1ed-42fa-a548-c968a1fa5578=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 16:41:04.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=141, memberId='consumer-dev-group-1-26496e77-b1ed-42fa-a548-c968a1fa5578', protocol='range'}
INFO  2025-05-29 16:41:04.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 16:41:04.680 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 16:41:04.701 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 16:41:04.705 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 16:45:51.304 [http-nio-8084-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 16:45:51.304 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 16:45:51.306 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
WARN  2025-05-29 16:45:51.543 [http-nio-8084-exec-3] notprivacysafe.graphql.GraphQL - Query did not validate : 'mutation CreateMsgTemplate {
    createMsgTemplate(newMsg: { locale: "en", message: "You cannot link DSCJC with FORCJC that {0} are not of same branch.", messageTemplateID: "job.card.link.error.JobCard",serviceProviderID:"JobCard",serviceConsumerID:"JobCard" }) {
        locale
        message
        msgTemplateI
        serviceProviderID
    }
}'
INFO  2025-05-29 16:57:25.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 16:57:25.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 16:57:25.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-26496e77-b1ed-42fa-a548-c968a1fa5578 sending LeaveGroup request to coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-29 16:57:25.364 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:57:25.364 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:57:25.364 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 16:57:25.372 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:57:25.372 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 16:57:25.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-29 16:57:25.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-29 16:57:25.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-29 16:57:25.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-29 16:57:25.847 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-29 16:57:25.848 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-29 16:57:25.908 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-29 16:57:26.456 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-29 16:57:46.417 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-29 16:57:46.527 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 10552 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-29 16:57:46.529 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-29 16:57:46.660 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-29 16:57:46.660 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-29 16:57:49.339 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-29 16:57:49.688 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 338 ms. Found 1 MongoDB repository interface.
WARN  2025-05-29 16:57:51.497 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.509 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.544 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.549 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.555 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.558 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.736 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.776 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.789 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.815 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.838 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.842 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.861 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.866 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:51.868 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-05-29 16:57:52.389 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@3089790c, com.mongodb.Jep395RecordCodecProvider@7654e0c0, com.mongodb.KotlinCodecProvider@4064486]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-29 16:57:52.392 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:52.405 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:52.408 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:52.681 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:57:52.695 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:52.747 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:52.972 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.004 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-29 16:57:53.097 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.255 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.548 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.550 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy71] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.557 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.662 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.710 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.741 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.747 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.839 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.885 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.894 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.912 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.914 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.923 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-05-29 16:57:53.925 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-05-29 16:57:55.160 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-29 16:57:55.235 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:57:55.239 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-29 16:57:55.239 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-29 16:57:55.252 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:57:55.562 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-29 16:57:55.567 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 8873 ms
INFO  2025-05-29 16:57:55.901 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-29 16:57:57.073 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-29 16:57:58.709 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-29 16:57:58.754 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-29 16:57:58.863 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-29 16:57:59.016 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-29 16:57:59.361 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-29 16:57:59.366 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-29 16:57:59.366 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-29 16:57:59.367 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748518079362
INFO  2025-05-29 16:57:59.373 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-29 16:57:59.418 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 14.349 seconds (process running for 16.268)
INFO  2025-05-29 16:58:00.631 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-29 16:58:00.632 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 16:58:00.639 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:58:00.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-a5bd3293-a3ae-4ebe-b18b-88ba5b59286d
INFO  2025-05-29 16:58:00.673 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 16:58:00.678 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=143, memberId='consumer-dev-group-1-a5bd3293-a3ae-4ebe-b18b-88ba5b59286d', protocol='range'}
INFO  2025-05-29 16:58:00.692 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 143: {consumer-dev-group-1-a5bd3293-a3ae-4ebe-b18b-88ba5b59286d=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 16:58:00.704 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=143, memberId='consumer-dev-group-1-a5bd3293-a3ae-4ebe-b18b-88ba5b59286d', protocol='range'}
INFO  2025-05-29 16:58:00.706 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 16:58:00.711 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 16:58:00.730 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 16:58:00.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 16:58:10.193 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-29 16:58:10.193 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-29 16:58:10.196 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-29 16:58:17.139 [http-nio-8084-exec-2] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 4. Remaining time: 29969 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 16:58:17.141 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:21.020 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:21.522 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:33.871 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:34.383 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:46.788 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 16:58:47.134 [http-nio-8084-exec-2] io.leangen.graphql.util.ClassFinder - GraphQL error: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:609)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1558)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1356)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1282)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:98)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:277)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:515)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:284)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:734)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:174)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:158)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.save(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.LocalizationController.createLocalizedMsg(LocalizationController.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at io.leangen.graphql.metadata.execution.FixedMethodInvoker.execute(FixedMethodInvoker.java:22)
	at io.leangen.graphql.metadata.Resolver.resolve(Resolver.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$3(OperationExecutor.java:105)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$2(OperationExecutor.java:101)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.generator.mapping.core.DataFetcherResultAdapter$ErrorAppender.aroundInvoke(DataFetcherResultAdapter.java:78)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:111)
	at io.leangen.graphql.execution.OperationExecutor.get(OperationExecutor.java:60)
	at graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation.lambda$instrumentDataFetcher$0(DataLoaderDispatcherInstrumentation.java:90)
	at graphql.execution.ExecutionStrategy.invokeDataFetcher(ExecutionStrategy.java:329)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:305)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getWriteConnectionSource(ClusterBinding.java:100)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getWriteConnectionSource(ClientSessionBinding.java:98)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:191)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$decorateWriteWithRetries$0(MixedBulkWriteOperation.java:148)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:210)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:80)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:446)
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1116)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:498)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:481)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:475)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$17(MongoTemplate.java:1564)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:607)
	... 125 common frames omitted
INFO  2025-05-29 16:58:52.525 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:58:52.752 [http-nio-8084-exec-2] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 49. Remaining time: 29999 ms. Selector: ReadPreferenceServerSelector{readPreference=primary}, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}].
INFO  2025-05-29 16:58:59.816 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:59:00.452 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:59:12.711 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 16:59:13.226 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
WARN  2025-05-29 16:59:22.758 [http-nio-8084-exec-2] n.g.e.SimpleDataFetcherExceptionHandler - Exception while fetching data (/createMsgTemplate) : Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:48)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.lambda$new$4(CustomGraphQLExceptionHandler.java:84)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.lambda$handleException$6(CustomGraphQLExceptionHandler.java:102)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.handleException(CustomGraphQLExceptionHandler.java:102)
	at graphql.execution.ExecutionStrategy.asyncHandleException(ExecutionStrategy.java:406)
	at graphql.execution.ExecutionStrategy.handleFetchingException(ExecutionStrategy.java:394)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$5(ExecutionStrategy.java:312)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:309)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:82)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:88)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 109 common frames omitted
INFO  2025-05-29 16:59:25.895 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:17.421 [http-nio-8084-exec-5] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 107. Remaining time: 29999 ms. Selector: WritableServerSelector, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 17:01:17.424 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:20.628 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:21.133 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:33.397 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:33.913 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:46.304 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:01:46.804 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
ERROR 2025-05-29 17:01:47.429 [http-nio-8084-exec-5] io.leangen.graphql.util.ClassFinder - GraphQL error: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:609)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1558)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1356)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1282)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:98)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:277)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:515)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:284)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:734)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:174)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:158)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.save(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.LocalizationController.createLocalizedMsg(LocalizationController.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at io.leangen.graphql.metadata.execution.FixedMethodInvoker.execute(FixedMethodInvoker.java:22)
	at io.leangen.graphql.metadata.Resolver.resolve(Resolver.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$3(OperationExecutor.java:105)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$2(OperationExecutor.java:101)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.lambda$execute$4(OperationExecutor.java:115)
	at io.leangen.graphql.generator.mapping.core.DataFetcherResultAdapter$ErrorAppender.aroundInvoke(DataFetcherResultAdapter.java:78)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:115)
	at io.leangen.graphql.execution.OperationExecutor.execute(OperationExecutor.java:111)
	at io.leangen.graphql.execution.OperationExecutor.get(OperationExecutor.java:60)
	at graphql.execution.instrumentation.dataloader.DataLoaderDispatcherInstrumentation.lambda$instrumentDataFetcher$0(DataLoaderDispatcherInstrumentation.java:90)
	at graphql.execution.ExecutionStrategy.invokeDataFetcher(ExecutionStrategy.java:329)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:305)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches WritableServerSelector. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getWriteConnectionSource(ClusterBinding.java:100)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getWriteConnectionSource(ClientSessionBinding.java:98)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$execute$3(MixedBulkWriteOperation.java:191)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$decorateWriteWithRetries$0(MixedBulkWriteOperation.java:148)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:210)
	at com.mongodb.internal.operation.MixedBulkWriteOperation.execute(MixedBulkWriteOperation.java:80)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:446)
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1116)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:498)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:481)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:475)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$17(MongoTemplate.java:1564)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:607)
	... 125 common frames omitted
INFO  2025-05-29 17:04:25.623 [http-nio-8084-exec-5] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 152. Remaining time: 29999 ms. Selector: ReadPreferenceServerSelector{readPreference=primary}, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}].
INFO  2025-05-29 17:04:26.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to request timeout.
INFO  2025-05-29 17:04:26.625 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 500 due to node 0 being disconnected (elapsed time since creation: 159341ms, elapsed time since send: 159341ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 17:04:26.627 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=774079492, epoch=414) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 17:04:26.628 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 17:04:26.628 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:04:26.628 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 17:04:26.759 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:04:26.762 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=143, memberId='consumer-dev-group-1-a5bd3293-a3ae-4ebe-b18b-88ba5b59286d', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 17:04:26.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:04:26.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:04:26.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 17:04:26.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 17:04:26.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 17:04:26.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 17:04:26.765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:04:26.768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-e1ce8dac-7bb7-4d26-b3ce-580373fba4f1
INFO  2025-05-29 17:04:26.768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:04:26.772 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=145, memberId='consumer-dev-group-1-e1ce8dac-7bb7-4d26-b3ce-580373fba4f1', protocol='range'}
INFO  2025-05-29 17:04:26.773 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 145: {consumer-dev-group-1-e1ce8dac-7bb7-4d26-b3ce-580373fba4f1=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 17:04:26.776 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=145, memberId='consumer-dev-group-1-e1ce8dac-7bb7-4d26-b3ce-580373fba4f1', protocol='range'}
INFO  2025-05-29 17:04:26.777 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 17:04:26.777 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 17:04:26.779 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 17:04:26.781 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 17:04:29.520 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:04:30.023 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:04:42.457 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:04:42.959 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:04:55.189 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:05:59.026 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 17:05:59.036 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:05:59.040 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 17:05:59.046 [http-nio-8084-exec-5] org.mongodb.driver.cluster - Waiting for server to become available for operation with ID 194. Remaining time: 29999 ms. Selector: ReadPreferenceServerSelector{readPreference=primary}, topology description: {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: No such host is known (mongodb)}, caused by {java.net.UnknownHostException: No such host is known (mongodb)}}].
INFO  2025-05-29 17:05:59.049 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 579 due to node 2147483647 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 17:05:59.051 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to request timeout.
INFO  2025-05-29 17:05:59.051 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FIND_COORDINATOR request with correlation id 580 due to node 0 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 38854ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 17:05:59.149 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:05:59.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=145, memberId='consumer-dev-group-1-e1ce8dac-7bb7-4d26-b3ce-580373fba4f1', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 17:05:59.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:05:59.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:05:59.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 17:05:59.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 17:05:59.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 17:05:59.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 17:05:59.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:05:59.177 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-27305e38-e9f1-4608-9dc3-1b052431a5c4
INFO  2025-05-29 17:05:59.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:05:59.181 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=147, memberId='consumer-dev-group-1-27305e38-e9f1-4608-9dc3-1b052431a5c4', protocol='range'}
INFO  2025-05-29 17:05:59.181 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 147: {consumer-dev-group-1-27305e38-e9f1-4608-9dc3-1b052431a5c4=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 17:05:59.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=147, memberId='consumer-dev-group-1-27305e38-e9f1-4608-9dc3-1b052431a5c4', protocol='range'}
INFO  2025-05-29 17:05:59.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 17:05:59.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 17:05:59.189 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 17:05:59.190 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 17:06:02.263 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:06:14.741 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:06:15.242 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:06:27.519 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:06:28.021 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: mongodb
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: mongodb
	at java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:801)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
WARN  2025-05-29 17:06:33.046 [http-nio-8084-exec-5] n.g.e.SimpleDataFetcherExceptionHandler - Exception while fetching data (/createMsgTemplate) : Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
org.springframework.dao.DataAccessResourceFailureException: Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:97)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy71.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:48)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.lambda$new$4(CustomGraphQLExceptionHandler.java:84)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.lambda$handleException$6(CustomGraphQLExceptionHandler.java:102)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler.handleException(CustomGraphQLExceptionHandler.java:102)
	at graphql.execution.ExecutionStrategy.asyncHandleException(ExecutionStrategy.java:406)
	at graphql.execution.ExecutionStrategy.handleFetchingException(ExecutionStrategy.java:394)
	at graphql.execution.ExecutionStrategy.lambda$fetchField$5(ExecutionStrategy.java:312)
	at java.base/java.util.concurrent.CompletableFuture.uniHandle(CompletableFuture.java:934)
	at java.base/java.util.concurrent.CompletableFuture.uniHandleStage(CompletableFuture.java:950)
	at java.base/java.util.concurrent.CompletableFuture.handle(CompletableFuture.java:2340)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:309)
	at graphql.execution.ExecutionStrategy.fetchField(ExecutionStrategy.java:243)
	at graphql.execution.ExecutionStrategy.resolveFieldWithInfo(ExecutionStrategy.java:214)
	at graphql.execution.ExecutionStrategy.resolveField(ExecutionStrategy.java:186)
	at graphql.execution.AsyncSerialExecutionStrategy.lambda$execute$1(AsyncSerialExecutionStrategy.java:56)
	at graphql.execution.Async.eachSequentiallyImpl(Async.java:162)
	at graphql.execution.Async.eachSequentially(Async.java:151)
	at graphql.execution.AsyncSerialExecutionStrategy.execute(AsyncSerialExecutionStrategy.java:51)
	at graphql.execution.Execution.executeOperation(Execution.java:162)
	at graphql.execution.Execution.execute(Execution.java:104)
	at graphql.GraphQL.execute(GraphQL.java:568)
	at graphql.GraphQL.lambda$parseValidateAndExecute$13(GraphQL.java:487)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.parseValidateAndExecute(GraphQL.java:482)
	at graphql.GraphQL.lambda$executeAsync$9(GraphQL.java:440)
	at java.base/java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:1187)
	at java.base/java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2309)
	at graphql.GraphQL.executeAsync(GraphQL.java:428)
	at io.leangen.graphql.spqr.spring.web.HttpExecutor.lambda$execute$0(HttpExecutor.java:33)
	at reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:47)
	at reactor.core.publisher.Mono.subscribe(Mono.java:4576)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler$DeferredResultSubscriber.connect(ReactiveTypeHandler.java:516)
	at org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler.handleValue(ReactiveTypeHandler.java:185)
	at org.springframework.web.servlet.mvc.method.annotation.ResponseBodyEmitterReturnValueHandler.handleReturnValue(ResponseBodyEmitterReturnValueHandler.java:210)
	at org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite.handleReturnValue(HandlerMethodReturnValueHandlerComposite.java:78)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:136)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:986)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:891)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1089)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:979)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1014)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:914)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:885)
	at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:658)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:195)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:51)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:164)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:140)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:167)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:90)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:483)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:116)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:93)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:344)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:398)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1740)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1189)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:658)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:63)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoTimeoutException: Timed out while waiting for a server that matches ReadPreferenceServerSelector{readPreference=primary}. Client view of cluster state is {type=UNKNOWN, servers=[{address=mongodb:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketException: mongodb}, caused by {java.net.UnknownHostException: mongodb}}]
	at com.mongodb.internal.connection.BaseCluster.logAndThrowTimeoutException(BaseCluster.java:427)
	at com.mongodb.internal.connection.BaseCluster.lambda$selectServer$0(BaseCluster.java:154)
	at com.mongodb.internal.time.Timeout.lambda$onExistsAndExpired$16(Timeout.java:236)
	at com.mongodb.internal.time.Timeout.lambda$run$10(Timeout.java:201)
	at com.mongodb.internal.time.TimePoint.checkedCall(TimePoint.java:99)
	at com.mongodb.internal.time.Timeout.call(Timeout.java:174)
	at com.mongodb.internal.time.Timeout.run(Timeout.java:194)
	at com.mongodb.internal.time.Timeout.onExistsAndExpired(Timeout.java:233)
	at com.mongodb.internal.time.Timeout.onExpired(Timeout.java:226)
	at com.mongodb.internal.connection.BaseCluster.selectServer(BaseCluster.java:153)
	at com.mongodb.internal.connection.SingleServerCluster.selectServer(SingleServerCluster.java:47)
	at com.mongodb.internal.binding.ClusterBinding.getReadConnectionSource(ClusterBinding.java:82)
	at com.mongodb.client.internal.ClientSessionBinding.getConnectionSource(ClientSessionBinding.java:108)
	at com.mongodb.client.internal.ClientSessionBinding.getReadConnectionSource(ClientSessionBinding.java:88)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:148)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 109 common frames omitted
INFO  2025-05-29 17:06:45.774 [cluster-ClusterId{value='683844b844c163063a0c8b3b', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server mongodb:27017
com.mongodb.MongoSocketException: No such host is known (mongodb)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:75)
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:100)
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:79)
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:233)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:219)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.UnknownHostException: No such host is known (mongodb)
	at java.base/java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:934)
	at java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)
	at java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:852)
	at java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1385)
	at java.base/java.net.InetAddress.getAllByName(InetAddress.java:1306)
	at com.mongodb.internal.connection.DefaultInetAddressResolver.lookupByName(DefaultInetAddressResolver.java:34)
	at com.mongodb.internal.connection.ServerAddressHelper.getSocketAddresses(ServerAddressHelper.java:71)
	... 5 common frames omitted
INFO  2025-05-29 17:18:54.189 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 17:18:54.189 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:18:54.189 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-29 17:18:54.233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:18:54.233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-29 17:18:54.234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:18:54.345 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null)
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=147, memberId='consumer-dev-group-1-27305e38-e9f1-4608-9dc3-1b052431a5c4', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-29 17:18:54.363 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 17:18:54.364 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:18:54.374 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-1f245108-958e-40f9-8957-4274f01a7ec7
INFO  2025-05-29 17:18:54.374 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-29 17:18:54.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=149, memberId='consumer-dev-group-1-1f245108-958e-40f9-8957-4274f01a7ec7', protocol='range'}
INFO  2025-05-29 17:18:54.379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 149: {consumer-dev-group-1-1f245108-958e-40f9-8957-4274f01a7ec7=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-29 17:18:54.394 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=149, memberId='consumer-dev-group-1-1f245108-958e-40f9-8957-4274f01a7ec7', protocol='range'}
INFO  2025-05-29 17:18:54.395 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-29 17:18:54.395 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-29 17:18:54.400 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=38, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.103.114:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-29 17:18:54.400 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-29 21:45:41.035 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
INFO  2025-05-29 21:45:41.035 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 2028 due to node 0 being disconnected (elapsed time since creation: 15768892ms, elapsed time since send: 15768892ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-29 21:45:41.036 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 2147483647 disconnected.
INFO  2025-05-29 21:45:41.036 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=1272) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:45:41.036 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 192.168.103.114:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-29 21:45:50.961 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to socket connection setup timeout. The timeout value is 9783 ms.
INFO  2025-05-29 21:45:50.962 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:46:12.349 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to socket connection setup timeout. The timeout value is 21213 ms.
INFO  2025-05-29 21:46:12.350 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:46:33.742 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 21:46:33.742 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 21:46:33.742 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:46:55.641 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 21:46:55.641 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 21:46:55.641 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:47:17.739 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 0 disconnected.
WARN  2025-05-29 21:47:17.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Connection to node 0 (/192.168.103.114:9092) could not be established. Node may not be available.
INFO  2025-05-29 21:47:17.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=798411461, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-29 21:47:25.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-29 21:47:25.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-29 21:47:25.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 21:47:25.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-29 21:47:25.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-29 21:47:25.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-29 21:47:25.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
