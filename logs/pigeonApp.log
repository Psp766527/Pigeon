INFO  2025-06-20 00:01:14.279 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
WARN  2025-06-20 00:03:50.270 [http-nio-8085-exec-5] notprivacysafe.graphql.GraphQL - Query did not validate : 'mutation CreateStaff {
    createStaff(
        newStaff: {
            email: "kushwahpradeep531@gmail.com"
            isActive: true 
            name: "Pradeep"
            password: "0928Cs161036###"
            userName: "pradeepKushwah766527@"
        }
    ) {
        createdOn
        email
        id
        isActive
        markInActiveOn
        name
        password
        updatedOn
        userName
    }
}
'
INFO  2025-06-20 00:06:14.333 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:11:14.345 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:16:14.351 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
WARN  2025-06-20 00:17:47.776 [http-nio-8085-exec-9] notprivacysafe.graphql.GraphQL - Query did not validate : 'mutation CreateStaff {
    createStaff(
        newStaff: {
            email: "kushwahpradeep531@gmail.com"
            isActive: true 
            name: "Pradeep"
            password: "0928Cs161036###"
            userName: "pradeepKushwah766527@"
        }
    ) {
        createdOn
        email
        id
        isActive
        markInActiveOn
        name
        password
        updatedOn
        userName
    }
}
'
INFO  2025-06-20 00:19:03.394 [SpringApplicationShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application PIGEON with eureka with status DOWN
INFO  2025-06-20 00:19:03.395 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750358943395, current=DOWN, previous=UP]
INFO  2025-06-20 00:19:03.395 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 00:19:03.428 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 00:19:03.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Member consumer-dev-group-5-d68257a5-ecf9-477d-ad44-f993c1bbac51 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 00:19:03.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Member consumer-dev-group-4-bf0c3d2c-8f38-4fe6-b007-7aa4921f6ee8 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 00:19:03.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-9c8f416a-7b7f-490f-a5a1-6cc1da3ed0bb sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 00:19:03.443 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-3f6ffe2c-0abe-484e-9c32-18466d21c540 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 00:19:03.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-06-20 00:19:03.448 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-7a99f86c-64fa-416b-9b47-f9a9ab6761ad sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 00:19:03.450 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 00:19:03.451 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.451 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.451 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.461 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 00:19:03.697 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 00:19:03.697 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 00:19:03.697 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 00:19:03.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 00:19:03.724 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-06-20 00:19:03.725 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-5 unregistered
INFO  2025-06-20 00:19:03.725 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-06-20 00:19:03.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 00:19:03.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 00:19:03.728 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 00:19:03.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 00:19:03.743 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 00:19:03.743 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 00:19:03.743 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 00:19:03.750 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-06-20 00:19:03.750 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 00:19:04.006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 00:19:04.006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 00:19:04.006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 00:19:04.006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 00:19:04.015 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-06-20 00:19:04.016 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 00:19:04.031 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-06-20 00:19:04.470 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-06-20 00:19:04.537 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
INFO  2025-06-20 00:19:07.543 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Unregistering ...
INFO  2025-06-20 00:19:07.559 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - deregister  status: 200
INFO  2025-06-20 00:19:07.560 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
INFO  2025-06-20 00:19:14.771 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-06-20 00:19:14.887 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 33504 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-06-20 00:19:14.890 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-06-20 00:19:15.004 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-06-20 00:19:15.005 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-06-20 00:19:17.183 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-06-20 00:19:17.454 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 253 ms. Found 1 MongoDB repository interface.
INFO  2025-06-20 00:19:18.008 [restartedMain] o.s.cloud.context.scope.GenericScope - BeanFactory id=d381efcd-872a-32b6-a23e-191b3d26bdfb
WARN  2025-06-20 00:19:18.199 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.208 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.220 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.225 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.233 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.237 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.313 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.328 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.332 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.334 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$817/0x00000169a24a8588] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.336 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.350 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.361 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.366 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.370 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.374 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.388 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.394 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.396 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 00:19:18.692 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6b9675fb, com.mongodb.Jep395RecordCodecProvider@1715990b, com.mongodb.KotlinCodecProvider@128535fa]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-06-20 00:19:18.698 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.710 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.714 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 00:19:18.724 [cluster-ClusterId{value='68545bae4b4c75f1b9270b14', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=45964000, minRoundTripTimeNanos=0}
WARN  2025-06-20 00:19:18.852 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 00:19:18.857 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:18.906 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.095 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.146 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 00:19:19.247 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.348 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.584 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.586 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.595 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.603 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.612 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.631 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.634 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.655 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.729 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.736 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.757 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.759 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.766 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 00:19:19.767 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-06-20 00:19:20.450 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8085 (http)
INFO  2025-06-20 00:19:20.481 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 00:19:20.484 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-06-20 00:19:20.487 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-06-20 00:19:20.704 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-06-20 00:19:20.709 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5662 ms
INFO  2025-06-20 00:19:20.856 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-06-20 00:19:22.538 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-06-20 00:19:24.829 [restartedMain] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
WARN  2025-06-20 00:19:24.980 [restartedMain] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
INFO  2025-06-20 00:19:25.094 [restartedMain] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
INFO  2025-06-20 00:19:25.138 [restartedMain] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
INFO  2025-06-20 00:19:25.148 [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:19:25.166 [restartedMain] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Application version is -1: true
INFO  2025-06-20 00:19:25.167 [restartedMain] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 00:19:25.859 [restartedMain] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 00:19:25.863 [restartedMain] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
INFO  2025-06-20 00:19:25.871 [restartedMain] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
INFO  2025-06-20 00:19:25.874 [restartedMain] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1750358965872 with initial instances count: 2
INFO  2025-06-20 00:19:25.878 [restartedMain] o.s.c.n.e.s.EurekaServiceRegistry - Registering application PIGEON with eureka with status UP
INFO  2025-06-20 00:19:25.879 [restartedMain] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750358965879, current=UP, previous=STARTING]
INFO  2025-06-20 00:19:25.881 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 00:19:25.881 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 00:19:25.925 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8085 (http) with context path '/'
INFO  2025-06-20 00:19:25.927 [restartedMain] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8085
INFO  2025-06-20 00:19:25.959 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 00:19:26.283 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 00:19:26.359 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 00:19:26.607 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 00:19:26.610 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 00:19:26.611 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 00:19:26.611 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750358966608
INFO  2025-06-20 00:19:26.616 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 00:19:26.628 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 00:19:26.628 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 00:19:26.638 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 00:19:26.639 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 00:19:26.639 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 00:19:26.639 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750358966639
INFO  2025-06-20 00:19:26.639 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 00:19:26.641 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 00:19:26.642 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 00:19:26.650 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 00:19:26.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 00:19:26.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 00:19:26.651 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750358966651
INFO  2025-06-20 00:19:26.651 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 00:19:26.653 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 00:19:26.654 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 00:19:26.661 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 00:19:26.661 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 00:19:26.663 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 00:19:26.663 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750358966661
INFO  2025-06-20 00:19:26.663 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 00:19:26.665 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 00:19:26.666 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 00:19:26.678 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 00:19:26.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 00:19:26.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 00:19:26.678 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750358966678
INFO  2025-06-20 00:19:26.679 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 00:19:26.704 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 13.305 seconds (process running for 16.51)
INFO  2025-06-20 00:19:28.763 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 00:19:28.843 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 00:19:28.843 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 00:19:28.843 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 00:19:29.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 00:19:29.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 00:19:29.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 00:19:29.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.187 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.188 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 00:19:29.192 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.504 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 00:19:29.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-3dffc416-a226-4845-86b4-2f1a6f891248
INFO  2025-06-20 00:19:29.812 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-acd39f73-a1f7-44f7-b5b0-ba0ca97c5581
INFO  2025-06-20 00:19:29.838 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.854 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-ab20654f-f3e9-4155-bcb8-463a969fd1ce
INFO  2025-06-20 00:19:29.856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 00:19:29.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:29.950 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-456cbb6c-3110-4651-b7da-cffede778b4e
INFO  2025-06-20 00:19:29.950 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:30.150 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-5-d9f5b9d5-3ce3-466f-8654-46a97b75b2a2
INFO  2025-06-20 00:19:30.151 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 00:19:33.352 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-3-3dffc416-a226-4845-86b4-2f1a6f891248', protocol='range'}
INFO  2025-06-20 00:19:33.352 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-4-456cbb6c-3110-4651-b7da-cffede778b4e', protocol='range'}
INFO  2025-06-20 00:19:33.352 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-1-ab20654f-f3e9-4155-bcb8-463a969fd1ce', protocol='range'}
INFO  2025-06-20 00:19:33.352 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-2-acd39f73-a1f7-44f7-b5b0-ba0ca97c5581', protocol='range'}
INFO  2025-06-20 00:19:33.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-5-d9f5b9d5-3ce3-466f-8654-46a97b75b2a2', protocol='range'}
INFO  2025-06-20 00:19:33.370 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 15: {consumer-dev-group-1-ab20654f-f3e9-4155-bcb8-463a969fd1ce=Assignment(partitions=[pigeon-dev-events-0]), consumer-dev-group-4-456cbb6c-3110-4651-b7da-cffede778b4e=Assignment(partitions=[]), consumer-dev-group-3-3dffc416-a226-4845-86b4-2f1a6f891248=Assignment(partitions=[]), consumer-dev-group-2-acd39f73-a1f7-44f7-b5b0-ba0ca97c5581=Assignment(partitions=[]), consumer-dev-group-5-d9f5b9d5-3ce3-466f-8654-46a97b75b2a2=Assignment(partitions=[])}
INFO  2025-06-20 00:19:33.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-1-ab20654f-f3e9-4155-bcb8-463a969fd1ce', protocol='range'}
INFO  2025-06-20 00:19:33.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-5-d9f5b9d5-3ce3-466f-8654-46a97b75b2a2', protocol='range'}
INFO  2025-06-20 00:19:33.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-2-acd39f73-a1f7-44f7-b5b0-ba0ca97c5581', protocol='range'}
INFO  2025-06-20 00:19:33.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-4-456cbb6c-3110-4651-b7da-cffede778b4e', protocol='range'}
INFO  2025-06-20 00:19:33.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 00:19:33.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 00:19:33.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 00:19:33.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-06-20 00:19:33.479 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 00:19:33.479 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 00:19:33.479 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 00:19:33.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 00:19:33.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 00:19:33.481 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 00:19:33.485 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-3-3dffc416-a226-4845-86b4-2f1a6f891248', protocol='range'}
INFO  2025-06-20 00:19:33.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 00:19:33.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 00:19:33.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 00:19:33.489 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-06-20 00:19:33.562 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:30093 (id: 1 rack: null)], epoch=2}}
INFO  2025-06-20 00:19:33.566 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-06-20 00:19:48.321 [http-nio-8085-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-06-20 00:19:48.322 [http-nio-8085-exec-1] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-06-20 00:19:48.325 [http-nio-8085-exec-1] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-06-20 00:24:25.180 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:29:25.183 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:34:25.192 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:39:25.197 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:44:25.209 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:49:25.212 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:54:25.227 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 00:59:25.229 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 01:04:25.239 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 01:09:25.247 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 01:10:55.364 [SpringApplicationShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application PIGEON with eureka with status DOWN
INFO  2025-06-20 01:10:55.364 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750362055364, current=DOWN, previous=UP]
INFO  2025-06-20 01:10:55.365 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 01:10:55.390 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 01:10:55.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Member consumer-dev-group-4-456cbb6c-3110-4651-b7da-cffede778b4e sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:10:55.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Member consumer-dev-group-5-d9f5b9d5-3ce3-466f-8654-46a97b75b2a2 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:10:55.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-3dffc416-a226-4845-86b4-2f1a6f891248 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:10:55.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-acd39f73-a1f7-44f7-b5b0-ba0ca97c5581 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:10:55.408 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-06-20 01:10:55.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:10:55.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:10:55.413 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-ab20654f-f3e9-4155-bcb8-463a969fd1ce sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:10:55.413 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.414 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.414 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:10:55.419 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.419 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.421 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.421 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:10:55.542 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:10:55.543 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:10:55.543 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:10:55.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:10:55.547 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:10:55.548 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:10:55.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:10:55.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:10:55.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-06-20 01:10:55.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-06-20 01:10:55.563 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:10:55.573 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:10:55.584 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:10:55.584 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:10:55.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:10:55.585 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:10:55.591 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-5 unregistered
INFO  2025-06-20 01:10:55.591 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:10:55.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:10:55.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:10:55.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:10:55.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:10:55.714 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-06-20 01:10:55.714 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:10:55.937 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:10:55.938 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:10:55.938 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:10:55.938 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:10:55.944 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-06-20 01:10:55.944 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:10:55.952 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-06-20 01:10:56.286 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-06-20 01:10:56.328 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
INFO  2025-06-20 01:10:59.330 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Unregistering ...
WARN  2025-06-20 01:10:59.331 [DiscoveryClient-%d] c.n.discovery.TimedSupervisorTask - task supervisor shutting down, can't accept the task
INFO  2025-06-20 01:10:59.339 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - deregister  status: 200
INFO  2025-06-20 01:10:59.340 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
INFO  2025-06-20 01:11:13.575 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-06-20 01:11:13.661 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 21252 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-06-20 01:11:13.663 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-06-20 01:11:13.745 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-06-20 01:11:13.745 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-06-20 01:11:16.405 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-06-20 01:11:16.716 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 296 ms. Found 1 MongoDB repository interface.
INFO  2025-06-20 01:11:17.344 [restartedMain] o.s.cloud.context.scope.GenericScope - BeanFactory id=d381efcd-872a-32b6-a23e-191b3d26bdfb
WARN  2025-06-20 01:11:17.486 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.502 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.510 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.514 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.519 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.522 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.601 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.617 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.621 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.623 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$817/0x00000209e34a5358] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.625 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.638 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.650 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.657 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.663 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.666 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.676 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.679 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:17.681 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 01:11:17.987 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@3be207f, com.mongodb.Jep395RecordCodecProvider@13eb6aa, com.mongodb.KotlinCodecProvider@31640fd3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-06-20 01:11:17.991 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.002 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.005 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 01:11:18.008 [cluster-ClusterId{value='685467dd94d7af6422db9f43', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=35853900, minRoundTripTimeNanos=0}
WARN  2025-06-20 01:11:18.158 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 01:11:18.164 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.185 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.438 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.459 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 01:11:18.521 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.579 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.803 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.805 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.813 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.820 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.827 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.849 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.853 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.869 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.916 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.923 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.940 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.941 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.948 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:18.949 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-06-20 01:11:19.708 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8085 (http)
INFO  2025-06-20 01:11:19.737 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 01:11:19.740 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-06-20 01:11:19.741 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-06-20 01:11:19.934 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-06-20 01:11:19.936 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6156 ms
INFO  2025-06-20 01:11:20.171 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-06-20 01:11:21.921 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-06-20 01:11:23.546 [restartedMain] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
WARN  2025-06-20 01:11:23.614 [restartedMain] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
INFO  2025-06-20 01:11:23.741 [restartedMain] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
INFO  2025-06-20 01:11:23.804 [restartedMain] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
INFO  2025-06-20 01:11:23.817 [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 01:11:23.840 [restartedMain] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 01:11:23.840 [restartedMain] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 01:11:23.840 [restartedMain] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 01:11:23.840 [restartedMain] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 01:11:23.840 [restartedMain] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 01:11:23.841 [restartedMain] c.netflix.discovery.DiscoveryClient - Application version is -1: true
INFO  2025-06-20 01:11:23.841 [restartedMain] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 01:11:24.649 [restartedMain] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 01:11:24.653 [restartedMain] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
INFO  2025-06-20 01:11:24.657 [restartedMain] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
INFO  2025-06-20 01:11:24.660 [restartedMain] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1750362084659 with initial instances count: 1
INFO  2025-06-20 01:11:24.664 [restartedMain] o.s.c.n.e.s.EurekaServiceRegistry - Registering application PIGEON with eureka with status UP
INFO  2025-06-20 01:11:24.665 [restartedMain] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750362084665, current=UP, previous=STARTING]
INFO  2025-06-20 01:11:24.670 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 01:11:24.709 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8085 (http) with context path '/'
INFO  2025-06-20 01:11:24.711 [restartedMain] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8085
INFO  2025-06-20 01:11:24.747 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 01:11:25.124 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:25.246 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:25.584 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:25.588 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:25.589 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:25.589 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362085584
INFO  2025-06-20 01:11:25.597 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:25.616 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:25.617 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:25.636 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:25.637 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:25.637 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:25.637 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362085637
INFO  2025-06-20 01:11:25.638 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:25.656 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:25.657 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:25.678 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:25.679 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:25.679 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:25.679 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362085679
INFO  2025-06-20 01:11:25.680 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:25.685 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:25.686 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:25.705 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:25.707 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:25.707 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:25.708 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362085707
INFO  2025-06-20 01:11:25.709 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:25.712 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:25.713 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:25.725 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:25.726 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:25.726 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:25.726 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362085726
INFO  2025-06-20 01:11:25.726 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:25.754 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 13.452 seconds (process running for 23.395)
INFO  2025-06-20 01:11:25.760 [SpringApplicationShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application PIGEON with eureka with status DOWN
INFO  2025-06-20 01:11:25.761 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750362085761, current=DOWN, previous=UP]
INFO  2025-06-20 01:11:25.766 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 01:11:25.790 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 01:11:27.168 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.168 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.169 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.170 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:11:27.168 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.172 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:11:27.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.173 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.174 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:11:27.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:11:27.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:11:27.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:11:27.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:11:27.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:11:27.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:11:27.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:11:27.185 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:11:27.194 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:11:27.195 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:11:27.196 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:11:27.198 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:11:27.209 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-06-20 01:11:27.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:11:27.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-06-20 01:11:27.225 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:11:27.219 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-5 unregistered
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:11:27.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:11:27.228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:11:27.229 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:11:27.228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:11:27.238 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-06-20 01:11:27.239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:11:27.240 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-06-20 01:11:27.240 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:11:27.243 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-06-20 01:11:28.175 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-06-20 01:11:28.203 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
INFO  2025-06-20 01:11:33.818 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-06-20 01:11:33.947 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 2768 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-06-20 01:11:33.949 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-06-20 01:11:34.065 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-06-20 01:11:34.065 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-06-20 01:11:35.638 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-06-20 01:11:35.831 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 182 ms. Found 1 MongoDB repository interface.
INFO  2025-06-20 01:11:36.686 [restartedMain] o.s.cloud.context.scope.GenericScope - BeanFactory id=d381efcd-872a-32b6-a23e-191b3d26bdfb
WARN  2025-06-20 01:11:36.853 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.862 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.869 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.873 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.878 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.880 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.973 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.987 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.990 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.991 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$817/0x000001fd5e4a7a78] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:36.993 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.004 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.012 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.015 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.020 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.029 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.035 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.039 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.041 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 01:11:37.405 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@60ae3eb5, com.mongodb.Jep395RecordCodecProvider@5bc83e6a, com.mongodb.KotlinCodecProvider@60d9fa0c]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-06-20 01:11:37.408 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.425 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.428 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 01:11:37.449 [cluster-ClusterId{value='685467f1f0b4739bc2dfb44b', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=56816400, minRoundTripTimeNanos=0}
WARN  2025-06-20 01:11:37.611 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 01:11:37.616 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.654 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.783 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.800 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 01:11:37.855 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:37.908 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.045 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.046 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.051 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.058 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.066 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.084 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.088 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.105 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.139 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.144 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.158 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.160 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.172 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 01:11:38.173 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-06-20 01:11:39.144 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8085 (http)
INFO  2025-06-20 01:11:39.174 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 01:11:39.181 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-06-20 01:11:39.183 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-06-20 01:11:39.399 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-06-20 01:11:39.420 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5303 ms
INFO  2025-06-20 01:11:39.716 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-06-20 01:11:41.290 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-06-20 01:11:43.132 [restartedMain] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
WARN  2025-06-20 01:11:43.229 [restartedMain] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
INFO  2025-06-20 01:11:43.324 [restartedMain] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
INFO  2025-06-20 01:11:43.373 [restartedMain] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
INFO  2025-06-20 01:11:43.380 [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 01:11:43.397 [restartedMain] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 01:11:43.398 [restartedMain] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 01:11:43.401 [restartedMain] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 01:11:43.401 [restartedMain] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 01:11:43.402 [restartedMain] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 01:11:43.402 [restartedMain] c.netflix.discovery.DiscoveryClient - Application version is -1: true
INFO  2025-06-20 01:11:43.402 [restartedMain] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 01:11:44.255 [restartedMain] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 01:11:44.260 [restartedMain] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
INFO  2025-06-20 01:11:44.265 [restartedMain] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
INFO  2025-06-20 01:11:44.270 [restartedMain] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1750362104267 with initial instances count: 2
INFO  2025-06-20 01:11:44.276 [restartedMain] o.s.c.n.e.s.EurekaServiceRegistry - Registering application PIGEON with eureka with status UP
INFO  2025-06-20 01:11:44.276 [restartedMain] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750362104276, current=UP, previous=STARTING]
INFO  2025-06-20 01:11:44.281 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 01:11:44.283 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 01:11:44.338 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8085 (http) with context path '/'
INFO  2025-06-20 01:11:44.340 [restartedMain] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8085
INFO  2025-06-20 01:11:44.362 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 01:11:44.718 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:44.806 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:44.986 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:44.990 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:44.990 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:44.990 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362104987
INFO  2025-06-20 01:11:44.996 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:45.010 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:45.011 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:45.023 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:45.024 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:45.024 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:45.024 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362105024
INFO  2025-06-20 01:11:45.025 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:45.028 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:45.029 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:45.040 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:45.041 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:45.041 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:45.041 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362105041
INFO  2025-06-20 01:11:45.041 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:45.045 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:45.046 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:45.057 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:45.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:45.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:45.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362105057
INFO  2025-06-20 01:11:45.058 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:45.061 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 01:11:45.062 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 01:11:45.078 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 01:11:45.078 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 01:11:45.078 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 01:11:45.078 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750362105078
INFO  2025-06-20 01:11:45.079 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 01:11:45.106 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 12.743 seconds (process running for 14.64)
INFO  2025-06-20 01:11:45.964 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 01:11:45.964 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 01:11:45.964 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 01:11:45.965 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 01:11:45.977 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 01:11:45.978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 01:11:45.984 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.034 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 01:11:46.034 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 01:11:46.036 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.037 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.037 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 01:11:46.039 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-5-637faedf-ebeb-4c21-868a-fe93daa3ef14
INFO  2025-06-20 01:11:46.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-ce7c40a4-0c79-42ad-ab02-ebb225cc7d99
INFO  2025-06-20 01:11:46.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.063 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-88f519d0-6e14-46f8-a336-baa2aeb8f63c
INFO  2025-06-20 01:11:46.064 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 01:11:46.069 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.069 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-45c6d637-8609-4ee6-826d-8d930dd1d959
INFO  2025-06-20 01:11:46.070 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:46.080 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-84c8a86f-1479-403d-8f3b-680343d695d8
INFO  2025-06-20 01:11:46.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 01:11:49.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-3-88f519d0-6e14-46f8-a336-baa2aeb8f63c', protocol='range'}
INFO  2025-06-20 01:11:49.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-1-84c8a86f-1479-403d-8f3b-680343d695d8', protocol='range'}
INFO  2025-06-20 01:11:49.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-4-ce7c40a4-0c79-42ad-ab02-ebb225cc7d99', protocol='range'}
INFO  2025-06-20 01:11:49.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-2-45c6d637-8609-4ee6-826d-8d930dd1d959', protocol='range'}
INFO  2025-06-20 01:11:49.215 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-5-637faedf-ebeb-4c21-868a-fe93daa3ef14', protocol='range'}
INFO  2025-06-20 01:11:49.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Finished assignment for group at generation 17: {consumer-dev-group-4-ce7c40a4-0c79-42ad-ab02-ebb225cc7d99=Assignment(partitions=[]), consumer-dev-group-2-45c6d637-8609-4ee6-826d-8d930dd1d959=Assignment(partitions=[]), consumer-dev-group-1-84c8a86f-1479-403d-8f3b-680343d695d8=Assignment(partitions=[pigeon-dev-events-0]), consumer-dev-group-3-88f519d0-6e14-46f8-a336-baa2aeb8f63c=Assignment(partitions=[]), consumer-dev-group-5-637faedf-ebeb-4c21-868a-fe93daa3ef14=Assignment(partitions=[])}
INFO  2025-06-20 01:11:49.248 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-5-637faedf-ebeb-4c21-868a-fe93daa3ef14', protocol='range'}
INFO  2025-06-20 01:11:49.248 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-4-ce7c40a4-0c79-42ad-ab02-ebb225cc7d99', protocol='range'}
INFO  2025-06-20 01:11:49.248 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-2-45c6d637-8609-4ee6-826d-8d930dd1d959', protocol='range'}
INFO  2025-06-20 01:11:49.249 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 01:11:49.249 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 01:11:49.249 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 01:11:49.250 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 01:11:49.250 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 01:11:49.250 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 01:11:49.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-3-88f519d0-6e14-46f8-a336-baa2aeb8f63c', protocol='range'}
INFO  2025-06-20 01:11:49.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-1-84c8a86f-1479-403d-8f3b-680343d695d8', protocol='range'}
INFO  2025-06-20 01:11:49.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 01:11:49.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-06-20 01:11:49.251 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 01:11:49.252 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 01:11:49.252 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 01:11:49.252 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 01:11:49.252 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 01:11:49.255 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-06-20 01:11:49.270 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:30093 (id: 1 rack: null)], epoch=2}}
INFO  2025-06-20 01:11:49.271 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-06-20 01:14:44.443 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:119)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 19 more

INFO  2025-06-20 01:14:44.443 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:174)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:186)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 22 more

WARN  2025-06-20 01:14:44.443 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
WARN  2025-06-20 01:14:44.443 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 01:14:44.478 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:174)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:186)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 23 more

WARN  2025-06-20 01:14:44.479 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 01:14:44.479 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:119)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 20 more

WARN  2025-06-20 01:14:44.479 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 01:14:44.479 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)

ERROR 2025-06-20 01:14:44.479 [DiscoveryClient-HeartbeatExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - was unable to send heartbeat!
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-06-20 01:14:56.716 [SpringApplicationShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application PIGEON with eureka with status DOWN
INFO  2025-06-20 01:14:56.716 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750362296716, current=DOWN, previous=UP]
INFO  2025-06-20 01:14:56.716 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 01:14:56.719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-45c6d637-8609-4ee6-826d-8d930dd1d959 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:14:56.719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-88f519d0-6e14-46f8-a336-baa2aeb8f63c sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:14:56.719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Member consumer-dev-group-5-637faedf-ebeb-4c21-868a-fe93daa3ef14 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:14:56.719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Member consumer-dev-group-4-ce7c40a4-0c79-42ad-ab02-ebb225cc7d99 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:14:56.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:14:56.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-84c8a86f-1479-403d-8f3b-680343d695d8 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 01:14:56.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.721 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.723 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.723 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:14:56.732 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:14:56.737 [DiscoveryClient-InstanceInfoReplicator-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on POST request for "http://localhost:8761/eureka/apps/PIGEON": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://localhost:8761/eureka/apps/PIGEON": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:87)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 22 more

WARN  2025-06-20 01:14:56.738 [DiscoveryClient-InstanceInfoReplicator-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on POST request for "http://localhost:8761/eureka/apps/PIGEON": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
WARN  2025-06-20 01:14:56.738 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration failed Cannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
WARN  2025-06-20 01:14:56.739 [DiscoveryClient-InstanceInfoReplicator-%d] c.n.discovery.InstanceInfoReplicator - There was a problem with the instance info replicator
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:828)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:125)
	at com.netflix.discovery.InstanceInfoReplicator$2.run(InstanceInfoReplicator.java:105)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:14:56.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:14:56.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-5 unregistered
INFO  2025-06-20 01:14:56.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:14:56.743 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-06-20 01:14:56.744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:14:57.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 01:14:57.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 01:14:57.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 01:14:57.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 01:14:57.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-06-20 01:14:57.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 01:14:57.027 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-06-20 01:14:57.429 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-06-20 01:14:57.441 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
INFO  2025-06-20 08:58:20.387 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-06-20 08:58:20.498 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 35160 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-06-20 08:58:20.500 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-06-20 08:58:20.606 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-06-20 08:58:20.607 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-06-20 08:58:23.306 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-06-20 08:58:23.680 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 354 ms. Found 1 MongoDB repository interface.
INFO  2025-06-20 08:58:24.286 [restartedMain] o.s.cloud.context.scope.GenericScope - BeanFactory id=d381efcd-872a-32b6-a23e-191b3d26bdfb
WARN  2025-06-20 08:58:24.419 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.427 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.434 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.447 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.452 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.455 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.555 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.570 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.573 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.574 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$817/0x000001e3534a8588] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.575 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.587 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.595 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.598 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.604 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.607 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.615 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.619 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.621 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 08:58:24.885 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5799fa3c, com.mongodb.Jep395RecordCodecProvider@3f4344c9, com.mongodb.KotlinCodecProvider@40eb5e41]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-06-20 08:58:24.889 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.905 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:24.908 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 08:58:24.921 [cluster-ClusterId{value='6854d55818d53c7e8f1e8d79', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=42101700, minRoundTripTimeNanos=0}
WARN  2025-06-20 08:58:25.076 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 08:58:25.080 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.099 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.329 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.355 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 08:58:25.437 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.559 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.796 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.797 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.804 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.813 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.820 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.836 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.840 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.862 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.912 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.921 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.940 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.942 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.949 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 08:58:25.951 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-06-20 08:58:26.515 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8085 (http)
INFO  2025-06-20 08:58:26.540 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 08:58:26.544 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-06-20 08:58:26.544 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-06-20 08:58:26.689 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-06-20 08:58:26.692 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 6055 ms
INFO  2025-06-20 08:58:26.942 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-06-20 08:58:28.215 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-06-20 08:58:29.477 [restartedMain] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
WARN  2025-06-20 08:58:29.542 [restartedMain] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
INFO  2025-06-20 08:58:29.635 [restartedMain] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
INFO  2025-06-20 08:58:29.679 [restartedMain] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
INFO  2025-06-20 08:58:29.687 [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 08:58:29.704 [restartedMain] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Application version is -1: true
INFO  2025-06-20 08:58:29.705 [restartedMain] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 08:58:30.821 [restartedMain] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 08:58:30.824 [restartedMain] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
INFO  2025-06-20 08:58:30.832 [restartedMain] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
INFO  2025-06-20 08:58:30.854 [restartedMain] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1750390110836 with initial instances count: 0
INFO  2025-06-20 08:58:30.860 [restartedMain] o.s.c.n.e.s.EurekaServiceRegistry - Registering application PIGEON with eureka with status UP
INFO  2025-06-20 08:58:30.861 [restartedMain] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750390110861, current=UP, previous=STARTING]
INFO  2025-06-20 08:58:30.865 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 08:58:30.869 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 08:58:30.948 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8085 (http) with context path '/'
INFO  2025-06-20 08:58:30.950 [restartedMain] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8085
INFO  2025-06-20 08:58:31.251 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 08:58:31.507 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 08:58:31.667 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 08:58:32.006 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 08:58:32.010 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 08:58:32.010 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 08:58:32.010 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750390112006
INFO  2025-06-20 08:58:32.022 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 08:58:32.041 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 08:58:32.042 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 08:58:32.058 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 08:58:32.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 08:58:32.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 08:58:32.058 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750390112058
INFO  2025-06-20 08:58:32.059 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 08:58:32.062 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 08:58:32.062 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 08:58:32.085 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 08:58:32.085 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 08:58:32.085 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 08:58:32.085 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750390112085
INFO  2025-06-20 08:58:32.087 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 08:58:32.090 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 08:58:32.091 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 08:58:32.113 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 08:58:32.113 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 08:58:32.113 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 08:58:32.113 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750390112113
INFO  2025-06-20 08:58:32.114 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 08:58:32.139 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 08:58:32.140 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 08:58:32.168 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 08:58:32.170 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 08:58:32.171 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 08:58:32.171 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750390112170
INFO  2025-06-20 08:58:32.173 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 08:58:32.226 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 13.188 seconds (process running for 23.981)
INFO  2025-06-20 08:58:33.937 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 08:58:33.937 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 08:58:33.937 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 08:58:33.960 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 08:58:33.965 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 08:58:33.971 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:33.987 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 08:58:33.989 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.018 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 08:58:34.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 08:58:34.073 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 08:58:34.076 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 08:58:34.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-5-2856819b-56da-4f16-90aa-980c9d0db0e9
INFO  2025-06-20 08:58:34.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-9cb24a87-020c-4de0-b973-69ed336fba5f
INFO  2025-06-20 08:58:34.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-fc836b2f-7362-491f-b597-df63c20ed772
INFO  2025-06-20 08:58:34.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-99f1eb35-bc69-4226-b73b-690ddce5d63a
INFO  2025-06-20 08:58:34.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:34.132 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-cf3385f0-2c8b-46b2-9584-c85ae6cdd13e
INFO  2025-06-20 08:58:34.132 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 08:58:37.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-5-2856819b-56da-4f16-90aa-980c9d0db0e9', protocol='range'}
INFO  2025-06-20 08:58:37.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-2-99f1eb35-bc69-4226-b73b-690ddce5d63a', protocol='range'}
INFO  2025-06-20 08:58:37.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-4-cf3385f0-2c8b-46b2-9584-c85ae6cdd13e', protocol='range'}
INFO  2025-06-20 08:58:37.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-1-fc836b2f-7362-491f-b597-df63c20ed772', protocol='range'}
INFO  2025-06-20 08:58:37.193 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-3-9cb24a87-020c-4de0-b973-69ed336fba5f', protocol='range'}
INFO  2025-06-20 08:58:37.206 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 19: {consumer-dev-group-4-cf3385f0-2c8b-46b2-9584-c85ae6cdd13e=Assignment(partitions=[]), consumer-dev-group-2-99f1eb35-bc69-4226-b73b-690ddce5d63a=Assignment(partitions=[]), consumer-dev-group-5-2856819b-56da-4f16-90aa-980c9d0db0e9=Assignment(partitions=[]), consumer-dev-group-3-9cb24a87-020c-4de0-b973-69ed336fba5f=Assignment(partitions=[]), consumer-dev-group-1-fc836b2f-7362-491f-b597-df63c20ed772=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-4-cf3385f0-2c8b-46b2-9584-c85ae6cdd13e', protocol='range'}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-5-2856819b-56da-4f16-90aa-980c9d0db0e9', protocol='range'}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-1-fc836b2f-7362-491f-b597-df63c20ed772', protocol='range'}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-2-99f1eb35-bc69-4226-b73b-690ddce5d63a', protocol='range'}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-3-9cb24a87-020c-4de0-b973-69ed336fba5f', protocol='range'}
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 08:58:37.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 08:58:37.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 08:58:37.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 08:58:37.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 08:58:37.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 08:58:37.336 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 08:58:37.340 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 08:58:37.340 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 08:58:37.340 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 08:58:37.340 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 08:58:37.340 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-06-20 08:58:37.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:30093 (id: 1 rack: null)], epoch=2}}
INFO  2025-06-20 08:58:37.364 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-06-20 08:59:00.827 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 08:59:00.829 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 08:59:00.829 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 08:59:00.830 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 08:59:00.830 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 08:59:00.831 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Application version is -1: false
INFO  2025-06-20 08:59:00.831 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 08:59:00.869 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 09:03:29.712 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:08:39.750 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 09:08:39.751 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:39.752 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 09:08:39.821 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 09:08:39.821 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:39.822 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 09:08:39.822 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 09:08:39.823 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:39.824 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 09:08:39.864 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 09:08:39.865 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:39.872 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 09:08:39.995 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 09:08:39.996 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:39.996 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 09:08:40.015 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:40.088 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:43.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:43.104 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:43.160 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:08:43.818 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:11:40.132 [http-nio-8085-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-06-20 09:11:40.132 [http-nio-8085-exec-3] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-06-20 09:11:40.135 [http-nio-8085-exec-3] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-06-20 09:13:06.422 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:18:06.431 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:23:06.442 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:28:06.452 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:33:06.454 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:38:06.468 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:41:12.265 [SpringApplicationShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry - Unregistering application PIGEON with eureka with status DOWN
INFO  2025-06-20 09:41:12.266 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750392672266, current=DOWN, previous=UP]
INFO  2025-06-20 09:41:12.267 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085: registering service...
INFO  2025-06-20 09:41:12.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Member consumer-dev-group-5-2856819b-56da-4f16-90aa-980c9d0db0e9 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 09:41:12.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-99f1eb35-bc69-4226-b73b-690ddce5d63a sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 09:41:12.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Member consumer-dev-group-4-cf3385f0-2c8b-46b2-9584-c85ae6cdd13e sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 09:41:12.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Member consumer-dev-group-3-9cb24a87-020c-4de0-b973-69ed336fba5f sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 09:41:12.282 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 09:41:12.284 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.284 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 09:41:12.283 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-06-20 09:41:12.287 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-fc836b2f-7362-491f-b597-df63c20ed772 sending LeaveGroup request to coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-06-20 09:41:12.288 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.288 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.288 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-06-20 09:41:12.289 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.289 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.290 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-06-20 09:41:12.300 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - registration status: 204
INFO  2025-06-20 09:41:12.355 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 09:41:12.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 09:41:12.369 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-06-20 09:41:12.369 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-06-20 09:41:12.369 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-5 unregistered
INFO  2025-06-20 09:41:12.371 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 09:41:12.371 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 09:41:12.371 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 09:41:12.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 09:41:12.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 09:41:12.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 09:41:12.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 09:41:12.439 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-06-20 09:41:12.440 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-06-20 09:41:12.440 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-06-20 09:41:12.440 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-06-20 09:41:12.444 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-06-20 09:41:12.445 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 09:41:12.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-4 unregistered
INFO  2025-06-20 09:41:12.447 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-06-20 09:41:12.451 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-06-20 09:41:12.733 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-06-20 09:41:12.762 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Shutting down DiscoveryClient ...
INFO  2025-06-20 09:41:15.773 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Unregistering ...
INFO  2025-06-20 09:41:15.795 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/pigeon:8085 - deregister  status: 200
INFO  2025-06-20 09:41:15.796 [SpringApplicationShutdownHook] c.netflix.discovery.DiscoveryClient - Completed shut down of DiscoveryClient
INFO  2025-06-20 09:41:28.139 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-06-20 09:41:28.269 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 23496 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-06-20 09:41:28.272 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-06-20 09:41:28.425 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-06-20 09:41:28.426 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-06-20 09:41:31.059 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-06-20 09:41:31.257 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 187 ms. Found 1 MongoDB repository interface.
INFO  2025-06-20 09:41:31.758 [restartedMain] o.s.cloud.context.scope.GenericScope - BeanFactory id=d381efcd-872a-32b6-a23e-191b3d26bdfb
WARN  2025-06-20 09:41:31.907 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.config.PropertiesBasedNamedQueriesFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:31.917 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo.named-queries#0' of type [org.springframework.data.repository.core.support.PropertiesBasedNamedQueries] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:31.932 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryDependentConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:31.935 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDatabaseFactoryConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:31.940 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:31.942 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration' of type [org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration$MongoClientSettingsConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.054 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoClientSettings' of type [com.mongodb.MongoClientSettings] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.068 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.070 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.071 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$817/0x00000229a44a5358] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.072 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.084 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.data.mongodb-org.springframework.boot.autoconfigure.mongo.MongoProperties' of type [org.springframework.boot.autoconfigure.mongo.MongoProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.094 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.ssl-org.springframework.boot.autoconfigure.ssl.SslProperties' of type [org.springframework.boot.autoconfigure.ssl.SslProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.101 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration' of type [org.springframework.boot.autoconfigure.ssl.SslAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.111 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'fileWatcher' of type [org.springframework.boot.autoconfigure.ssl.FileWatcher] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.117 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslPropertiesSslBundleRegistrar' of type [org.springframework.boot.autoconfigure.ssl.SslPropertiesBundleRegistrar] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.130 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'sslBundleRegistry' of type [org.springframework.boot.ssl.DefaultSslBundleRegistry] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.136 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoConnectionDetails' of type [org.springframework.boot.autoconfigure.mongo.PropertiesMongoConnectionDetails] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.138 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'standardMongoSettingsCustomizer' of type [org.springframework.boot.autoconfigure.mongo.StandardMongoClientSettingsBuilderCustomizer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 09:41:32.556 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6bf8fb50, com.mongodb.Jep395RecordCodecProvider@69436298, com.mongodb.KotlinCodecProvider@27e556e4]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-06-20 09:41:32.559 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongo' of type [com.mongodb.client.internal.MongoClientImpl] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.571 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoDatabaseFactory' of type [org.springframework.data.mongodb.core.SimpleMongoClientDatabaseFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.573 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration' of type [org.springframework.boot.autoconfigure.data.mongo.MongoDataConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
INFO  2025-06-20 09:41:32.585 [cluster-ClusterId{value='6854df742f6545db95351a81', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32563100, minRoundTripTimeNanos=0}
WARN  2025-06-20 09:41:32.701 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 09:41:32.704 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoCustomConversions' of type [org.springframework.data.mongodb.core.convert.MongoCustomConversions] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.721 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoManagedTypes' of type [org.springframework.data.mongodb.MongoManagedTypes] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.819 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoMappingContext' of type [org.springframework.data.mongodb.core.mapping.MongoMappingContext] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:32.836 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-06-20 09:41:32.925 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mappingMongoConverter' of type [org.springframework.data.mongodb.core.convert.MappingMongoConverter] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.007 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'mongoTemplate' of type [org.springframework.data.mongodb.core.MongoTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.164 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.166 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageRepository' of type [jdk.proxy3.$Proxy77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.172 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSourceConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.config.MessageSourceConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.178 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageSource' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.184 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'messageService' of type [com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.199 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPropertiesConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.KafkaPropertiesConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.201 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafka_P_And_C_Config' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.config.Kafka_P_And_C_Config$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.215 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaPigeonProducerFactory' of type [org.springframework.kafka.core.DefaultKafkaProducerFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.248 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaTemplate' of type [org.springframework.kafka.core.KafkaTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.254 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'producerRetryBean' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.ProducerRetryBean$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.266 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'kafkaProducerRetryTemplate' of type [org.springframework.retry.support.RetryTemplate] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.267 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'pigeonKafkaProducerService' of type [com.daimlertrucksasia.it.dsc.pigeon.kafka.service.producer.PigeonKafkaProducerService] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.273 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'customGraphQLExceptionHandler' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.CustomGraphQLExceptionHandler] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected/applied to a currently created BeanPostProcessor [graphQLBeanPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies/advisors. If this bean does not have to be post-processed, declare it with ROLE_INFRASTRUCTURE.
WARN  2025-06-20 09:41:33.275 [restartedMain] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'graphQLConfig' of type [com.daimlertrucksasia.it.dsc.pigeon.exceptions.e.GraphQLConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [graphQLBeanPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
INFO  2025-06-20 09:41:33.737 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8085 (http)
INFO  2025-06-20 09:41:33.757 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 09:41:33.760 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-06-20 09:41:33.760 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-06-20 09:41:33.845 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-06-20 09:41:33.847 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5355 ms
INFO  2025-06-20 09:41:33.950 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-06-20 09:41:35.068 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-06-20 09:41:36.531 [restartedMain] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
WARN  2025-06-20 09:41:36.609 [restartedMain] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
INFO  2025-06-20 09:41:36.684 [restartedMain] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
INFO  2025-06-20 09:41:36.715 [restartedMain] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
INFO  2025-06-20 09:41:36.722 [restartedMain] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:41:36.737 [restartedMain] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 09:41:36.737 [restartedMain] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 09:41:36.737 [restartedMain] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 09:41:36.738 [restartedMain] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 09:41:36.738 [restartedMain] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 09:41:36.738 [restartedMain] c.netflix.discovery.DiscoveryClient - Application version is -1: true
INFO  2025-06-20 09:41:36.738 [restartedMain] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 09:41:37.824 [restartedMain] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 09:41:37.828 [restartedMain] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
INFO  2025-06-20 09:41:37.835 [restartedMain] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
INFO  2025-06-20 09:41:37.838 [restartedMain] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1750392697837 with initial instances count: 1
INFO  2025-06-20 09:41:37.843 [restartedMain] o.s.c.n.e.s.EurekaServiceRegistry - Registering application PIGEON with eureka with status UP
INFO  2025-06-20 09:41:37.844 [restartedMain] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1750392697844, current=UP, previous=STARTING]
INFO  2025-06-20 09:41:37.847 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8085"]
INFO  2025-06-20 09:41:37.847 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085: registering service...
INFO  2025-06-20 09:41:37.883 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8085 (http) with context path '/'
INFO  2025-06-20 09:41:37.885 [restartedMain] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8085
INFO  2025-06-20 09:41:37.909 [DiscoveryClient-InstanceInfoReplicator-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085 - registration status: 204
INFO  2025-06-20 09:41:38.142 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 09:41:38.217 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 09:41:38.400 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 09:41:38.403 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 09:41:38.403 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 09:41:38.403 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750392698400
INFO  2025-06-20 09:41:38.409 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 09:41:38.425 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 09:41:38.426 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 09:41:38.439 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 09:41:38.440 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 09:41:38.440 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 09:41:38.440 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750392698439
INFO  2025-06-20 09:41:38.440 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 09:41:38.443 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 09:41:38.444 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 09:41:38.456 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 09:41:38.456 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 09:41:38.457 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 09:41:38.457 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750392698456
INFO  2025-06-20 09:41:38.457 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 09:41:38.465 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 09:41:38.466 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 09:41:38.474 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 09:41:38.475 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 09:41:38.475 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 09:41:38.475 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750392698475
INFO  2025-06-20 09:41:38.476 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 09:41:38.478 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:31092, 127.0.0.1:31093, 127.0.0.1:31094]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-06-20 09:41:38.479 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-06-20 09:41:38.491 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, max-poll-records, enable-auto-commit, topic, key-deserializer]' were supplied but are not used yet.
INFO  2025-06-20 09:41:38.491 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-06-20 09:41:38.491 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-06-20 09:41:38.491 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1750392698491
INFO  2025-06-20 09:41:38.492 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-06-20 09:41:38.516 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 11.452 seconds (process running for 20.298)
INFO  2025-06-20 09:41:39.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 09:41:39.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 09:41:39.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 09:41:39.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 09:41:39.507 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: bSfJclEtQYGycnBQbm_rzw
INFO  2025-06-20 09:41:39.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:41:39.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:41:39.517 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.517 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.542 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:41:39.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.581 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:41:39.583 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.591 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 09:41:39.593 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-ba0962b3-d77b-4bbd-afda-11944c318b34
INFO  2025-06-20 09:41:39.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-5-c7985446-948a-4b9d-b33f-af8001fdeb79
INFO  2025-06-20 09:41:39.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-4-1f8ec031-8384-46cd-be3c-eb690a310a79
INFO  2025-06-20 09:41:39.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-6743c80c-199b-40c8-abf8-750cd1dd0625
INFO  2025-06-20 09:41:39.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:39.643 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-0e2943e2-9dd6-4501-a900-47d41db38bdc
INFO  2025-06-20 09:41:39.644 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-06-20 09:41:42.659 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-4-1f8ec031-8384-46cd-be3c-eb690a310a79', protocol='range'}
INFO  2025-06-20 09:41:42.659 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-3-6743c80c-199b-40c8-abf8-750cd1dd0625', protocol='range'}
INFO  2025-06-20 09:41:42.659 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-2-0e2943e2-9dd6-4501-a900-47d41db38bdc', protocol='range'}
INFO  2025-06-20 09:41:42.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-1-ba0962b3-d77b-4bbd-afda-11944c318b34', protocol='range'}
INFO  2025-06-20 09:41:42.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-5-c7985446-948a-4b9d-b33f-af8001fdeb79', protocol='range'}
INFO  2025-06-20 09:41:42.670 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 21: {consumer-dev-group-4-1f8ec031-8384-46cd-be3c-eb690a310a79=Assignment(partitions=[]), consumer-dev-group-3-6743c80c-199b-40c8-abf8-750cd1dd0625=Assignment(partitions=[]), consumer-dev-group-2-0e2943e2-9dd6-4501-a900-47d41db38bdc=Assignment(partitions=[]), consumer-dev-group-1-ba0962b3-d77b-4bbd-afda-11944c318b34=Assignment(partitions=[pigeon-dev-events-0]), consumer-dev-group-5-c7985446-948a-4b9d-b33f-af8001fdeb79=Assignment(partitions=[])}
INFO  2025-06-20 09:41:42.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-4-1f8ec031-8384-46cd-be3c-eb690a310a79', protocol='range'}
INFO  2025-06-20 09:41:42.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-1-ba0962b3-d77b-4bbd-afda-11944c318b34', protocol='range'}
INFO  2025-06-20 09:41:42.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-5-c7985446-948a-4b9d-b33f-af8001fdeb79', protocol='range'}
INFO  2025-06-20 09:41:42.698 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-3-6743c80c-199b-40c8-abf8-750cd1dd0625', protocol='range'}
INFO  2025-06-20 09:41:42.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 09:41:42.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 09:41:42.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 09:41:42.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-06-20 09:41:42.700 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 09:41:42.700 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 09:41:42.700 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 09:41:42.702 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 09:41:42.702 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 09:41:42.702 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 09:41:42.703 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-06-20 09:41:42.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-2-0e2943e2-9dd6-4501-a900-47d41db38bdc', protocol='range'}
INFO  2025-06-20 09:41:42.709 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[])
INFO  2025-06-20 09:41:42.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: 
INFO  2025-06-20 09:41:42.710 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: []
INFO  2025-06-20 09:41:42.722 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:30093 (id: 1 rack: null)], epoch=2}}
INFO  2025-06-20 09:41:42.723 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-06-20 09:42:16.569 [http-nio-8085-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-06-20 09:42:16.569 [http-nio-8085-exec-1] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-06-20 09:42:16.573 [http-nio-8085-exec-1] o.s.web.servlet.DispatcherServlet - Completed initialization in 3 ms
INFO  2025-06-20 09:46:36.752 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:51:36.757 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 09:56:36.763 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:01:36.776 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:06:36.778 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:11:36.794 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:12:09.688 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:174)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:186)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 22 more

WARN  2025-06-20 10:12:09.689 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 10:12:09.688 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/} exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:119)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 19 more

WARN  2025-06-20 10:12:09.691 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 10:12:09.713 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:174)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:186)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 23 more

WARN  2025-06-20 10:12:09.715 [DiscoveryClient-CacheRefreshExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/delta": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
INFO  2025-06-20 10:12:09.715 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085 - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1080)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:963)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1473)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1441)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)

INFO  2025-06-20 10:12:09.719 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at org.springframework.web.client.RestTemplate.createResourceAccessException(RestTemplate.java:926)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:906)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:841)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:702)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:119)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.hc.client5.http.HttpHostConnectException: Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:547)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:602)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:633)
	at org.apache.hc.client5.http.impl.io.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:216)
	at org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:490)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:164)
	at org.apache.hc.client5.http.impl.classic.InternalExecRuntime.connectEndpoint(InternalExecRuntime.java:174)
	at org.apache.hc.client5.http.impl.classic.ConnectExec.execute(ConnectExec.java:144)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ProtocolExec.execute(ProtocolExec.java:192)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.ContentCompressionExec.execute(ContentCompressionExec.java:150)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.HttpRequestRetryExec.execute(HttpRequestRetryExec.java:113)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.hc.client5.http.impl.classic.ExecChainElement.execute(ExecChainElement.java:51)
	at org.apache.hc.client5.http.impl.classic.InternalHttpClient.doExecute(InternalHttpClient.java:183)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:87)
	at org.apache.hc.client5.http.impl.classic.CloseableHttpClient.execute(CloseableHttpClient.java:55)
	at org.apache.hc.client5.http.classic.HttpClient.executeOpen(HttpClient.java:183)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:99)
	at org.springframework.http.client.AbstractStreamingClientHttpRequest.executeInternal(AbstractStreamingClientHttpRequest.java:71)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:117)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateTransportClientFactory.lambda$restTemplate$2(RestTemplateTransportClientFactory.java:145)
	at org.springframework.http.client.InterceptingClientHttpRequest$InterceptingRequestExecution.execute(InterceptingClientHttpRequest.java:88)
	at org.springframework.http.client.InterceptingClientHttpRequest.executeInternal(InterceptingClientHttpRequest.java:72)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:81)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:900)
	... 20 more

WARN  2025-06-20 10:12:09.719 [DiscoveryClient-HeartbeatExecutor-%d] c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: I/O error on PUT request for "http://localhost:8761/eureka/apps/PIGEON/Pigeon:8085": Connect to http://localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: getsockopt
ERROR 2025-06-20 10:12:09.720 [DiscoveryClient-HeartbeatExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085 - was unable to send heartbeat!
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:76)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:845)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1402)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
INFO  2025-06-20 10:12:40.364 [DiscoveryClient-HeartbeatExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085 - Re-registering apps/PIGEON
INFO  2025-06-20 10:12:40.364 [DiscoveryClient-HeartbeatExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085: registering service...
INFO  2025-06-20 10:12:40.771 [DiscoveryClient-HeartbeatExecutor-%d] c.netflix.discovery.DiscoveryClient - DiscoveryClient_PIGEON/Pigeon:8085 - registration status: 204
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Disable delta property : false
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Application is null : false
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Application version is -1: false
INFO  2025-06-20 10:13:10.103 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
INFO  2025-06-20 10:13:10.128 [DiscoveryClient-CacheRefreshExecutor-%d] c.netflix.discovery.DiscoveryClient - The response status is 200
INFO  2025-06-20 10:16:36.805 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:21:36.818 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:26:36.819 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:31:36.826 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:36:36.831 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:41:36.835 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:46:36.852 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:51:36.863 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 10:56:36.878 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:01:36.889 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:06:36.893 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:11:36.896 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:16:36.899 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:21:36.911 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:26:36.922 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:30:06.845 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 11:30:06.846 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:06.857 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 11:30:06.912 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 11:30:06.913 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:06.913 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 11:30:06.939 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 11:30:06.940 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:06.940 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 11:30:07.265 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 11:30:07.266 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:07.267 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 11:30:07.642 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 11:30:07.642 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:07.642 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 11:30:11.105 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:11.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:11.355 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:11.360 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:11.699 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:30:11.745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 11:33:32.859 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:38:32.862 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:43:32.873 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:48:32.876 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:53:32.891 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 11:58:32.940 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:03:32.948 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:08:32.951 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:13:32.962 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:18:32.977 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:23:32.993 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:28:32.997 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:33:32.999 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:38:33.010 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:43:33.023 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:48:33.031 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:53:33.041 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 12:58:33.046 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:03:33.055 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:08:33.059 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:13:33.066 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:18:33.076 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:23:33.094 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:28:33.103 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:33:33.113 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:38:33.124 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:43:33.134 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:48:33.140 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:53:33.157 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 13:58:33.167 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:03:33.182 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:08:33.205 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:13:33.219 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:18:33.232 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:23:33.238 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:28:33.250 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:33:33.254 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:38:33.261 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:43:33.277 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:48:33.294 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:53:33.301 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 14:58:33.318 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:03:33.326 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:08:33.330 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:13:33.334 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:18:33.340 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:23:33.349 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:28:33.359 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:33:33.360 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:38:33.362 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:43:33.377 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:48:33.389 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:54:12.103 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 15:59:12.110 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:04:12.120 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:09:12.124 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:14:12.125 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:19:12.133 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:24:12.141 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:29:12.142 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:34:12.155 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:39:12.156 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:44:12.161 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:49:12.174 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:54:12.185 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 16:59:12.191 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 17:04:12.202 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 17:09:12.205 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 17:14:12.207 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 17:19:12.217 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
INFO  2025-06-20 20:19:13.774 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 20:19:13.776 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 20:19:13.776 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:13.774 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 20:19:13.800 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 20:19:13.827 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 20:19:41.970 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.101 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.164 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.176 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.177 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.178 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.183 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.183 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.209 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.213 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.607 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 20:19:42.608 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:46.978 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 21:38:47.161 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 21:38:47.162 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:47.162 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 21:38:48.194 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 21:38:48.194 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:48.194 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 21:38:48.196 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-06-20 21:38:48.197 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-06-20 21:38:48.197 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Requesting disconnect from last known coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:48.197 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-06-20 21:38:48.252 [cluster-ClusterId{value='6854df742f6545db95351a81', description='null'}-localhost:27017] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-06-20 21:38:49.286 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:49.553 [cluster-ClusterId{value='6854df742f6545db95351a81', description='null'}-localhost:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=514642500, minRoundTripTimeNanos=0}
INFO  2025-06-20 21:38:49.738 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:50.503 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:53.310 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:53.316 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:53.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-4, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:38:53.352 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-5, groupId=dev-group] Discovered group coordinator 127.0.0.1:30092 (id: 2147483647 rack: null)
INFO  2025-06-20 21:39:25.434 [AsyncResolver-bootstrap-executor-%d] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
