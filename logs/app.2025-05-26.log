INFO  2025-05-26 10:12:01.908 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 10:12:02.028 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24140 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 10:12:02.031 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 10:12:02.223 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 10:12:02.224 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 10:12:02.326 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 10:12:07.841 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 10:12:08.331 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 10:12:10.298 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 10:12:10.299 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 10:12:10.836 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 10:12:18.010 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 10:12:18.484 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 457 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 10:12:19.675 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6a397777, com.mongodb.Jep395RecordCodecProvider@69b1cb97, com.mongodb.KotlinCodecProvider@6e509b5d]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:56095], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 10:12:19.697 [cluster-ClusterId{value='6833f12bb7805b8bc483417f', description='null'}-127.0.0.1:56095] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:56095, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=47502100, minRoundTripTimeNanos=0}
WARN  2025-05-26 10:12:19.814 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 10:12:20.000 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 10:12:21.111 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 10:12:21.142 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 10:12:21.149 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 10:12:21.149 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 10:12:21.309 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 10:12:21.311 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 5273 ms
INFO  2025-05-26 10:12:21.511 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 10:12:23.315 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 10:12:23.928 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 10:12:24.003 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 10:12:24.212 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 10:12:24.363 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 10:12:24.785 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 10:12:24.793 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 10:12:24.794 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 10:12:24.795 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748234544786
INFO  2025-05-26 10:12:24.801 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 10:12:24.857 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 24.211 seconds (process running for 27.152)
INFO  2025-05-26 10:12:27.134 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 10:12:27.135 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 10:12:27.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 10:12:27.210 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-48b5ebfd-95d6-4df1-9d08-c602e269a36e
INFO  2025-05-26 10:12:27.211 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 10:12:27.250 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=5, memberId='consumer-dev-group-1-48b5ebfd-95d6-4df1-9d08-c602e269a36e', protocol='range'}
INFO  2025-05-26 10:12:27.263 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 5: {consumer-dev-group-1-48b5ebfd-95d6-4df1-9d08-c602e269a36e=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 10:12:27.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=5, memberId='consumer-dev-group-1-48b5ebfd-95d6-4df1-9d08-c602e269a36e', protocol='range'}
INFO  2025-05-26 10:12:27.357 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 10:12:27.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 10:12:27.387 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 10:12:27.389 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 10:12:44.933 [http-nio-8084-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-26 10:12:44.933 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-26 10:12:44.936 [http-nio-8084-exec-3] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-26 10:43:11.564 [cluster-ClusterId{value='6833f12bb7805b8bc483417f', description='null'}-127.0.0.1:56095] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:56095
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 10:43:11.600 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Node 2147483647 disconnected.
INFO  2025-05-26 10:43:11.604 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to request timeout.
INFO  2025-05-26 10:43:11.604 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 1758 due to node 0 being disconnected (elapsed time since creation: 1082130ms, elapsed time since send: 1082130ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 10:43:11.604 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Error sending fetch request (sessionId=1206438086, epoch=1485) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-26 10:43:11.604 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 10:43:11.808 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 10:43:11.885 [cluster-ClusterId{value='6833f12bb7805b8bc483417f', description='null'}-127.0.0.1:56095] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:56095, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=259380100, minRoundTripTimeNanos=0}
INFO  2025-05-26 10:55:27.676 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: pradeep
INFO  2025-05-26 10:55:54.797 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: Subh
INFO  2025-05-26 10:56:21.761 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:06:48.669 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:06:48.671 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:06:48.671 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-48b5ebfd-95d6-4df1-9d08-c602e269a36e sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:06:48.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:06:48.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:06:48.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:06:48.674 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:06:48.674 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:06:48.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:06:48.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:06:48.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:06:48.819 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:06:48.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:06:48.825 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:06:48.827 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:06:49.117 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:07:17.170 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:07:17.262 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 6108 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:07:17.264 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:07:17.370 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:07:17.370 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:07:17.413 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:07:20.058 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:07:20.082 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:07:20.407 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:07:20.408 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:07:20.923 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:07:24.921 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:07:25.125 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 191 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:07:26.251 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@79486be2, com.mongodb.Jep395RecordCodecProvider@6f70454e, com.mongodb.KotlinCodecProvider@7cf117b1]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57016], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:07:26.270 [cluster-ClusterId{value='6833fe1601e25b6bb141f8cd', description='null'}-127.0.0.1:57016] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57016, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=41248200, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:07:26.390 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:07:26.545 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:07:27.422 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:07:27.494 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:07:27.497 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:07:27.499 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:07:27.648 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:07:27.650 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4642 ms
INFO  2025-05-26 11:07:27.880 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:07:29.652 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:07:30.169 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:07:30.219 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:07:30.320 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:07:30.636 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:07:31.093 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:07:31.096 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:07:31.097 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:07:31.097 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748237851093
INFO  2025-05-26 11:07:31.103 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:07:31.156 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 15.147 seconds (process running for 18.19)
INFO  2025-05-26 11:07:32.331 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:07:32.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:07:32.338 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:07:32.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-a6c20240-f014-4d7b-af1b-d5fe5aef5731
INFO  2025-05-26 11:07:32.362 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:07:32.367 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=7, memberId='consumer-dev-group-1-a6c20240-f014-4d7b-af1b-d5fe5aef5731', protocol='range'}
INFO  2025-05-26 11:07:32.377 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 7: {consumer-dev-group-1-a6c20240-f014-4d7b-af1b-d5fe5aef5731=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:07:32.386 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=7, memberId='consumer-dev-group-1-a6c20240-f014-4d7b-af1b-d5fe5aef5731', protocol='range'}
INFO  2025-05-26 11:07:32.387 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:07:32.392 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:07:32.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:07:32.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:07:41.453 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:07:41.454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:07:41.455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-a6c20240-f014-4d7b-af1b-d5fe5aef5731 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:07:41.456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:07:41.457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:07:41.457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:07:41.461 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:07:41.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:07:41.660 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:07:41.660 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:07:41.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:07:41.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:07:41.670 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:07:41.671 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:07:41.674 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:07:42.001 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:07:49.606 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:07:49.733 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 22688 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:07:49.735 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:07:49.865 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:07:49.866 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:07:49.905 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:07:52.296 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:07:52.316 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:07:52.554 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:07:52.554 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:07:53.064 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:07:56.503 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:07:56.795 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 277 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:07:58.012 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@132ae4d6, com.mongodb.Jep395RecordCodecProvider@3686fdc3, com.mongodb.KotlinCodecProvider@7483a111]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57033], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:07:58.056 [cluster-ClusterId{value='6833fe358539b880b270ed01', description='null'}-127.0.0.1:57033] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57033, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=65602300, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:07:58.230 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:07:58.518 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:07:59.635 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:07:59.670 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:07:59.679 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:07:59.680 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:07:59.805 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:07:59.808 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4897 ms
INFO  2025-05-26 11:07:59.942 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:08:01.775 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:08:02.340 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:08:02.376 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:08:02.446 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:08:02.531 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:08:02.751 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:08:02.759 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:08:02.759 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:08:02.759 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748237882751
INFO  2025-05-26 11:08:02.763 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:08:02.792 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 14.386 seconds (process running for 15.591)
INFO  2025-05-26 11:08:03.523 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:08:03.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:08:03.529 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:08:03.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-107cb057-7f82-4178-ab4f-90301ea1220f
INFO  2025-05-26 11:08:03.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:08:03.556 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=9, memberId='consumer-dev-group-1-107cb057-7f82-4178-ab4f-90301ea1220f', protocol='range'}
INFO  2025-05-26 11:08:03.566 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 9: {consumer-dev-group-1-107cb057-7f82-4178-ab4f-90301ea1220f=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:08:03.575 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=9, memberId='consumer-dev-group-1-107cb057-7f82-4178-ab4f-90301ea1220f', protocol='range'}
INFO  2025-05-26 11:08:03.575 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:08:03.578 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:08:03.590 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:08:03.592 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:08:55.168 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 11:08:55.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57033. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy75.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy75.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:53)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57033. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 57 common frames omitted
INFO  2025-05-26 11:09:25.598 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:09:25.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:09:25.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-107cb057-7f82-4178-ab4f-90301ea1220f sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:09:25.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:09:25.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:09:25.599 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:09:25.602 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:09:25.602 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:09:25.833 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:09:25.833 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:09:25.833 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:09:25.833 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:09:25.841 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:09:25.841 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:09:25.843 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:09:26.052 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:09:34.165 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:09:34.270 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 2664 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:09:34.272 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:09:34.401 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:09:34.403 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:09:34.465 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:09:37.006 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:09:37.030 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:09:37.284 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:09:37.285 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:09:37.790 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:09:40.829 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:09:41.219 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 371 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:09:42.320 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@15765f99, com.mongodb.Jep395RecordCodecProvider@375a18eb, com.mongodb.KotlinCodecProvider@63c5d3c3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57064], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:09:42.343 [cluster-ClusterId{value='6833fe9ed4325522e38a1beb', description='null'}-127.0.0.1:57064] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57064, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=38750800, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:09:42.519 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:09:42.721 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:09:43.608 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:09:43.633 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:09:43.637 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:09:43.638 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:09:43.743 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:09:43.746 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4138 ms
INFO  2025-05-26 11:09:43.871 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:09:49.068 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:09:51.212 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:09:51.279 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:09:51.520 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:09:51.725 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:09:52.462 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:09:52.474 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:09:52.474 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:09:52.475 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748237992462
INFO  2025-05-26 11:09:52.490 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:09:52.738 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 19.829 seconds (process running for 22.33)
INFO  2025-05-26 11:09:54.567 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:09:54.612 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:09:54.627 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:09:54.753 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275
INFO  2025-05-26 11:09:54.756 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:09:54.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=11, memberId='consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275', protocol='range'}
INFO  2025-05-26 11:09:54.825 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 11: {consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:09:54.843 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=11, memberId='consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275', protocol='range'}
INFO  2025-05-26 11:09:54.846 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:09:54.867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:09:54.917 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:09:54.924 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:10:00.415 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:16:36.584 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 11:16:36.585 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:16:36.585 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
ERROR 2025-05-26 11:16:36.611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57064. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy75.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy75.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:53)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57064. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:16:36.635 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:16:36.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 11:16:36.636 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:16:36.733 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
WARN  2025-05-26 11:16:36.734 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  2025-05-26 11:16:36.735 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired.
INFO  2025-05-26 11:16:36.736 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:16:36.736 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:16:36.736 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Failing OffsetCommit request since the consumer is not part of an active group
INFO  2025-05-26 11:16:36.738 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:16:36.739 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 11:16:36.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:16:36.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:16:36.740 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:16:36.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:16:36.742 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:16:36.743 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
ERROR 2025-05-26 11:16:36.745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] LeaveGroup request with Generation{generationId=11, memberId='consumer-dev-group-1-c5526f63-4b78-42ec-b729-71c088593275', protocol='range'} failed with error: The coordinator is not aware of this member.
INFO  2025-05-26 11:16:36.751 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:16:36.751 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:16:36.751 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:16:36.751 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:16:36.764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:16:36.766 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:16:36.769 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:16:37.015 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:16:46.822 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:16:46.960 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24508 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:16:46.961 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:16:47.072 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:16:47.072 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:16:47.110 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:16:49.493 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:16:49.518 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:16:49.840 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:16:49.841 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:16:50.347 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:16:53.397 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:16:53.742 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 331 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:16:55.058 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6529c404, com.mongodb.Jep395RecordCodecProvider@5255da85, com.mongodb.KotlinCodecProvider@56a74dca]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57193], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:16:55.084 [cluster-ClusterId{value='6834004e41770961f0dcc707', description='null'}-127.0.0.1:57193] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57193, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=52670500, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:16:55.285 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:16:55.560 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:16:56.438 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:16:56.478 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:16:56.484 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:16:56.486 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:16:56.606 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:16:56.609 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4380 ms
INFO  2025-05-26 11:16:56.738 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:17:03.392 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:17:05.908 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:17:05.982 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:17:06.199 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:17:06.463 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:17:07.240 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:17:07.271 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:17:07.273 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:17:07.275 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748238427242
INFO  2025-05-26 11:17:07.299 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:17:07.648 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 22.189 seconds (process running for 23.726)
INFO  2025-05-26 11:17:10.319 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:17:10.349 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:17:10.360 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:17:10.462 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de
INFO  2025-05-26 11:17:10.465 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:17:10.471 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=13, memberId='consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de', protocol='range'}
INFO  2025-05-26 11:17:10.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 13: {consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:17:10.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=13, memberId='consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de', protocol='range'}
INFO  2025-05-26 11:17:10.552 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:17:10.571 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:17:10.658 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:17:10.781 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:17:11.209 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 11:17:26.080 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:53)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:17:26.148 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:23:13.325 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 2147483647 due to request timeout.
ERROR 2025-05-26 11:23:13.320 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:53)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:23:13.334 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 22 due to node 2147483647 being disconnected (elapsed time since creation: 338325ms, elapsed time since send: 338325ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 11:23:13.344 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 11:23:13.455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
WARN  2025-05-26 11:23:13.459 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  2025-05-26 11:23:13.460 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired.
INFO  2025-05-26 11:23:13.463 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:13.464 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:13.466 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Failing OffsetCommit request since the consumer is not part of an active group
INFO  2025-05-26 11:23:13.470 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 11:23:13.472 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:23:13.474 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 11:23:13.477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:23:13.480 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
ERROR 2025-05-26 11:23:13.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] LeaveGroup request with Generation{generationId=13, memberId='consumer-dev-group-1-a5bf859c-2c5f-4cae-a3f4-6392e06b27de', protocol='range'} failed with error: The coordinator is not aware of this member.
INFO  2025-05-26 11:23:13.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-b4a981e2-850c-4851-b702-f2dab3c39cc9
INFO  2025-05-26 11:23:13.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:23:13.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=15, memberId='consumer-dev-group-1-b4a981e2-850c-4851-b702-f2dab3c39cc9', protocol='range'}
INFO  2025-05-26 11:23:13.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 15: {consumer-dev-group-1-b4a981e2-850c-4851-b702-f2dab3c39cc9=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:23:13.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=15, memberId='consumer-dev-group-1-b4a981e2-850c-4851-b702-f2dab3c39cc9', protocol='range'}
INFO  2025-05-26 11:23:13.529 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:23:13.530 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:23:13.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:23:13.540 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:23:13.569 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 11:23:15.744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:53)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57193. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:23:17.303 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (0 additions, 0 deletions, 1 modification)
INFO  2025-05-26 11:23:17.344 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:23:17.344 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:23:17.345 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-b4a981e2-850c-4851-b702-f2dab3c39cc9 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:23:17.347 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:17.347 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:17.347 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:23:17.354 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:17.355 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:23:17.821 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:23:17.821 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:23:17.822 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:23:17.822 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:23:17.966 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:23:17.971 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:23:17.984 [Thread-20] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:23:17.993 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:23:18.385 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:23:18.387 [Thread-20] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:23:19.934 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24508 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:23:19.935 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:23:20.041 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:23:21.687 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - There are already Docker Compose services running, skipping startup
INFO  2025-05-26 11:23:27.193 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:23:27.521 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 287 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:23:32.269 [cluster-ClusterId{value='683401dc41770961f0dcc708', description='null'}-127.0.0.1:57193] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57193, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14125800, minRoundTripTimeNanos=0}
INFO  2025-05-26 11:23:32.271 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6529c404, com.mongodb.Jep395RecordCodecProvider@5255da85, com.mongodb.KotlinCodecProvider@56a74dca]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57193], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-26 11:23:32.486 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:23:32.904 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:23:34.220 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:23:34.223 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:23:34.224 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:23:34.225 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:23:34.411 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:23:34.412 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 12675 ms
INFO  2025-05-26 11:23:34.599 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:23:37.642 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:23:38.666 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:23:38.674 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:23:38.683 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:23:38.685 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:23:38.793 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:23:38.794 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:23:38.795 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:23:38.796 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748238818794
INFO  2025-05-26 11:23:38.802 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:23:38.874 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:23:38.911 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:23:38.918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:23:38.980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-e816bee1-b3ab-4034-a53d-b5519c22d89c
INFO  2025-05-26 11:23:38.985 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:23:38.997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=17, memberId='consumer-dev-group-2-e816bee1-b3ab-4034-a53d-b5519c22d89c', protocol='range'}
INFO  2025-05-26 11:23:38.999 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 17: {consumer-dev-group-2-e816bee1-b3ab-4034-a53d-b5519c22d89c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:23:39.009 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=17, memberId='consumer-dev-group-2-e816bee1-b3ab-4034-a53d-b5519c22d89c', protocol='range'}
INFO  2025-05-26 11:23:39.013 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:23:39.015 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:23:39.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:23:39.029 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:23:39.118 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 20.368 seconds (process running for 415.197)
INFO  2025-05-26 11:23:39.179 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-26 11:29:37.057 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 2 class path changes (0 additions, 1 deletion, 1 modification)
INFO  2025-05-26 11:29:37.076 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:29:37.078 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:29:37.079 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Member consumer-dev-group-2-e816bee1-b3ab-4034-a53d-b5519c22d89c sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:29:37.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:37.081 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:37.082 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:29:37.083 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:37.084 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:37.111 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:29:37.112 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:29:37.113 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:29:37.113 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:29:37.194 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-2 unregistered
INFO  2025-05-26 11:29:37.194 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:29:37.195 [Thread-23] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:29:37.197 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:29:37.543 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:29:37.545 [Thread-23] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:29:38.270 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24508 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:29:38.272 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:29:38.344 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:29:39.890 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - There are already Docker Compose services running, skipping startup
INFO  2025-05-26 11:29:42.039 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:29:42.088 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 47 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:29:42.382 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6529c404, com.mongodb.Jep395RecordCodecProvider@5255da85, com.mongodb.KotlinCodecProvider@56a74dca]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57193], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-26 11:29:42.399 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:29:42.419 [cluster-ClusterId{value='6834034e41770961f0dcc709', description='null'}-127.0.0.1:57193] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57193, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19257800, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:29:42.440 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:29:42.585 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:29:42.633 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2693 ms
INFO  2025-05-26 11:29:42.652 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:29:42.942 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:29:43.072 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:29:43.076 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:29:43.078 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:29:43.111 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:29:43.111 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:29:43.111 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:29:43.111 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748239183111
INFO  2025-05-26 11:29:43.112 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:29:43.122 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:29:43.123 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:29:43.125 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:29:43.128 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 5.343 seconds (process running for 779.206)
INFO  2025-05-26 11:29:43.130 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:43.131 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:43.131 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:29:43.132 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:43.132 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:29:43.134 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-26 11:29:43.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-3, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-3-d3529dc6-0aae-4d4a-98e9-db95adfeb15e
INFO  2025-05-26 11:29:43.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:29:43.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:29:43.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:29:43.145 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:29:43.155 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-3 unregistered
INFO  2025-05-26 11:29:43.156 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:29:43.157 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:29:43.600 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:29:52.284 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:29:52.364 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 13832 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:29:52.366 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:29:52.505 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:29:52.506 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:29:52.544 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:29:54.675 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:29:54.697 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:29:54.943 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:29:54.944 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:29:55.501 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:29:59.020 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:29:59.398 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 360 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:30:00.552 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@6529c404, com.mongodb.Jep395RecordCodecProvider@5255da85, com.mongodb.KotlinCodecProvider@56a74dca]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57389], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:30:00.571 [cluster-ClusterId{value='68340360652d3d3491d6fcc9', description='null'}-127.0.0.1:57389] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57389, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=34401600, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:30:00.738 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:30:00.956 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:30:02.073 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:30:02.101 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:30:02.105 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:30:02.107 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:30:02.291 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:30:02.299 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4901 ms
INFO  2025-05-26 11:30:02.443 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:30:07.154 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:30:09.162 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:30:09.274 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:30:09.502 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:30:09.730 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:30:10.459 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:30:10.472 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:30:10.473 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:30:10.474 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748239210460
INFO  2025-05-26 11:30:10.496 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:30:10.748 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 20.305 seconds (process running for 22.017)
INFO  2025-05-26 11:30:13.147 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:30:13.149 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:30:13.159 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:30:13.230 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-3eefbfb2-681e-4fc5-b5ff-5b0cb7a0dbd6
INFO  2025-05-26 11:30:13.231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:30:13.235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=19, memberId='consumer-dev-group-1-3eefbfb2-681e-4fc5-b5ff-5b0cb7a0dbd6', protocol='range'}
INFO  2025-05-26 11:30:13.275 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 19: {consumer-dev-group-1-3eefbfb2-681e-4fc5-b5ff-5b0cb7a0dbd6=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:30:13.292 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=19, memberId='consumer-dev-group-1-3eefbfb2-681e-4fc5-b5ff-5b0cb7a0dbd6', protocol='range'}
INFO  2025-05-26 11:30:13.295 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:30:13.312 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:30:13.348 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:30:13.354 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:30:22.597 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 11:30:28.418 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57389. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57389. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:30:44.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:30:44.224 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:30:44.226 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-3eefbfb2-681e-4fc5-b5ff-5b0cb7a0dbd6 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:30:44.228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:30:44.228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:30:44.228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:30:44.230 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:30:44.230 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:30:44.395 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:30:44.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:30:44.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:30:44.396 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:30:44.406 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:30:44.407 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:30:44.411 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:30:44.625 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:30:51.628 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:30:51.726 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 9624 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:30:51.728 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:30:51.866 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:30:51.866 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:30:51.910 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:30:53.937 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:30:53.954 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:30:54.210 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:30:54.210 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:30:54.716 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:30:57.622 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:30:57.904 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 263 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:30:58.953 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@1f461796, com.mongodb.Jep395RecordCodecProvider@23a60575, com.mongodb.KotlinCodecProvider@51b0846c]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57410], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:30:58.995 [cluster-ClusterId{value='6834039ac296789566f6e591', description='null'}-127.0.0.1:57410] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57410, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=66187100, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:30:59.140 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:30:59.348 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:31:00.257 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:31:00.282 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:31:00.286 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:31:00.287 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:31:00.397 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:31:00.399 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 3961 ms
INFO  2025-05-26 11:31:00.520 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:31:06.394 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:31:09.586 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:31:09.677 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:31:09.926 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:31:10.562 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:31:11.904 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:31:11.918 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:31:11.919 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:31:11.919 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748239271905
INFO  2025-05-26 11:31:11.935 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:31:12.402 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 22.347 seconds (process running for 23.693)
INFO  2025-05-26 11:31:14.473 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:31:14.490 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:31:14.498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:31:14.590 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c
INFO  2025-05-26 11:31:14.592 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:31:14.597 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=21, memberId='consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c', protocol='range'}
INFO  2025-05-26 11:31:14.641 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 21: {consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:31:14.656 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=21, memberId='consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c', protocol='range'}
INFO  2025-05-26 11:31:14.659 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:31:14.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:31:14.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:31:14.731 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:31:15.047 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:33:19.176 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 11:33:19.178 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:33:19.179 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
ERROR 2025-05-26 11:35:08.968 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:35:09.090 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:35:09.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=21, memberId='consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 11:35:09.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 11:35:09.101 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
ERROR 2025-05-26 11:35:09.105 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Offset commit failed on partition pigeon-dev-events-0 at offset 12: The coordinator is not aware of this member.
INFO  2025-05-26 11:35:09.105 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] OffsetCommit failed with Generation{generationId=21, memberId='consumer-dev-group-1-17fe5b39-27ac-4693-a51f-ab16835a729c', protocol='range'}: The coordinator is not aware of this member.
INFO  2025-05-26 11:35:09.105 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 11:35:09.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 11:35:09.106 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 11:35:09.108 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:35:09.109 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 11:35:09.112 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:35:09.116 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:35:09.125 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1
INFO  2025-05-26 11:35:09.126 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:35:09.130 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=23, memberId='consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1', protocol='range'}
INFO  2025-05-26 11:35:09.131 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 23: {consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:35:09.135 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=23, memberId='consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1', protocol='range'}
INFO  2025-05-26 11:35:09.136 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:35:09.137 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:35:09.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:35:09.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:35:09.155 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 11:35:25.374 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:40:53.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:46:18.947 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 2147483647 due to request timeout.
INFO  2025-05-26 11:46:18.948 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 788 due to node 2147483647 being disconnected (elapsed time since creation: 288055ms, elapsed time since send: 288055ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 11:49:11.383 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
ERROR 2025-05-26 11:49:11.426 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:49:11.444 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 0 due to request timeout.
INFO  2025-05-26 11:49:11.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight METADATA request with correlation id 789 due to node 0 being disconnected (elapsed time since creation: 172499ms, elapsed time since send: 172499ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 11:49:11.579 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
WARN  2025-05-26 11:49:11.583 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  2025-05-26 11:49:11.584 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired.
INFO  2025-05-26 11:49:11.590 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:49:11.591 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:49:11.594 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Failing OffsetCommit request since the consumer is not part of an active group
INFO  2025-05-26 11:49:11.598 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 11:49:11.600 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:49:11.601 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 11:49:11.603 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:49:11.605 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
ERROR 2025-05-26 11:49:11.644 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] LeaveGroup request with Generation{generationId=23, memberId='consumer-dev-group-1-1598ef75-5112-4fc9-9297-0b9329114fc1', protocol='range'} failed with error: The coordinator is not aware of this member.
INFO  2025-05-26 11:49:11.647 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f
INFO  2025-05-26 11:49:11.649 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:49:11.658 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=25, memberId='consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f', protocol='range'}
INFO  2025-05-26 11:49:11.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 25: {consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:49:11.672 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=25, memberId='consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f', protocol='range'}
INFO  2025-05-26 11:49:11.675 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:49:11.677 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:49:11.685 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:49:11.688 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:49:11.713 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:51:02.192 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 2147483647 due to request timeout.
INFO  2025-05-26 11:51:02.194 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 807 due to node 2147483647 being disconnected (elapsed time since creation: 58119ms, elapsed time since send: 58119ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 11:51:02.196 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
ERROR 2025-05-26 11:54:48.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
org.springframework.data.mongodb.UncategorizedMongoDbException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.doTranslateException(MongoExceptionTranslator.java:151)
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:74)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:3033)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2953)
	at org.springframework.data.mongodb.core.MongoTemplate.doFind(MongoTemplate.java:2652)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.doFind(ExecutableFindOperationSupport.java:178)
	at org.springframework.data.mongodb.core.ExecutableFindOperationSupport$ExecutableFindSupport.oneValue(ExecutableFindOperationSupport.java:113)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.lambda$getExecution$8(AbstractMongoQuery.java:239)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.doExecute(AbstractMongoQuery.java:184)
	at org.springframework.data.mongodb.repository.query.AbstractMongoQuery.execute(AbstractMongoQuery.java:156)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:170)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:158)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:170)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:149)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:69)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.data.mongodb.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:129)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:359)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)
	at jdk.proxy3/jdk.proxy3.$Proxy74.findMessageByCodeAndLocale(Unknown Source)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:34)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.mongodb.MongoQueryException: Command failed with error 2 (BadValue): 'Field 'locale' is invalid in: { locale: "Localized_Message" }' on server 127.0.0.1:57410. The full response is {"ok": 0.0, "errmsg": "Field 'locale' is invalid in: { locale: \"Localized_Message\" }", "code": 2, "codeName": "BadValue"}
	at com.mongodb.internal.operation.FindOperation.lambda$execute$1(FindOperation.java:303)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$0(SyncOperationHelper.java:131)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$withSourceAndConnection$1(SyncOperationHelper.java:130)
	at com.mongodb.internal.operation.SyncOperationHelper.withSuppliedResource(SyncOperationHelper.java:156)
	at com.mongodb.internal.operation.SyncOperationHelper.withSourceAndConnection(SyncOperationHelper.java:129)
	at com.mongodb.internal.operation.FindOperation.lambda$execute$2(FindOperation.java:296)
	at com.mongodb.internal.operation.SyncOperationHelper.lambda$decorateReadWithRetries$13(SyncOperationHelper.java:317)
	at com.mongodb.internal.async.function.RetryingSyncSupplier.get(RetryingSyncSupplier.java:67)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:307)
	at com.mongodb.internal.operation.FindOperation.execute(FindOperation.java:70)
	at com.mongodb.client.internal.MongoClusterImpl$OperationExecutorImpl.execute(MongoClusterImpl.java:424)
	at com.mongodb.client.internal.MongoIterableImpl.execute(MongoIterableImpl.java:156)
	at com.mongodb.client.internal.MongoIterableImpl.iterator(MongoIterableImpl.java:116)
	at org.springframework.data.mongodb.core.MongoTemplate.executeFindMultiInternal(MongoTemplate.java:2940)
	... 58 common frames omitted
INFO  2025-05-26 11:54:48.807 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
WARN  2025-05-26 11:54:48.809 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  2025-05-26 11:54:48.809 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired.
INFO  2025-05-26 11:54:48.809 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:54:48.810 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:54:48.810 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Failing OffsetCommit request since the consumer is not part of an active group
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:54:48.811 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:54:48.814 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:54:48.814 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
ERROR 2025-05-26 11:54:48.817 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] LeaveGroup request with Generation{generationId=25, memberId='consumer-dev-group-1-c27a53a4-d86e-49e4-b7ea-ab58b0e7405f', protocol='range'} failed with error: The coordinator is not aware of this member.
INFO  2025-05-26 11:54:48.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:54:48.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:54:48.823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:54:48.824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:54:48.835 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:54:48.836 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:54:48.839 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:54:49.032 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:55:01.940 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:55:02.017 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 10920 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:55:02.019 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:55:02.088 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:55:02.089 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:55:02.120 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:55:03.936 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:55:03.955 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:55:04.206 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:55:04.206 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:55:04.714 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:55:07.890 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:55:08.119 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 218 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:55:08.960 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5ac2f9c6, com.mongodb.Jep395RecordCodecProvider@7defef90, com.mongodb.KotlinCodecProvider@1a952d86]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57616], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:55:08.984 [cluster-ClusterId{value='68340944b159cda0a710c902', description='null'}-127.0.0.1:57616] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57616, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=36120200, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:55:09.141 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:55:09.312 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:55:17.859 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:55:17.874 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:55:17.876 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:55:17.876 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:55:17.946 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:55:17.948 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 11448 ms
INFO  2025-05-26 11:55:18.026 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:55:23.844 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:55:25.720 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:55:25.776 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:55:25.951 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:55:26.152 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:55:27.007 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:55:27.025 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:55:27.026 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:55:27.027 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748240727008
INFO  2025-05-26 11:55:27.041 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:55:27.231 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 26.251 seconds (process running for 32.148)
INFO  2025-05-26 11:55:28.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:55:28.912 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:55:28.919 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:55:28.990 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-726387cd-9238-4100-9742-733a0b4420b3
INFO  2025-05-26 11:55:28.992 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:55:28.997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=27, memberId='consumer-dev-group-1-726387cd-9238-4100-9742-733a0b4420b3', protocol='range'}
INFO  2025-05-26 11:55:29.034 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 27: {consumer-dev-group-1-726387cd-9238-4100-9742-733a0b4420b3=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:55:29.048 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=27, memberId='consumer-dev-group-1-726387cd-9238-4100-9742-733a0b4420b3', protocol='range'}
INFO  2025-05-26 11:55:29.049 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:55:29.063 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:55:29.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:55:29.102 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:55:29.268 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:56:14.158 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Found No message found under msgTemplateID [staff.not.found.by.user.id] for locale en
INFO  2025-05-26 11:56:14.161 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 11:56:22.390 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Found No message found under msgTemplateID [staff.not.found.by.user.id] for locale en
INFO  2025-05-26 11:56:54.786 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-26 11:56:54.787 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-26 11:56:54.804 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 17 ms
INFO  2025-05-26 11:57:09.942 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.duplicate.found.by.email
ERROR 2025-05-26 11:57:28.949 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.duplicate.found.by.email
java.lang.IllegalArgumentException: can't parse argument number: "message": "\u30fc {0} "
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "\u30fc {0} ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 11:58:10.439 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.duplicate.found.by.email
ERROR 2025-05-26 11:58:22.157 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.duplicate.found.by.email
java.lang.IllegalArgumentException: can't parse argument number: "message": "\u30fc {0} "
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "\u30fc {0} ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 11:58:38.306 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 11:58:38.306 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 11:58:38.307 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-726387cd-9238-4100-9742-733a0b4420b3 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 11:58:38.308 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:58:38.308 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:58:38.308 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 11:58:38.310 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:58:38.310 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 11:58:38.576 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 11:58:38.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 11:58:38.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 11:58:38.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 11:58:38.588 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 11:58:38.589 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 11:58:38.592 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 11:58:38.803 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 11:58:46.053 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:58:46.130 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 23692 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:58:46.132 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:58:46.200 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:58:46.200 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:58:46.248 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:58:47.579 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 11:58:47.591 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 11:58:47.761 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 11:58:47.761 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 11:58:48.271 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 11:58:50.721 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:58:50.869 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 141 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:58:52.079 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@12c4a1ed, com.mongodb.Jep395RecordCodecProvider@48a99bee, com.mongodb.KotlinCodecProvider@675ce2b1]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57673], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:58:52.096 [cluster-ClusterId{value='68340a23afb1f23f0bf0a669', description='null'}-127.0.0.1:57673] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57673, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=37716400, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:58:52.261 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:58:52.459 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:59:10.930 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:59:11.029 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 21143 ms
INFO  2025-05-26 11:59:11.176 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
INFO  2025-05-26 11:59:25.687 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 11:59:25.818 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 25404 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 11:59:25.820 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 11:59:25.934 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 11:59:25.935 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 11:59:25.985 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 11:59:28.456 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - There are already Docker Compose services running, skipping startup
INFO  2025-05-26 11:59:29.779 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 11:59:30.078 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 287 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 11:59:31.190 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@23e0df57, com.mongodb.Jep395RecordCodecProvider@585e38ea, com.mongodb.KotlinCodecProvider@113e04af]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57673], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 11:59:31.245 [cluster-ClusterId{value='68340a4a85d0e4d53ff803b6', description='null'}-127.0.0.1:57673] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57673, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=56800000, minRoundTripTimeNanos=0}
WARN  2025-05-26 11:59:31.415 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 11:59:31.644 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 11:59:32.626 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 11:59:32.661 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:59:32.663 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 11:59:32.664 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 11:59:32.785 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 11:59:32.788 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4303 ms
INFO  2025-05-26 11:59:32.947 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 11:59:34.433 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 11:59:35.066 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 11:59:35.115 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 11:59:35.199 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 11:59:35.311 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 11:59:35.602 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 11:59:35.607 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 11:59:35.607 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 11:59:35.608 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748240975603
INFO  2025-05-26 11:59:35.613 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 11:59:35.648 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 10.972 seconds (process running for 11.849)
INFO  2025-05-26 11:59:36.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 11:59:36.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 11:59:36.518 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:59:36.548 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb
INFO  2025-05-26 11:59:36.549 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 11:59:36.554 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=29, memberId='consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb', protocol='range'}
INFO  2025-05-26 11:59:36.566 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 29: {consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 11:59:36.575 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=29, memberId='consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb', protocol='range'}
INFO  2025-05-26 11:59:36.577 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 11:59:36.582 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 11:59:36.600 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=16, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 11:59:36.603 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 11:59:44.954 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.duplicate.found.by.email
INFO  2025-05-26 12:01:54.351 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 12:01:54.351 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:01:54.353 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
ERROR 2025-05-26 12:01:54.353 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.duplicate.found.by.email
java.lang.IllegalArgumentException: can't parse argument number: "message": "\u30fc {0} "
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "\u30fc {0} ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:01:54.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:01:54.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 12:01:54.376 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:01:54.425 [http-nio-8084-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-26 12:01:54.425 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-26 12:01:54.426 [http-nio-8084-exec-2] o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
INFO  2025-05-26 12:01:54.499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:01:54.504 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=29, memberId='consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 12:01:54.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 12:01:54.505 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
ERROR 2025-05-26 12:01:54.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Offset commit failed on partition pigeon-dev-events-0 at offset 17: The coordinator is not aware of this member.
INFO  2025-05-26 12:01:54.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] OffsetCommit failed with Generation{generationId=29, memberId='consumer-dev-group-1-991616a2-63ba-4605-803c-a6d6abc60fdb', protocol='range'}: The coordinator is not aware of this member.
INFO  2025-05-26 12:01:54.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:01:54.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:01:54.506 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 12:01:54.507 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:01:54.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 12:01:54.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:01:54.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:01:54.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89
INFO  2025-05-26 12:01:54.512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:01:54.515 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=31, memberId='consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89', protocol='range'}
INFO  2025-05-26 12:01:54.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 31: {consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:01:54.520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=31, memberId='consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89', protocol='range'}
INFO  2025-05-26 12:01:54.521 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:01:54.522 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:01:54.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=16, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:01:54.527 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:01:54.535 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.duplicate.found.by.email
ERROR 2025-05-26 12:01:55.394 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.duplicate.found.by.email
java.lang.IllegalArgumentException: can't parse argument number: "message": "\u30fc {0} "
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "\u30fc {0} ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:02:08.214 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:04:40.292 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 2147483647 due to request timeout.
INFO  2025-05-26 12:04:40.295 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 79 due to node 2147483647 being disconnected (elapsed time since creation: 149128ms, elapsed time since send: 149128ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 12:04:40.296 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
ERROR 2025-05-26 12:04:40.294 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
java.lang.IllegalArgumentException: can't parse argument number: "message": "No staff found with id  {0}"
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "No staff found with id  {0}""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:04:40.405 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=31, memberId='consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
ERROR 2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Offset commit failed on partition pigeon-dev-events-0 at offset 18: The coordinator is not aware of this member.
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] OffsetCommit failed with Generation{generationId=31, memberId='consumer-dev-group-1-7ec50810-76e1-49d4-b641-c9a631563a89', protocol='range'}: The coordinator is not aware of this member.
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:04:40.410 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:04:40.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 12:04:40.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:04:40.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 12:04:40.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:04:40.411 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:04:40.413 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-606fc5c4-425b-4fce-a1f0-feae875f850e
INFO  2025-05-26 12:04:40.414 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:04:40.417 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=33, memberId='consumer-dev-group-1-606fc5c4-425b-4fce-a1f0-feae875f850e', protocol='range'}
INFO  2025-05-26 12:04:40.418 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 33: {consumer-dev-group-1-606fc5c4-425b-4fce-a1f0-feae875f850e=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:04:40.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=33, memberId='consumer-dev-group-1-606fc5c4-425b-4fce-a1f0-feae875f850e', protocol='range'}
INFO  2025-05-26 12:04:40.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:04:40.420 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:04:40.423 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=17, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:04:40.423 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:04:40.427 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 12:04:42.405 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
java.lang.IllegalArgumentException: can't parse argument number: "message": "No staff found with id  {0}"
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "No staff found with id  {0}""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:04:57.093 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:04:57.094 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:04:57.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-606fc5c4-425b-4fce-a1f0-feae875f850e sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 12:04:57.095 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:04:57.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:04:57.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 12:04:57.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:04:57.098 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:04:57.265 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 12:04:57.265 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 12:04:57.265 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 12:04:57.266 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 12:04:57.272 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 12:04:57.273 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 12:04:57.275 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 12:04:57.553 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 12:06:22.780 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 12:06:22.862 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 11712 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 12:06:22.864 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 12:06:22.953 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 12:06:22.954 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 12:06:23.000 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 12:06:24.327 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Creating
INFO  2025-05-26 12:06:24.449 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 12:06:24.494 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 12:06:24.803 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 12:06:24.804 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 12:06:25.308 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 12:06:30.816 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 12:06:31.026 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 201 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 12:06:31.968 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@59a36901, com.mongodb.Jep395RecordCodecProvider@45715585, com.mongodb.KotlinCodecProvider@40df76d9]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57743], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 12:06:31.989 [cluster-ClusterId{value='68340bef9444da55489e0273', description='null'}-127.0.0.1:57743] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57743, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49494900, minRoundTripTimeNanos=0}
WARN  2025-05-26 12:06:32.174 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 12:06:32.440 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 12:06:33.215 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 12:06:33.239 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:06:33.243 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 12:06:33.244 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 12:06:33.340 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 12:06:33.342 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 3355 ms
INFO  2025-05-26 12:06:33.473 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 12:06:34.911 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 12:06:35.578 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:06:35.627 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 12:06:35.757 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 12:06:35.892 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 12:06:36.248 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 12:06:36.252 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 12:06:36.252 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 12:06:36.253 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748241396248
INFO  2025-05-26 12:06:36.261 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 12:06:36.296 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 14.543 seconds (process running for 15.551)
INFO  2025-05-26 12:06:37.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 12:06:37.029 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:06:37.033 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:06:37.064 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-dde1c9f7-6ec9-457e-af01-47a8fe35c2f2
INFO  2025-05-26 12:06:37.066 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:06:37.072 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=35, memberId='consumer-dev-group-1-dde1c9f7-6ec9-457e-af01-47a8fe35c2f2', protocol='range'}
INFO  2025-05-26 12:06:37.085 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 35: {consumer-dev-group-1-dde1c9f7-6ec9-457e-af01-47a8fe35c2f2=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:06:37.096 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=35, memberId='consumer-dev-group-1-dde1c9f7-6ec9-457e-af01-47a8fe35c2f2', protocol='range'}
INFO  2025-05-26 12:06:37.097 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:06:37.102 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:06:37.128 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:06:37.130 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:06:48.894 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:06:55.397 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Found No message found under msgTemplateID [staff.not.found.by.user.id] for locale en
INFO  2025-05-26 12:07:34.840 [http-nio-8084-exec-4] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
INFO  2025-05-26 12:07:34.841 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
INFO  2025-05-26 12:07:34.843 [http-nio-8084-exec-4] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
INFO  2025-05-26 12:07:41.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
ERROR 2025-05-26 12:07:43.366 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
java.lang.IllegalArgumentException: can't parse argument number: "message": "No staff found with id {0}"
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "No staff found with id {0}""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:09:29.333 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:10:14.006 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 12:10:14.008 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:10:14.009 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
ERROR 2025-05-26 12:10:21.724 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
java.lang.IllegalArgumentException: can't parse argument number: "message": "No staff found with id {0}"
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "No staff found with id {0}""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:10:21.729 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:10:21.730 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
ERROR 2025-05-26 12:10:21.733 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Offset commit failed on partition pigeon-dev-events-0 at offset 21: The coordinator is not aware of this member.
INFO  2025-05-26 12:10:21.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] OffsetCommit failed with Generation{generationId=35, memberId='consumer-dev-group-1-dde1c9f7-6ec9-457e-af01-47a8fe35c2f2', protocol='range'}: The coordinator is not aware of this member.
INFO  2025-05-26 12:10:21.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:10:21.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
INFO  2025-05-26 12:10:21.734 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 12:10:21.735 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:10:21.736 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 12:10:21.737 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:10:21.737 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:10:21.739 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d
INFO  2025-05-26 12:10:21.739 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:10:21.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=37, memberId='consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d', protocol='range'}
INFO  2025-05-26 12:10:21.741 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 37: {consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:10:21.745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=37, memberId='consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d', protocol='range'}
INFO  2025-05-26 12:10:21.745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:10:21.745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:10:21.748 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=20, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:10:21.748 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:10:21.753 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:15:55.146 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Disconnecting from node 2147483647 due to request timeout.
INFO  2025-05-26 12:15:55.147 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cancelled in-flight HEARTBEAT request with correlation id 404 due to node 2147483647 being disconnected (elapsed time since creation: 329992ms, elapsed time since send: 329992ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 12:15:55.148 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null. isDisconnected: true. Rediscovery will be attempted.
ERROR 2025-05-26 12:15:55.184 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Error processing Kafka message: staff.not.found.by.user.id
java.lang.IllegalArgumentException: can't parse argument number: "message": "No staff found with id {0}"
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1460)
	at java.base/java.text.MessageFormat.applyPattern(MessageFormat.java:493)
	at java.base/java.text.MessageFormat.<init>(MessageFormat.java:392)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.lambda$resolveCode$0(DatabaseMessageSource.java:35)
	at java.base/java.util.Optional.map(Optional.java:260)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.DatabaseMessageSource.resolveCode(DatabaseMessageSource.java:35)
	at org.springframework.context.support.AbstractMessageSource.getMessageInternal(AbstractMessageSource.java:225)
	at org.springframework.context.support.AbstractMessageSource.getMessage(AbstractMessageSource.java:154)
	at com.daimlertrucksasia.it.dsc.pigeon.localization.service.MessageService.getMessage(MessageService.java:64)
	at com.daimlertrucksasia.it.dsc.pigeon.resolver.ResolveLocaleMsg.getResolvedMsg(ResolveLocaleMsg.java:18)
	at com.daimlertrucksasia.it.dsc.pigeon.kafka.service.consumer.PigeonKafkaConsumerService.consume(PigeonKafkaConsumerService.java:58)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2875)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2856)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$57(KafkaMessageListenerContainer.java:2774)
	at io.micrometer.observation.Observation.observe(Observation.java:564)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2772)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2624)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2510)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2152)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1506)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1470)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1345)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run$$$capture(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.NumberFormatException: For input string: ""message": "No staff found with id {0}""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:67)
	at java.base/java.lang.Integer.parseInt(Integer.java:654)
	at java.base/java.lang.Integer.parseInt(Integer.java:786)
	at java.base/java.text.MessageFormat.makeFormat(MessageFormat.java:1458)
	... 34 common frames omitted
INFO  2025-05-26 12:15:55.311 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
WARN  2025-05-26 12:15:55.314 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
INFO  2025-05-26 12:15:55.315 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired.
INFO  2025-05-26 12:15:55.315 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:15:55.315 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:15:55.317 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Failing OffsetCommit request since the consumer is not part of an active group
INFO  2025-05-26 12:15:55.318 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:15:55.318 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 12:15:55.319 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:15:55.319 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:15:55.319 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:15:55.319 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 12:15:55.322 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:15:55.322 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
ERROR 2025-05-26 12:15:55.326 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] LeaveGroup request with Generation{generationId=37, memberId='consumer-dev-group-1-ab6b1638-4be1-4149-92a2-802350cee52d', protocol='range'} failed with error: The coordinator is not aware of this member.
INFO  2025-05-26 12:15:55.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 12:15:55.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 12:15:55.334 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 12:15:55.335 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 12:15:55.353 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 12:15:55.356 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 12:15:55.362 [SpringApplicationShutdownHook] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 12:15:55.877 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 12:16:04.760 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
INFO  2025-05-26 12:16:04.863 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24748 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 12:16:04.866 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 12:16:04.975 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
INFO  2025-05-26 12:16:04.976 [restartedMain] o.s.b.d.e.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
INFO  2025-05-26 12:16:05.016 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 12:16:06.760 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Created
INFO  2025-05-26 12:16:06.782 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Starting
INFO  2025-05-26 12:16:06.995 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Started
INFO  2025-05-26 12:16:06.995 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Waiting
INFO  2025-05-26 12:16:07.504 [OutputReader-stderr] o.s.b.docker.compose.core.DockerCli -  Container pigeon-mongodb-1  Healthy
INFO  2025-05-26 12:16:10.593 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 12:16:10.903 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 298 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 12:16:12.178 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5b03c310, com.mongodb.Jep395RecordCodecProvider@1f4426df, com.mongodb.KotlinCodecProvider@1f78c695]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57867], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 12:16:12.201 [cluster-ClusterId{value='68340e34f52a03faf1bf6ae4', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=40503400, minRoundTripTimeNanos=0}
WARN  2025-05-26 12:16:12.396 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 12:16:12.626 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 12:16:13.640 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 12:16:13.662 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:16:13.665 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 12:16:13.666 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 12:16:13.791 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 12:16:13.795 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 4506 ms
INFO  2025-05-26 12:16:13.925 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 12:16:15.390 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 12:16:16.012 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:16:16.060 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 12:16:16.132 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 12:16:16.281 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 12:16:16.582 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 12:16:16.587 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 12:16:16.587 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 12:16:16.588 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748241976583
INFO  2025-05-26 12:16:16.595 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 12:16:16.630 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 13.179 seconds (process running for 16.488)
INFO  2025-05-26 12:16:17.436 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 12:16:17.438 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:16:17.446 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:16:17.476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-bd434083-0866-4a33-9006-fb031f73e9a5
INFO  2025-05-26 12:16:17.478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:16:17.482 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=39, memberId='consumer-dev-group-1-bd434083-0866-4a33-9006-fb031f73e9a5', protocol='range'}
INFO  2025-05-26 12:16:17.496 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 39: {consumer-dev-group-1-bd434083-0866-4a33-9006-fb031f73e9a5=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:16:17.509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=39, memberId='consumer-dev-group-1-bd434083-0866-4a33-9006-fb031f73e9a5', protocol='range'}
INFO  2025-05-26 12:16:17.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:16:17.516 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:16:17.538 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=20, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:16:17.541 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:16:17.625 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:16:22.519 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Found No staff found with id id_123
INFO  2025-05-26 12:16:35.207 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Received message from Kafka: staff.not.found.by.user.id
INFO  2025-05-26 12:16:46.744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.d.i.d.p.k.s.c.PigeonKafkaConsumerService - Found No staff found with id id_123
INFO  2025-05-26 12:32:25.805 [cluster-ClusterId{value='68340e34f52a03faf1bf6ae4', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 12:32:26.005 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 12:32:26.007 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:32:26.008 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-26 12:32:26.044 [cluster-ClusterId{value='68340e34f52a03faf1bf6ae4', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=228894700, minRoundTripTimeNanos=0}
INFO  2025-05-26 12:32:27.055 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:32:27.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Attempt to heartbeat with Generation{generationId=39, memberId='consumer-dev-group-1-bd434083-0866-4a33-9006-fb031f73e9a5', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 12:32:27.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 12:32:27.061 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 12:32:27.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 12:32:27.062 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:32:27.063 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 12:32:27.064 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:32:27.065 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:32:27.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-1-745daf1c-3258-4721-ac33-fbb1cb0c60e4
INFO  2025-05-26 12:32:27.117 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:32:27.803 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully joined group with generation Generation{generationId=41, memberId='consumer-dev-group-1-745daf1c-3258-4721-ac33-fbb1cb0c60e4', protocol='range'}
INFO  2025-05-26 12:32:27.805 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Finished assignment for group at generation 41: {consumer-dev-group-1-745daf1c-3258-4721-ac33-fbb1cb0c60e4=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:32:27.838 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Successfully synced group in generation Generation{generationId=41, memberId='consumer-dev-group-1-745daf1c-3258-4721-ac33-fbb1cb0c60e4', protocol='range'}
INFO  2025-05-26 12:32:27.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:32:27.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:32:27.844 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:32:27.844 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 12:34:47.673 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (0 additions, 1 deletion, 0 modifications)
INFO  2025-05-26 12:34:47.680 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Revoke previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 12:34:47.681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 12:34:47.681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Member consumer-dev-group-1-745daf1c-3258-4721-ac33-fbb1cb0c60e4 sending LeaveGroup request to coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
INFO  2025-05-26 12:34:47.682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:34:47.682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:34:47.682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Unsubscribed all topics or patterns and assigned partitions
INFO  2025-05-26 12:34:47.684 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:34:47.685 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-1, groupId=dev-group] Request joining group due to: consumer pro-actively leaving the group
INFO  2025-05-26 12:34:48.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
INFO  2025-05-26 12:34:48.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  2025-05-26 12:34:48.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
INFO  2025-05-26 12:34:48.011 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
INFO  2025-05-26 12:34:48.023 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dev-group-1 unregistered
INFO  2025-05-26 12:34:48.025 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: Consumer stopped
INFO  2025-05-26 12:34:48.027 [Thread-20] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 12:34:48.029 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:48.276 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 12:34:48.277 [Thread-20] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:48.530 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24748 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 12:34:48.531 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 12:34:48.540 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 12:34:49.591 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - There are already Docker Compose services running, skipping startup
INFO  2025-05-26 12:34:50.352 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 12:34:50.376 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 23 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 12:34:50.546 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5b03c310, com.mongodb.Jep395RecordCodecProvider@1f4426df, com.mongodb.KotlinCodecProvider@1f78c695]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57867], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
INFO  2025-05-26 12:34:50.554 [cluster-ClusterId{value='68341292f52a03faf1bf6ae5', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=3345600, minRoundTripTimeNanos=0}
WARN  2025-05-26 12:34:50.554 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 12:34:50.587 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 12:34:50.680 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 12:34:50.681 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:50.682 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 12:34:50.682 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 12:34:50.719 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 12:34:50.719 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1125 ms
INFO  2025-05-26 12:34:50.732 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 12:34:50.941 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 12:34:51.028 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:51.036 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 12:34:51.042 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 2.647 seconds (process running for 1130.9)
INFO  2025-05-26 12:34:51.048 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-26 12:34:54.567 [File Watcher] o.s.b.d.a.LocalDevToolsAutoConfiguration$RestartingClassPathChangeChangedEventListener - Restarting due to 1 class path change (1 addition, 0 deletions, 0 modifications)
INFO  2025-05-26 12:34:54.568 [Thread-23] o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
INFO  2025-05-26 12:34:54.569 [tomcat-shutdown] o.a.coyote.http11.Http11NioProtocol - Pausing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:54.882 [tomcat-shutdown] o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
INFO  2025-05-26 12:34:54.883 [Thread-23] o.a.coyote.http11.Http11NioProtocol - Stopping ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:55.043 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Starting PigeonApplication using Java 17.0.15 with PID 24748 (C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\target\classes started by KUSHWPR in C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon)
INFO  2025-05-26 12:34:55.044 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - The following 1 profile is active: "dev"
INFO  2025-05-26 12:34:55.054 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - Using Docker Compose file C:\Users\KUSHWPR\OneDrive - Daimler Truck\Desktop\pradeep\pigeon\pigeon\compose.yaml
INFO  2025-05-26 12:34:56.536 [restartedMain] o.s.b.d.c.l.DockerComposeLifecycleManager - There are already Docker Compose services running, skipping startup
INFO  2025-05-26 12:34:57.137 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
INFO  2025-05-26 12:34:57.164 [restartedMain] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 25 ms. Found 1 MongoDB repository interface.
INFO  2025-05-26 12:34:57.343 [restartedMain] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "5.4.0"}, "os": {"type": "Windows", "name": "Windows 11", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Microsoft/17.0.15+6-LTS"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='root', source='admin', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@5b03c310, com.mongodb.Jep395RecordCodecProvider@1f4426df, com.mongodb.KotlinCodecProvider@1f78c695]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[127.0.0.1:57867], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverMonitoringMode=AUTO, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null, timeoutMS=null}
WARN  2025-05-26 12:34:57.350 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
WARN  2025-05-26 12:34:57.384 [restartedMain] o.s.data.convert.CustomConversions - Registering converter from interface java.util.List to interface org.springframework.data.domain.Vector as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
INFO  2025-05-26 12:34:57.437 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=41794400, minRoundTripTimeNanos=0}
INFO  2025-05-26 12:34:57.507 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8084 (http)
INFO  2025-05-26 12:34:57.509 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:57.509 [restartedMain] o.a.catalina.core.StandardService - Starting service [Tomcat]
INFO  2025-05-26 12:34:57.509 [restartedMain] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.41]
INFO  2025-05-26 12:34:57.554 [restartedMain] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
INFO  2025-05-26 12:34:57.554 [restartedMain] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 1013 ms
INFO  2025-05-26 12:34:57.565 [restartedMain] o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 35729
WARN  2025-05-26 12:34:57.769 [restartedMain] i.l.g.m.s.q.AnnotatedArgumentBuilder - No explicit argument name given and the parameter name lost in compilation: public static boolean org.bson.types.ObjectId.isValid(java.lang.String)#java.lang.String arg0. For details and possible solutions see https://github.com/leangen/graphql-spqr/wiki/Errors#missing-argument-name
INFO  2025-05-26 12:34:57.841 [restartedMain] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8084"]
INFO  2025-05-26 12:34:57.847 [restartedMain] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8084 (http) with context path '/'
INFO  2025-05-26 12:34:57.849 [restartedMain] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dev-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dev-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  2025-05-26 12:34:57.850 [restartedMain] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
INFO  2025-05-26 12:34:57.861 [restartedMain] o.a.k.c.consumer.ConsumerConfig - These configurations '[value-deserializer, group-id, auto-offset-reset, topic, enable-auto-commit, key-deserializer]' were supplied but are not used yet.
INFO  2025-05-26 12:34:57.861 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
INFO  2025-05-26 12:34:57.861 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
INFO  2025-05-26 12:34:57.861 [restartedMain] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1748243097861
INFO  2025-05-26 12:34:57.862 [restartedMain] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Subscribed to topic(s): pigeon-dev-events
INFO  2025-05-26 12:34:57.868 [restartedMain] c.d.it.dsc.pigeon.PigeonApplication - Started PigeonApplication in 2.926 seconds (process running for 1137.725)
INFO  2025-05-26 12:34:57.869 [restartedMain] o.s.b.d.a.ConditionEvaluationDeltaLoggingListener - Condition evaluation unchanged
INFO  2025-05-26 12:34:57.873 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cluster ID: CN7txgUcSB6MWW_nfJzuzg
INFO  2025-05-26 12:34:57.876 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 12:34:57.879 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:34:57.887 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-db39724d-266e-4a37-9152-646f7f844704
INFO  2025-05-26 12:34:57.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 12:34:57.890 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=43, memberId='consumer-dev-group-2-db39724d-266e-4a37-9152-646f7f844704', protocol='range'}
INFO  2025-05-26 12:34:57.892 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 43: {consumer-dev-group-2-db39724d-266e-4a37-9152-646f7f844704=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 12:34:57.903 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=43, memberId='consumer-dev-group-2-db39724d-266e-4a37-9152-646f7f844704', protocol='range'}
INFO  2025-05-26 12:34:57.903 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 12:34:57.904 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 12:34:57.911 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 12:34:57.911 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 13:18:46.828 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 13:18:46.928 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Node -1 disconnected.
INFO  2025-05-26 13:18:46.929 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Disconnecting from node 0 due to request timeout.
INFO  2025-05-26 13:18:46.933 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 1878 due to node 0 being disconnected (elapsed time since creation: 1815388ms, elapsed time since send: 1815388ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 13:18:46.935 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 13:18:46.935 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Error sending fetch request (sessionId=789644135, epoch=1588) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-26 13:18:47.110 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 13:18:48.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=43, memberId='consumer-dev-group-2-db39724d-266e-4a37-9152-646f7f844704', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 13:18:48.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 13:18:48.099 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 13:18:48.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 13:18:48.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 13:18:48.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 13:18:48.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 13:18:48.100 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 13:18:48.129 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-dca10611-0d7c-4f7e-a576-631fcd2be35c
INFO  2025-05-26 13:18:48.130 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 13:18:48.226 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=45, memberId='consumer-dev-group-2-dca10611-0d7c-4f7e-a576-631fcd2be35c', protocol='range'}
INFO  2025-05-26 13:18:48.227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 45: {consumer-dev-group-2-dca10611-0d7c-4f7e-a576-631fcd2be35c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 13:18:48.281 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=45, memberId='consumer-dev-group-2-dca10611-0d7c-4f7e-a576-631fcd2be35c', protocol='range'}
INFO  2025-05-26 13:18:48.282 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 13:18:48.282 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 13:18:48.600 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1723346800, minRoundTripTimeNanos=0}
INFO  2025-05-26 13:18:48.681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 13:18:48.681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 13:44:39.699 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 13:44:39.839 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 13:44:39.896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=45, memberId='consumer-dev-group-2-dca10611-0d7c-4f7e-a576-631fcd2be35c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 13:44:40.888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 13:44:40.889 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 13:44:40.903 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-04a5da9c-c9bf-4ad4-9adb-1857594fd98f
INFO  2025-05-26 13:44:40.904 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 13:44:41.023 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=47, memberId='consumer-dev-group-2-04a5da9c-c9bf-4ad4-9adb-1857594fd98f', protocol='range'}
INFO  2025-05-26 13:44:41.023 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 47: {consumer-dev-group-2-04a5da9c-c9bf-4ad4-9adb-1857594fd98f=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 13:44:41.036 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=47, memberId='consumer-dev-group-2-04a5da9c-c9bf-4ad4-9adb-1857594fd98f', protocol='range'}
INFO  2025-05-26 13:44:41.037 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 13:44:41.037 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 13:44:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 13:44:41.041 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 13:44:41.249 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1547987800, minRoundTripTimeNanos=0}
INFO  2025-05-26 14:07:06.116 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 14:07:06.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 2373 due to node 0 being disconnected (elapsed time since creation: 1341695ms, elapsed time since send: 1341695ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 14:07:06.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Node 2147483647 disconnected.
INFO  2025-05-26 14:07:06.618 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Error sending fetch request (sessionId=1004206930, epoch=403) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-26 14:07:06.619 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 14:07:07.591 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 14:07:07.788 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=47, memberId='consumer-dev-group-2-04a5da9c-c9bf-4ad4-9adb-1857594fd98f', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 14:07:07.789 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 14:07:07.790 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 14:07:07.790 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 14:07:07.790 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 14:07:07.791 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 14:07:07.791 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 14:07:07.791 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 14:07:08.176 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2055995800, minRoundTripTimeNanos=0}
INFO  2025-05-26 14:07:09.089 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-0dec7a02-f8dd-47bd-98c3-26e68bc28030
INFO  2025-05-26 14:07:09.090 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 14:07:09.104 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=49, memberId='consumer-dev-group-2-0dec7a02-f8dd-47bd-98c3-26e68bc28030', protocol='range'}
INFO  2025-05-26 14:07:09.104 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 49: {consumer-dev-group-2-0dec7a02-f8dd-47bd-98c3-26e68bc28030=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 14:07:09.107 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=49, memberId='consumer-dev-group-2-0dec7a02-f8dd-47bd-98c3-26e68bc28030', protocol='range'}
INFO  2025-05-26 14:07:09.108 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 14:07:09.108 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 14:07:09.111 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 14:07:09.112 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 15:22:12.599 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 15:22:12.666 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Node 0 disconnected.
INFO  2025-05-26 15:22:12.668 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 10703 due to node 0 being disconnected (elapsed time since creation: 877011ms, elapsed time since send: 877011ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 15:22:12.669 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Error sending fetch request (sessionId=784632610, epoch=7087) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-26 15:22:12.671 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 15:22:14.013 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 15:22:14.018 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=49, memberId='consumer-dev-group-2-0dec7a02-f8dd-47bd-98c3-26e68bc28030', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 15:22:14.019 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 15:22:14.020 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 15:22:14.021 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 15:22:14.023 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 15:22:14.027 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 15:22:14.032 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 15:22:14.033 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 15:22:14.054 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-b597189e-1478-40fd-9138-d9fff5213007
INFO  2025-05-26 15:22:14.057 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 15:22:14.071 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=51, memberId='consumer-dev-group-2-b597189e-1478-40fd-9138-d9fff5213007', protocol='range'}
INFO  2025-05-26 15:22:14.077 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 51: {consumer-dev-group-2-b597189e-1478-40fd-9138-d9fff5213007=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 15:22:14.146 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=51, memberId='consumer-dev-group-2-b597189e-1478-40fd-9138-d9fff5213007', protocol='range'}
INFO  2025-05-26 15:22:14.147 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 15:22:14.147 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 15:22:14.160 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 15:22:14.161 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 15:22:15.193 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2548478000, minRoundTripTimeNanos=0}
INFO  2025-05-26 15:48:33.674 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 15:48:33.523 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 15:48:34.294 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 15:48:34.509 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=726452600, minRoundTripTimeNanos=0}
INFO  2025-05-26 15:48:34.560 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=51, memberId='consumer-dev-group-2-b597189e-1478-40fd-9138-d9fff5213007', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 15:48:34.560 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 15:48:34.560 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 15:48:34.560 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 15:48:34.561 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 15:48:34.561 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 15:48:34.561 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 15:48:34.562 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 15:48:34.607 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-2ded0a1e-caf6-40a7-981a-cbc70b8dc442
INFO  2025-05-26 15:48:34.608 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 15:48:34.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=53, memberId='consumer-dev-group-2-2ded0a1e-caf6-40a7-981a-cbc70b8dc442', protocol='range'}
INFO  2025-05-26 15:48:34.663 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 53: {consumer-dev-group-2-2ded0a1e-caf6-40a7-981a-cbc70b8dc442=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 15:48:34.666 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=53, memberId='consumer-dev-group-2-2ded0a1e-caf6-40a7-981a-cbc70b8dc442', protocol='range'}
INFO  2025-05-26 15:48:34.667 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 15:48:34.667 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 15:48:34.669 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 15:48:34.669 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 16:07:59.930 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 16:08:00.145 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 16:08:00.145 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 16:08:00.146 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-26 16:08:00.171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 16:08:00.171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 16:08:00.171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 16:08:00.678 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 16:08:00.865 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=928301800, minRoundTripTimeNanos=0}
INFO  2025-05-26 16:08:01.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=53, memberId='consumer-dev-group-2-2ded0a1e-caf6-40a7-981a-cbc70b8dc442', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 16:08:01.143 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 16:08:01.143 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 16:08:01.143 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 16:08:01.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 16:08:01.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 16:08:01.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 16:08:01.144 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 16:08:01.380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-b53bbb6d-9bfe-4c66-9794-562aac9e544c
INFO  2025-05-26 16:08:01.381 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 16:08:01.718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=55, memberId='consumer-dev-group-2-b53bbb6d-9bfe-4c66-9794-562aac9e544c', protocol='range'}
INFO  2025-05-26 16:08:01.720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 55: {consumer-dev-group-2-b53bbb6d-9bfe-4c66-9794-562aac9e544c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 16:08:02.684 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=55, memberId='consumer-dev-group-2-b53bbb6d-9bfe-4c66-9794-562aac9e544c', protocol='range'}
INFO  2025-05-26 16:08:02.685 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 16:08:02.685 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 16:08:02.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 16:08:02.696 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 17:06:02.257 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 17:06:02.360 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Cancelled in-flight FETCH request with correlation id 15549 due to node 0 being disconnected (elapsed time since creation: 3153208ms, elapsed time since send: 3153208ms, throttle time: 0ms, request timeout: 30000ms)
INFO  2025-05-26 17:06:02.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Node 2147483647 disconnected.
INFO  2025-05-26 17:06:02.361 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Error sending fetch request (sessionId=527365362, epoch=4102) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
INFO  2025-05-26 17:06:02.361 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
INFO  2025-05-26 17:06:02.530 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=55, memberId='consumer-dev-group-2-b53bbb6d-9bfe-4c66-9794-562aac9e544c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 17:06:02.661 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 17:06:02.662 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 17:06:02.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-28206399-d89b-4af0-ab68-a0460378d525
INFO  2025-05-26 17:06:02.901 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 17:06:03.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=57, memberId='consumer-dev-group-2-28206399-d89b-4af0-ab68-a0460378d525', protocol='range'}
INFO  2025-05-26 17:06:03.142 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 57: {consumer-dev-group-2-28206399-d89b-4af0-ab68-a0460378d525=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 17:06:03.478 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1214847700, minRoundTripTimeNanos=0}
INFO  2025-05-26 17:06:03.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=57, memberId='consumer-dev-group-2-28206399-d89b-4af0-ab68-a0460378d525', protocol='range'}
INFO  2025-05-26 17:06:03.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 17:06:03.544 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 17:06:03.557 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 17:06:03.559 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 17:14:37.843 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Exception in monitor thread while connecting to server 127.0.0.1:57867
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.createReadTimeoutException(InternalStreamConnection.java:819)
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:807)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:857)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:517)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:469)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.lookupServerDescription(DefaultServerMonitor.java:249)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitor.run(DefaultServerMonitor.java:176)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:182)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:824)
	... 4 common frames omitted
INFO  2025-05-26 17:14:37.888 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted.
INFO  2025-05-26 17:14:37.889 [kafka-coordinator-heartbeat-thread | dev-group] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Requesting disconnect from last known coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 17:14:37.889 [kafka-coordinator-heartbeat-thread | dev-group] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Client requested disconnect from node 2147483647
INFO  2025-05-26 17:14:38.024 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Discovered group coordinator DTC-5CG228321F:9092 (id: 2147483647 rack: null)
INFO  2025-05-26 17:14:38.140 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Attempt to heartbeat with Generation{generationId=57, memberId='consumer-dev-group-2-28206399-d89b-4af0-ab68-a0460378d525', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
INFO  2025-05-26 17:14:38.140 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 17:14:38.140 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
INFO  2025-05-26 17:14:38.140 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Giving away all assigned partitions as lost since generation/memberID has been reset,indicating that consumer is in old state or no longer part of the group
INFO  2025-05-26 17:14:38.140 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Lost previously assigned partitions pigeon-dev-events-0
INFO  2025-05-26 17:14:38.141 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions lost: [pigeon-dev-events-0]
INFO  2025-05-26 17:14:38.141 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions revoked: [pigeon-dev-events-0]
INFO  2025-05-26 17:14:38.141 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 17:14:38.150 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Request joining group due to: need to re-join with the given member-id: consumer-dev-group-2-6399ba22-e4d1-4f49-9c69-6e5eb0d4b11c
INFO  2025-05-26 17:14:38.150 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] (Re-)joining group
INFO  2025-05-26 17:14:38.212 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully joined group with generation Generation{generationId=59, memberId='consumer-dev-group-2-6399ba22-e4d1-4f49-9c69-6e5eb0d4b11c', protocol='range'}
INFO  2025-05-26 17:14:38.213 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Finished assignment for group at generation 59: {consumer-dev-group-2-6399ba22-e4d1-4f49-9c69-6e5eb0d4b11c=Assignment(partitions=[pigeon-dev-events-0])}
INFO  2025-05-26 17:14:38.222 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Successfully synced group in generation Generation{generationId=59, memberId='consumer-dev-group-2-6399ba22-e4d1-4f49-9c69-6e5eb0d4b11c', protocol='range'}
INFO  2025-05-26 17:14:38.223 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Notifying assignor about the new Assignment(partitions=[pigeon-dev-events-0])
INFO  2025-05-26 17:14:38.223 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-dev-group-2, groupId=dev-group] Adding newly assigned partitions: pigeon-dev-events-0
INFO  2025-05-26 17:14:38.226 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition pigeon-dev-events-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DTC-5CG228321F:9092 (id: 0 rack: null)], epoch=0}}
INFO  2025-05-26 17:14:38.226 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - dev-group: partitions assigned: [pigeon-dev-events-0]
INFO  2025-05-26 17:14:38.242 [cluster-ClusterId{value='68341299f52a03faf1bf6ae6', description='null'}-127.0.0.1:57867] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=127.0.0.1:57867, type=STANDALONE, cryptd=false, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=394849500, minRoundTripTimeNanos=0}
